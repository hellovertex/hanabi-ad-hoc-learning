{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhanabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "#import checkpointer\n",
    "#import iteration_statistics\n",
    "#import dqn_agent\n",
    "#import gin.tf\n",
    "import rl_env\n",
    "import numpy as np\n",
    "#import rainbow_agent\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "import rl_env\n",
    "#import run_paired_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_encoded_observations(encoder, state, num_players):\n",
    "    print(\"--- EncodedObservations ---\")\n",
    "    print(\"Observation encoding shape: {}\".format(encoder.shape()))\n",
    "    print(\"Current actual player: {}\".format(state.cur_player()))\n",
    "    for i in range(num_players):\n",
    "      print(\"Encoded observation for player {}: {}\".format(\n",
    "          i, encoder.encode(state.observation(i))))\n",
    "    print(\"--- EndEncodedObservations ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_observations(encoder, state, player_num):\n",
    "    codes = encoder.encode(state.observation(player_num))\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_observation(observation):\n",
    "    \"\"\"Print some basic information about an agent observation.\"\"\"\n",
    "    print(\"--- Observation ---\")\n",
    "    print(observation)\n",
    "\n",
    "    print(\"### Information about the observation retrieved separately ###\")\n",
    "    print(\"### Current player, relative to self: {}\".format(\n",
    "        observation.cur_player_offset()))\n",
    "    print(\"### Observed hands: {}\".format(observation.observed_hands()))\n",
    "    print(\"### Card knowledge: {}\".format(observation.card_knowledge()))\n",
    "    print(\"### Discard pile: {}\".format(observation.discard_pile()))\n",
    "    print(\"### Fireworks: {}\".format(observation.fireworks()))\n",
    "    print(\"### Deck size: {}\".format(observation.deck_size()))\n",
    "    move_string = \"### Last moves:\"\n",
    "    for move_tuple in observation.last_moves():\n",
    "      move_string += \" {}\".format(move_tuple)\n",
    "    print(move_string)\n",
    "    print(\"### Information tokens: {}\".format(observation.information_tokens()))\n",
    "    print(\"### Life tokens: {}\".format(observation.life_tokens()))\n",
    "    print(\"### Legal moves: {}\".format(observation.legal_moves()))\n",
    "    print(\"--- EndObservation ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state(state):\n",
    "    \"\"\"Print some basic information about the state.\"\"\"\n",
    "    print(\"\")\n",
    "    print(\"Current player: {}\".format(state.cur_player()))\n",
    "    print(state)\n",
    "\n",
    "    # Example of more queries to provide more about this state. For\n",
    "    # example, bots could use these methods to to get information\n",
    "    # about the state in order to act accordingly.\n",
    "    print(\"### Information about the state retrieved separately ###\")\n",
    "    print(\"### Information tokens: {}\".format(state.information_tokens()))\n",
    "    print(\"### Life tokens: {}\".format(state.life_tokens()))\n",
    "    print(\"### Fireworks: {}\".format(state.fireworks()))\n",
    "    print(\"### Deck size: {}\".format(state.deck_size()))\n",
    "    print(\"### Discard pile: {}\".format(str(state.discard_pile())))\n",
    "    print(\"### Player hands: {}\".format(str(state.player_hands())))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from rl_env import Agent\n",
    "\n",
    "\n",
    "class RandomAgent():\n",
    "    def act(self, observation):\n",
    "        \"\"\"Act based on an observation.\"\"\"\n",
    "        return random.choice(observation.legal_moves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = RandomAgent()\n",
    "agent = RandomAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0052, -0.0022,  0.0218,  ...,  0.0099, -0.0270, -0.0045],\n",
      "        [-0.0101, -0.0130,  0.0013,  ..., -0.0299, -0.0369, -0.0255],\n",
      "        [-0.0116, -0.0008, -0.0019,  ..., -0.0355, -0.0038,  0.0245],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0275,  0.0002,  ...,  0.0109, -0.0311,  0.0214],\n",
      "        [-0.0348,  0.0220, -0.0280,  ...,  0.0253,  0.0245, -0.0095],\n",
      "        [-0.0084, -0.0083, -0.0064,  ..., -0.0311,  0.0096, -0.0138]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-8.4133e-03, -5.5949e-03, -1.1412e-02,  ...,  1.3503e-03,\n",
      "          1.8761e-02,  3.8035e-03],\n",
      "        [ 7.7393e-03,  4.5130e-03,  1.1742e-04,  ..., -1.0072e-02,\n",
      "         -1.0530e-02,  2.3279e-02],\n",
      "        [-1.3216e-02,  2.2158e-02,  3.5500e-03,  ...,  2.0677e-03,\n",
      "         -1.8540e-02, -1.2972e-03],\n",
      "        ...,\n",
      "        [ 1.0474e-02,  5.3673e-03,  1.3706e-03,  ...,  1.3214e-02,\n",
      "          3.7996e-05,  9.2696e-03],\n",
      "        [ 4.8977e-03,  5.0213e-03, -8.2979e-05,  ...,  2.3672e-03,\n",
      "          1.1231e-02,  7.7150e-03],\n",
      "        [ 3.4147e-03,  7.7970e-05,  6.1556e-05,  ...,  5.1282e-03,\n",
      "          7.2330e-03, -2.0680e-03]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0136, -0.0078,  0.0104,  ...,  0.0113, -0.0083, -0.0007],\n",
      "        [-0.0024, -0.0085,  0.0014,  ..., -0.0400, -0.0474, -0.0022],\n",
      "        [-0.0248,  0.0214,  0.0016,  ..., -0.0334, -0.0223,  0.0232],\n",
      "        ...,\n",
      "        [ 0.0212, -0.0222,  0.0016,  ...,  0.0241, -0.0311,  0.0307],\n",
      "        [-0.0299,  0.0271, -0.0281,  ...,  0.0277,  0.0357, -0.0018],\n",
      "        [-0.0050, -0.0082, -0.0064,  ..., -0.0260,  0.0169, -0.0158]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 0.0277,  0.0013, -0.0284, -0.0199, -0.0357,  0.0320, -0.0029, -0.0292,\n",
      "         0.0090,  0.0098,  0.0268, -0.0170, -0.0002, -0.0225, -0.0261, -0.0386,\n",
      "        -0.0177,  0.0077, -0.0195,  0.0207,  0.0336,  0.0302,  0.0324,  0.0351,\n",
      "         0.0178, -0.0026,  0.0196,  0.0131,  0.0077,  0.0180, -0.0002, -0.0066,\n",
      "         0.0191,  0.0322,  0.0083, -0.0321,  0.0300, -0.0367,  0.0037,  0.0149,\n",
      "        -0.0168,  0.0181, -0.0107, -0.0122,  0.0309, -0.0118, -0.0135, -0.0061,\n",
      "         0.0016,  0.0269,  0.0097,  0.0248,  0.0277,  0.0001,  0.0276, -0.0083,\n",
      "        -0.0289, -0.0066, -0.0073,  0.0385, -0.0136,  0.0163, -0.0061, -0.0016,\n",
      "         0.0266,  0.0333,  0.0267, -0.0104,  0.0309,  0.0100, -0.0271, -0.0120,\n",
      "        -0.0390,  0.0288, -0.0124, -0.0302,  0.0061,  0.0200, -0.0136,  0.0176,\n",
      "        -0.0143, -0.0094, -0.0309, -0.0185,  0.0361,  0.0361, -0.0362,  0.0270,\n",
      "         0.0178, -0.0148,  0.0082, -0.0180, -0.0306,  0.0050,  0.0073,  0.0328,\n",
      "         0.0130,  0.0327, -0.0377, -0.0139, -0.0275, -0.0052,  0.0100, -0.0303,\n",
      "        -0.0113, -0.0115, -0.0126, -0.0332,  0.0139, -0.0173, -0.0081, -0.0311,\n",
      "        -0.0243,  0.0192, -0.0163, -0.0090,  0.0299, -0.0134, -0.0161,  0.0014,\n",
      "         0.0107,  0.0066,  0.0292,  0.0204, -0.0281, -0.0268,  0.0207, -0.0037,\n",
      "         0.0375, -0.0174, -0.0176, -0.0365, -0.0052, -0.0155,  0.0324, -0.0215,\n",
      "        -0.0311,  0.0285, -0.0051,  0.0190,  0.0120, -0.0054, -0.0104, -0.0120,\n",
      "         0.0361,  0.0239,  0.0068,  0.0217,  0.0071,  0.0191, -0.0301,  0.0055,\n",
      "         0.0128,  0.0040,  0.0364,  0.0177, -0.0044,  0.0067,  0.0008, -0.0388,\n",
      "         0.0338, -0.0138, -0.0376, -0.0123, -0.0224,  0.0072, -0.0313,  0.0095,\n",
      "         0.0215, -0.0373, -0.0262,  0.0095,  0.0158, -0.0340,  0.0077, -0.0198,\n",
      "         0.0153,  0.0100, -0.0175, -0.0352,  0.0216,  0.0389, -0.0076, -0.0269,\n",
      "        -0.0147,  0.0078, -0.0154,  0.0121, -0.0048, -0.0233,  0.0299, -0.0127,\n",
      "        -0.0243,  0.0187, -0.0360, -0.0052,  0.0252,  0.0055,  0.0105,  0.0269,\n",
      "        -0.0292, -0.0043,  0.0354,  0.0290, -0.0172,  0.0332,  0.0253,  0.0183,\n",
      "        -0.0022, -0.0121, -0.0033,  0.0260, -0.0218, -0.0070, -0.0104,  0.0028,\n",
      "         0.0200,  0.0124,  0.0192, -0.0057,  0.0015, -0.0285, -0.0356,  0.0058,\n",
      "        -0.0011, -0.0269, -0.0066, -0.0354,  0.0227,  0.0240,  0.0205, -0.0208,\n",
      "         0.0013,  0.0026,  0.0262, -0.0086,  0.0092,  0.0053,  0.0309, -0.0161,\n",
      "         0.0275, -0.0103,  0.0305, -0.0150,  0.0015,  0.0082, -0.0011,  0.0191,\n",
      "        -0.0052,  0.0141,  0.0108, -0.0004,  0.0080,  0.0144, -0.0231,  0.0353,\n",
      "         0.0220, -0.0384,  0.0238, -0.0193, -0.0245,  0.0311,  0.0096,  0.0300,\n",
      "         0.0058, -0.0160, -0.0387, -0.0318,  0.0345, -0.0383, -0.0068, -0.0061,\n",
      "         0.0037,  0.0047, -0.0203,  0.0309, -0.0076, -0.0140, -0.0117, -0.0132,\n",
      "        -0.0291,  0.0146,  0.0208,  0.0166,  0.0346, -0.0269, -0.0369, -0.0199,\n",
      "        -0.0042,  0.0006, -0.0055,  0.0349, -0.0018,  0.0190,  0.0288, -0.0354,\n",
      "        -0.0015,  0.0356,  0.0005,  0.0084, -0.0286,  0.0296, -0.0333, -0.0106,\n",
      "         0.0032, -0.0044,  0.0249,  0.0010, -0.0138, -0.0335,  0.0120,  0.0137,\n",
      "         0.0151, -0.0194,  0.0180, -0.0327, -0.0151,  0.0149, -0.0379,  0.0341,\n",
      "         0.0186,  0.0356,  0.0112,  0.0144, -0.0323, -0.0006,  0.0042, -0.0346,\n",
      "        -0.0021,  0.0243,  0.0025, -0.0355,  0.0314, -0.0058,  0.0067,  0.0156,\n",
      "         0.0268,  0.0080, -0.0305, -0.0276,  0.0007, -0.0056,  0.0236, -0.0180,\n",
      "         0.0069,  0.0097, -0.0303,  0.0236,  0.0085,  0.0298,  0.0269,  0.0130,\n",
      "        -0.0176,  0.0254,  0.0006, -0.0221, -0.0045,  0.0199,  0.0292,  0.0053,\n",
      "         0.0226, -0.0389,  0.0133,  0.0121,  0.0176, -0.0219,  0.0375, -0.0136,\n",
      "         0.0295,  0.0307, -0.0009, -0.0313, -0.0117,  0.0021,  0.0037, -0.0001,\n",
      "        -0.0382, -0.0264,  0.0342, -0.0015, -0.0286,  0.0241, -0.0277, -0.0023,\n",
      "        -0.0195, -0.0232,  0.0287, -0.0234,  0.0160, -0.0184, -0.0323, -0.0324,\n",
      "         0.0041, -0.0216, -0.0126,  0.0018,  0.0254, -0.0172, -0.0320,  0.0082,\n",
      "        -0.0151,  0.0205, -0.0033,  0.0052, -0.0132,  0.0237,  0.0169,  0.0195,\n",
      "         0.0255, -0.0362, -0.0088,  0.0263,  0.0213, -0.0078, -0.0145, -0.0124,\n",
      "         0.0155,  0.0190,  0.0373, -0.0356,  0.0042,  0.0151, -0.0278, -0.0132,\n",
      "        -0.0356, -0.0129, -0.0018, -0.0377,  0.0053, -0.0271,  0.0087, -0.0110,\n",
      "        -0.0330, -0.0082, -0.0085,  0.0381,  0.0385, -0.0251,  0.0164, -0.0264,\n",
      "         0.0172, -0.0045, -0.0115,  0.0082,  0.0029, -0.0298, -0.0059, -0.0092,\n",
      "        -0.0124, -0.0193, -0.0021, -0.0245, -0.0283, -0.0248, -0.0306, -0.0247,\n",
      "         0.0101, -0.0201, -0.0062, -0.0122,  0.0337, -0.0132,  0.0069, -0.0122,\n",
      "         0.0051, -0.0010, -0.0064,  0.0312, -0.0151, -0.0306, -0.0005, -0.0188,\n",
      "         0.0276, -0.0071, -0.0311, -0.0325, -0.0091, -0.0110,  0.0275,  0.0109,\n",
      "         0.0334,  0.0100,  0.0174,  0.0197,  0.0324,  0.0216, -0.0309,  0.0095,\n",
      "         0.0184, -0.0313, -0.0159,  0.0160, -0.0318, -0.0154, -0.0308,  0.0226,\n",
      "        -0.0287,  0.0164,  0.0164, -0.0343,  0.0280, -0.0078,  0.0066,  0.0201,\n",
      "         0.0277,  0.0215,  0.0338,  0.0035,  0.0016, -0.0341, -0.0049,  0.0239],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([ 2.0068e-02, -1.7170e-02, -8.6423e-03, -1.3582e-02, -5.1761e-03,\n",
      "        -6.6875e-04, -4.4811e-04, -1.0316e-02,  2.8761e-03, -2.3544e-02,\n",
      "         2.6224e-03,  1.2409e-03,  1.2300e-02, -6.9732e-03,  1.8834e-02,\n",
      "        -1.7210e-04, -1.7928e-02, -9.6749e-03, -3.0159e-03, -4.7063e-03,\n",
      "        -1.4769e-02, -1.6101e-03,  5.7873e-03, -4.1233e-03, -1.9303e-03,\n",
      "        -1.7966e-02, -4.8091e-03,  4.6820e-03,  9.0352e-03, -7.5732e-03,\n",
      "         9.8976e-03,  1.0803e-02,  3.8808e-03, -1.2124e-02, -7.9593e-03,\n",
      "        -7.1081e-03, -1.8559e-02, -1.5532e-04, -1.4672e-02, -3.0045e-04,\n",
      "         4.5860e-03,  9.1942e-03, -2.9081e-03, -1.7864e-02,  4.8332e-03,\n",
      "         4.5259e-03, -4.9013e-03, -2.1069e-04,  1.0490e-02,  3.7032e-03,\n",
      "         3.5591e-04, -4.3880e-03,  1.7138e-02, -8.2447e-04,  2.1462e-03,\n",
      "         1.1565e-03,  6.0374e-03,  1.4988e-02, -4.9218e-03, -2.2817e-03,\n",
      "         1.2069e-02, -4.4951e-03, -8.6971e-03,  8.2557e-03,  8.4035e-03,\n",
      "         7.9475e-04, -7.7537e-03,  2.5769e-03,  8.8112e-03, -1.6768e-02,\n",
      "         3.3628e-03, -1.8652e-02, -4.5014e-03,  1.1628e-02,  3.1468e-03,\n",
      "        -6.9634e-03,  1.1796e-02,  2.4108e-03, -2.7687e-03,  2.4750e-03,\n",
      "         1.6380e-02,  1.7098e-02,  1.7430e-02,  1.7183e-02, -1.2419e-03,\n",
      "         1.8662e-02, -9.0342e-03, -5.3191e-03,  1.4936e-03,  4.3605e-03,\n",
      "         2.1379e-02, -1.2093e-02,  5.7767e-03,  1.4891e-03,  4.0018e-03,\n",
      "        -2.6325e-03,  1.5687e-02,  4.5105e-03,  4.3597e-03, -1.6461e-02,\n",
      "        -1.7966e-03, -5.2481e-03,  1.2778e-03,  9.1857e-03,  1.4402e-03,\n",
      "         7.6674e-03, -5.8571e-03,  7.2597e-03, -6.9531e-03, -1.8991e-02,\n",
      "        -1.9905e-03, -9.1034e-03,  1.0195e-02, -1.1648e-02, -9.9855e-04,\n",
      "         3.9496e-03,  1.1436e-02, -2.8102e-03,  1.3002e-02,  6.4159e-03,\n",
      "         1.6964e-02, -1.1610e-02,  5.3769e-03, -6.0962e-03,  2.5576e-02,\n",
      "         3.4549e-03,  6.2163e-03, -1.3814e-02, -2.1529e-03,  2.1361e-03,\n",
      "        -1.0361e-02, -2.0738e-02, -7.4962e-03, -9.8464e-03, -6.5478e-03,\n",
      "         6.4829e-03,  5.2283e-03,  5.5363e-03,  3.6062e-04,  1.7790e-03,\n",
      "         1.5520e-02,  6.5007e-03, -1.3989e-02, -7.2855e-03, -1.9940e-03,\n",
      "         8.7328e-03,  1.2912e-02, -6.0545e-03,  1.9620e-02, -1.6037e-02,\n",
      "         1.6406e-03,  7.0778e-03, -3.4767e-03, -4.4142e-03,  1.1783e-02,\n",
      "         1.2655e-02, -1.0670e-02, -5.5138e-03, -4.5807e-03,  1.5855e-02,\n",
      "        -9.8717e-04, -1.2199e-02,  4.5757e-03,  4.5117e-03, -2.4193e-03,\n",
      "         1.1375e-02, -1.0071e-02,  6.8136e-03, -2.3506e-03,  1.7875e-03,\n",
      "        -1.0733e-02,  4.0600e-03,  6.7628e-03,  4.9192e-03, -3.8884e-03,\n",
      "        -1.5662e-02, -1.3893e-02,  1.3004e-02,  1.1861e-02,  1.7160e-03,\n",
      "        -4.9941e-04,  3.9027e-03,  6.8383e-03, -1.4272e-02,  2.4411e-04,\n",
      "        -1.0972e-02, -1.3575e-02,  5.9571e-03, -2.8501e-03, -3.7390e-04,\n",
      "         1.2277e-03,  1.6481e-03,  1.5521e-02,  9.7132e-04, -1.6805e-02,\n",
      "        -5.9117e-03, -4.7914e-03, -1.7595e-02,  3.6349e-03,  2.3398e-04,\n",
      "        -1.1196e-02,  1.5932e-02, -6.7262e-03, -7.4944e-03,  7.3575e-03,\n",
      "        -5.2266e-04,  5.8744e-03, -4.9775e-03,  1.0094e-02,  2.3116e-04,\n",
      "         3.0316e-04,  7.9944e-04, -6.1772e-03, -1.9112e-02,  5.0768e-03,\n",
      "        -4.6993e-04, -4.1793e-03, -9.6691e-03, -7.8304e-03,  3.1707e-04,\n",
      "        -1.7130e-04, -1.6747e-02, -5.2644e-03, -4.7970e-03,  6.0380e-03,\n",
      "         4.9813e-03, -1.2961e-02,  1.4301e-03, -8.7906e-03, -9.5080e-03,\n",
      "        -8.0952e-03, -1.2132e-02,  1.8598e-03, -7.6786e-03, -1.8506e-03,\n",
      "        -3.0446e-04,  1.5911e-02,  1.5343e-02,  1.7828e-03,  1.4452e-02,\n",
      "        -2.1130e-02,  1.3197e-02,  6.8997e-03,  7.6947e-03,  1.3732e-02,\n",
      "        -6.4136e-04,  1.5264e-02,  1.0550e-03,  3.3650e-03,  1.1812e-02,\n",
      "        -1.7339e-02, -1.0064e-02,  7.4394e-03, -9.6523e-03,  2.0004e-02,\n",
      "        -1.5626e-02,  6.0878e-03, -6.5552e-03,  1.4996e-02, -5.6808e-03,\n",
      "        -9.4025e-03,  4.2752e-03,  2.0321e-02, -1.7613e-02,  1.4468e-02,\n",
      "         8.9913e-03,  5.0788e-04,  2.4674e-02,  5.0122e-03,  8.7161e-04,\n",
      "        -9.4864e-03,  1.1266e-02,  2.6916e-02, -1.7431e-02,  3.7301e-03,\n",
      "        -1.0972e-02,  1.3596e-03,  5.0507e-03, -1.6176e-03, -1.6480e-02,\n",
      "        -3.6019e-03, -1.8236e-02, -2.8697e-03,  2.7095e-04, -9.0824e-04,\n",
      "         2.6029e-03,  1.4178e-03,  4.8321e-04,  2.7792e-03,  6.8128e-03,\n",
      "        -1.5336e-02, -8.6655e-03, -3.6959e-03, -1.0135e-02, -1.5610e-03,\n",
      "         7.0680e-03,  1.7575e-02, -5.4386e-03,  1.3175e-02,  9.7751e-03,\n",
      "        -5.6301e-03,  2.9638e-03, -7.8123e-04,  1.3360e-02, -2.4664e-02,\n",
      "        -1.9854e-02, -7.8289e-03,  3.3386e-03,  1.3599e-02,  1.7060e-02,\n",
      "        -6.9163e-03, -7.7010e-03, -3.5572e-03,  1.0900e-03,  1.4195e-02,\n",
      "         1.0799e-02,  2.8064e-02,  1.2897e-02,  1.0792e-02,  6.1288e-03,\n",
      "         1.4365e-02, -7.8141e-03,  9.1495e-03, -5.5296e-03,  5.8315e-03,\n",
      "        -4.1356e-03, -9.2392e-03,  1.3818e-03,  9.1809e-03, -3.6237e-03,\n",
      "         3.6167e-04,  7.0838e-03,  5.0620e-03,  6.3132e-03, -4.5965e-03,\n",
      "         8.7729e-03, -1.6384e-02, -1.1526e-03,  3.0938e-03,  1.8563e-02,\n",
      "         7.7243e-03, -7.0381e-04,  3.2681e-03,  7.0613e-03,  4.1420e-03,\n",
      "         4.7397e-03, -3.7514e-03, -1.3975e-03,  1.1092e-02,  1.1438e-02,\n",
      "        -1.3519e-02,  4.4804e-03, -6.6165e-04,  2.5506e-03,  5.3476e-03,\n",
      "        -4.1978e-03, -2.7802e-03,  1.1749e-02, -9.6090e-04, -1.8167e-02,\n",
      "         7.6867e-03,  6.9587e-03, -5.8979e-03,  2.7970e-03, -1.4942e-02,\n",
      "        -8.1422e-03,  1.2354e-03, -1.2130e-03, -8.8490e-04,  2.7861e-02,\n",
      "         3.9686e-04, -1.2928e-02,  5.1655e-03, -6.3897e-03, -1.0591e-02,\n",
      "         1.2214e-02,  1.2141e-02,  6.5926e-03,  6.0165e-03, -1.2731e-02,\n",
      "         1.8737e-03,  6.5075e-03,  5.5571e-03, -1.0583e-02,  1.1214e-02,\n",
      "         6.5144e-03,  1.4523e-02, -2.5260e-02, -1.6945e-02,  2.1001e-02,\n",
      "        -1.0624e-04,  7.5281e-03,  5.2673e-04, -8.0381e-03,  6.3071e-03,\n",
      "         1.1330e-02,  3.1824e-03,  4.3609e-03,  7.8962e-03,  8.7352e-03,\n",
      "         1.4789e-02, -3.7137e-03,  2.1007e-03,  2.5413e-03,  1.8966e-03,\n",
      "        -1.1361e-02,  5.8775e-03, -9.7063e-04, -3.3590e-03,  1.1570e-02,\n",
      "        -2.4442e-03,  3.5328e-03,  1.1168e-02, -4.8180e-03, -5.8707e-05,\n",
      "        -8.2382e-03, -6.3965e-03, -1.0354e-02,  9.7170e-03, -2.1056e-02,\n",
      "         7.3536e-03,  5.2280e-03, -1.4653e-03, -1.9276e-02, -3.6028e-03,\n",
      "         2.4230e-03, -2.1264e-02,  1.1124e-02,  1.5564e-03,  2.4951e-03,\n",
      "         7.9845e-06, -7.3896e-03,  6.2076e-03, -4.0784e-03,  8.1778e-03,\n",
      "         2.0344e-03, -7.7997e-03,  1.1428e-02, -1.2803e-02, -8.0221e-03,\n",
      "        -2.2280e-02, -8.4634e-03, -7.3795e-03,  1.4914e-03,  9.1316e-03,\n",
      "         3.3691e-03,  3.6154e-03,  1.2945e-02, -4.8520e-03,  9.6210e-04,\n",
      "         1.1222e-02,  1.5420e-03,  1.1526e-03,  5.0958e-03,  8.4748e-03,\n",
      "         4.8080e-03, -1.1184e-02,  1.3291e-02, -1.0254e-02, -5.4987e-03,\n",
      "         1.8359e-03,  6.4558e-03,  7.0426e-05, -2.4045e-03, -1.5598e-02,\n",
      "        -1.0037e-02, -7.5223e-03, -1.3774e-02,  7.4867e-04, -8.6394e-05,\n",
      "         1.9618e-02, -6.7070e-03, -7.8045e-03,  1.6775e-03,  8.6275e-03,\n",
      "         1.5617e-02, -2.1166e-02,  8.9054e-03,  2.3575e-03,  5.4962e-04,\n",
      "         2.7510e-03, -8.3977e-03, -2.5796e-03,  9.0148e-03, -1.0748e-02,\n",
      "         8.1355e-03, -1.6990e-03,  3.7183e-03, -9.2874e-04, -2.5024e-03,\n",
      "         2.9092e-03,  3.5413e-03, -1.8859e-03, -1.4175e-02,  6.6933e-03,\n",
      "        -3.2428e-03,  3.4634e-03, -1.4489e-02,  7.9270e-03,  1.0045e-02,\n",
      "         9.9079e-03,  1.0899e-02,  3.4056e-03, -8.2491e-03, -1.7925e-02,\n",
      "         2.6118e-03,  6.1711e-03,  1.7172e-02, -1.2358e-03, -1.0392e-02,\n",
      "         1.5944e-02, -5.2842e-03])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([ 0.0477, -0.0158, -0.0370, -0.0335, -0.0409,  0.0314, -0.0034, -0.0395,\n",
      "         0.0119, -0.0138,  0.0294, -0.0158,  0.0121, -0.0295, -0.0073, -0.0388,\n",
      "        -0.0356, -0.0020, -0.0225,  0.0160,  0.0188,  0.0286,  0.0381,  0.0310,\n",
      "         0.0158, -0.0206,  0.0148,  0.0178,  0.0168,  0.0104,  0.0097,  0.0042,\n",
      "         0.0230,  0.0201,  0.0004, -0.0392,  0.0115, -0.0369, -0.0110,  0.0146,\n",
      "        -0.0122,  0.0272, -0.0136, -0.0301,  0.0358, -0.0073, -0.0184, -0.0063,\n",
      "         0.0121,  0.0306,  0.0101,  0.0205,  0.0448, -0.0007,  0.0297, -0.0071,\n",
      "        -0.0229,  0.0083, -0.0123,  0.0362, -0.0015,  0.0118, -0.0148,  0.0066,\n",
      "         0.0350,  0.0341,  0.0190, -0.0078,  0.0397, -0.0067, -0.0237, -0.0306,\n",
      "        -0.0435,  0.0404, -0.0093, -0.0372,  0.0179,  0.0224, -0.0164,  0.0201,\n",
      "         0.0021,  0.0077, -0.0134, -0.0013,  0.0348,  0.0548, -0.0452,  0.0216,\n",
      "         0.0193, -0.0104,  0.0296, -0.0301, -0.0249,  0.0065,  0.0113,  0.0302,\n",
      "         0.0287,  0.0372, -0.0333, -0.0304, -0.0293, -0.0105,  0.0113, -0.0212,\n",
      "        -0.0099, -0.0038, -0.0185, -0.0259,  0.0070, -0.0363, -0.0101, -0.0402,\n",
      "        -0.0141,  0.0075, -0.0173, -0.0050,  0.0413, -0.0162, -0.0031,  0.0078,\n",
      "         0.0277, -0.0050,  0.0345,  0.0143, -0.0025, -0.0234,  0.0269, -0.0175,\n",
      "         0.0353, -0.0153, -0.0280, -0.0572, -0.0127, -0.0253,  0.0258, -0.0150,\n",
      "        -0.0259,  0.0340, -0.0047,  0.0208,  0.0275,  0.0011, -0.0244, -0.0193,\n",
      "         0.0341,  0.0326,  0.0197,  0.0156,  0.0268,  0.0031, -0.0285,  0.0126,\n",
      "         0.0093, -0.0004,  0.0481,  0.0303, -0.0151,  0.0012, -0.0038, -0.0230,\n",
      "         0.0328, -0.0260, -0.0330, -0.0078, -0.0248,  0.0186, -0.0414,  0.0163,\n",
      "         0.0191, -0.0356, -0.0370,  0.0136,  0.0226, -0.0290,  0.0038, -0.0354,\n",
      "         0.0014,  0.0230, -0.0056, -0.0335,  0.0211,  0.0429, -0.0008, -0.0412,\n",
      "        -0.0144, -0.0032, -0.0290,  0.0181, -0.0076, -0.0237,  0.0311, -0.0110,\n",
      "        -0.0087,  0.0197, -0.0528, -0.0111,  0.0205, -0.0121,  0.0142,  0.0272,\n",
      "        -0.0404,  0.0116,  0.0287,  0.0215, -0.0098,  0.0327,  0.0312,  0.0134,\n",
      "         0.0079, -0.0119, -0.0030,  0.0268, -0.0279, -0.0261, -0.0054,  0.0024,\n",
      "         0.0158,  0.0028,  0.0114, -0.0053,  0.0013, -0.0453, -0.0408,  0.0010,\n",
      "         0.0050, -0.0219, -0.0196, -0.0340,  0.0139,  0.0145,  0.0124, -0.0330,\n",
      "         0.0032, -0.0051,  0.0243, -0.0089,  0.0252,  0.0206,  0.0327, -0.0017,\n",
      "         0.0064,  0.0029,  0.0374, -0.0073,  0.0152,  0.0075,  0.0142,  0.0201,\n",
      "        -0.0018,  0.0260, -0.0065, -0.0104,  0.0154,  0.0047, -0.0031,  0.0197,\n",
      "         0.0281, -0.0450,  0.0388, -0.0250, -0.0339,  0.0354,  0.0300,  0.0124,\n",
      "         0.0203, -0.0070, -0.0382, -0.0071,  0.0395, -0.0374, -0.0163,  0.0052,\n",
      "         0.0306, -0.0127, -0.0166,  0.0200, -0.0062, -0.0089, -0.0133, -0.0296,\n",
      "        -0.0327, -0.0037,  0.0179,  0.0168,  0.0337, -0.0243, -0.0355, -0.0195,\n",
      "        -0.0014,  0.0074, -0.0208,  0.0263, -0.0055,  0.0088,  0.0272, -0.0283,\n",
      "         0.0161,  0.0301,  0.0137,  0.0182, -0.0343,  0.0325, -0.0341,  0.0028,\n",
      "        -0.0215, -0.0242,  0.0171,  0.0043, -0.0002, -0.0165,  0.0051,  0.0060,\n",
      "         0.0115, -0.0183,  0.0322, -0.0219,  0.0130,  0.0278, -0.0271,  0.0402,\n",
      "         0.0330,  0.0278,  0.0204,  0.0089, -0.0265, -0.0047, -0.0051, -0.0333,\n",
      "         0.0071,  0.0207,  0.0029, -0.0284,  0.0365,  0.0005,  0.0021,  0.0244,\n",
      "         0.0104,  0.0068, -0.0274, -0.0090,  0.0084, -0.0063,  0.0269, -0.0109,\n",
      "         0.0110,  0.0145, -0.0341,  0.0222,  0.0195,  0.0413,  0.0133,  0.0175,\n",
      "        -0.0182,  0.0280,  0.0060, -0.0263, -0.0073,  0.0317,  0.0282, -0.0129,\n",
      "         0.0302, -0.0319,  0.0074,  0.0149,  0.0027, -0.0301,  0.0388, -0.0148,\n",
      "         0.0287,  0.0586, -0.0005, -0.0442, -0.0066, -0.0043, -0.0069,  0.0121,\n",
      "        -0.0261, -0.0198,  0.0402, -0.0142, -0.0268,  0.0306, -0.0221, -0.0128,\n",
      "        -0.0083, -0.0167,  0.0432, -0.0486, -0.0009,  0.0026, -0.0324, -0.0249,\n",
      "         0.0047, -0.0296, -0.0063,  0.0132,  0.0286, -0.0129, -0.0241,  0.0169,\n",
      "        -0.0003,  0.0168, -0.0012,  0.0078, -0.0113,  0.0124,  0.0228,  0.0186,\n",
      "         0.0221, -0.0247, -0.0113,  0.0299,  0.0324, -0.0127, -0.0145, -0.0207,\n",
      "         0.0091,  0.0086,  0.0470, -0.0567,  0.0115,  0.0203, -0.0292, -0.0325,\n",
      "        -0.0392, -0.0105, -0.0231, -0.0266,  0.0068, -0.0246,  0.0087, -0.0183,\n",
      "        -0.0268, -0.0122, -0.0003,  0.0401,  0.0307, -0.0137,  0.0036, -0.0344,\n",
      "        -0.0051, -0.0129, -0.0189,  0.0097,  0.0120, -0.0265, -0.0023,  0.0038,\n",
      "        -0.0173, -0.0183,  0.0091, -0.0229, -0.0272, -0.0197, -0.0221, -0.0199,\n",
      "        -0.0010, -0.0068, -0.0165, -0.0177,  0.0355, -0.0067,  0.0069, -0.0146,\n",
      "        -0.0105, -0.0110, -0.0140,  0.0175, -0.0144, -0.0307,  0.0191, -0.0255,\n",
      "         0.0198, -0.0054, -0.0224, -0.0169, -0.0303, -0.0021,  0.0299,  0.0115,\n",
      "         0.0361,  0.0016,  0.0148,  0.0287,  0.0216,  0.0298, -0.0326,  0.0132,\n",
      "         0.0175, -0.0338, -0.0130,  0.0196, -0.0336, -0.0296, -0.0241,  0.0194,\n",
      "        -0.0252,  0.0019,  0.0244, -0.0243,  0.0379,  0.0031,  0.0100,  0.0119,\n",
      "         0.0098,  0.0241,  0.0400,  0.0206,  0.0004, -0.0445,  0.0110,  0.0186],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0235, -0.0429, -0.0039,  ...,  0.0288, -0.0438,  0.0065],\n",
      "        [-0.0413,  0.0120, -0.0412,  ..., -0.0235, -0.0021, -0.0073],\n",
      "        [ 0.0296, -0.0437, -0.0188,  ...,  0.0416, -0.0124,  0.0077],\n",
      "        ...,\n",
      "        [ 0.0384, -0.0289, -0.0298,  ..., -0.0247,  0.0033, -0.0037],\n",
      "        [-0.0117,  0.0404,  0.0120,  ..., -0.0281,  0.0394, -0.0069],\n",
      "        [-0.0290,  0.0343, -0.0089,  ..., -0.0286,  0.0062,  0.0398]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-0.0232,  0.0027, -0.0086,  ...,  0.0128,  0.0051, -0.0050],\n",
      "        [ 0.0160, -0.0182, -0.0036,  ..., -0.0056, -0.0095,  0.0023],\n",
      "        [ 0.0040,  0.0010, -0.0054,  ..., -0.0050, -0.0285,  0.0116],\n",
      "        ...,\n",
      "        [-0.0133, -0.0100, -0.0109,  ...,  0.0020, -0.0015, -0.0028],\n",
      "        [ 0.0140,  0.0009,  0.0100,  ...,  0.0020, -0.0056,  0.0081],\n",
      "        [ 0.0060,  0.0016, -0.0037,  ..., -0.0115, -0.0028, -0.0116]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0003, -0.0402, -0.0125,  ...,  0.0416, -0.0387,  0.0015],\n",
      "        [-0.0253, -0.0063, -0.0448,  ..., -0.0291, -0.0116, -0.0051],\n",
      "        [ 0.0336, -0.0426, -0.0242,  ...,  0.0366, -0.0410,  0.0193],\n",
      "        ...,\n",
      "        [ 0.0251, -0.0389, -0.0408,  ..., -0.0227,  0.0018, -0.0066],\n",
      "        [ 0.0023,  0.0413,  0.0221,  ..., -0.0261,  0.0338,  0.0012],\n",
      "        [-0.0230,  0.0359, -0.0126,  ..., -0.0401,  0.0034,  0.0282]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 4.2962e-02, -2.5850e-02,  2.3193e-02, -4.0758e-02, -2.0169e-02,\n",
      "        -2.5027e-02,  2.2833e-02,  3.9860e-02,  8.4973e-03, -3.0608e-02,\n",
      "        -2.2652e-02, -1.3785e-02,  3.4430e-02,  1.8226e-02,  2.7176e-02,\n",
      "        -8.6743e-03, -3.2555e-02, -3.7980e-02, -9.0539e-03,  4.9310e-03,\n",
      "         8.0201e-03, -4.4371e-03,  2.1160e-03,  2.8079e-02,  2.7361e-02,\n",
      "         4.0969e-03, -1.7164e-02, -6.3610e-03, -2.8270e-02, -3.3193e-02,\n",
      "        -9.3218e-03,  2.9546e-02, -1.9433e-02,  2.8451e-02, -2.8142e-02,\n",
      "         4.0696e-02,  1.1912e-03,  1.1269e-02,  7.4974e-03,  1.1994e-02,\n",
      "         3.7180e-02,  3.0967e-02,  1.1611e-02,  8.6945e-03, -2.9929e-02,\n",
      "         3.0238e-02,  2.1753e-02,  2.3300e-02,  2.0186e-02,  1.4592e-02,\n",
      "        -6.5763e-03, -2.4272e-02, -3.5595e-02, -8.8281e-03, -2.9003e-02,\n",
      "         3.6393e-02,  3.8699e-02,  3.7341e-02, -4.4018e-04,  3.4421e-02,\n",
      "         2.6756e-02, -3.4001e-02,  3.7448e-02, -2.5078e-02,  2.0753e-02,\n",
      "         1.9490e-02, -6.8479e-03, -3.9562e-02, -2.8759e-02, -2.3100e-02,\n",
      "        -2.5403e-02,  2.1283e-03,  2.4854e-02,  2.4560e-02, -4.3375e-02,\n",
      "         1.1941e-02,  2.8606e-02, -1.0297e-02, -2.7613e-02,  4.2534e-02,\n",
      "        -2.9365e-02,  4.7473e-03,  3.9959e-02, -3.9243e-02, -2.5615e-02,\n",
      "        -2.0616e-02,  7.9952e-03, -3.3064e-02,  2.5451e-02,  5.7355e-03,\n",
      "         2.2953e-02, -2.6008e-02,  4.4102e-02,  2.5840e-02, -4.1981e-02,\n",
      "         2.6639e-02,  2.3174e-03, -1.0910e-02,  2.2833e-02,  2.3828e-02,\n",
      "        -1.8758e-02,  3.7839e-02, -4.2898e-02, -2.5590e-02,  2.3391e-02,\n",
      "         1.2528e-02,  9.8928e-03,  3.3163e-03,  1.1584e-02,  3.2026e-02,\n",
      "        -3.4075e-03, -3.4048e-02,  1.5761e-02, -8.7175e-03, -3.2773e-02,\n",
      "         1.5471e-02,  3.1491e-02,  2.2843e-03, -1.9926e-03,  2.8476e-02,\n",
      "        -2.2205e-02,  1.8031e-03, -3.2314e-02,  9.3852e-03,  5.1056e-03,\n",
      "        -2.3469e-02,  2.2231e-02,  1.0270e-02, -2.7383e-02, -3.1918e-02,\n",
      "         4.3180e-02, -3.8426e-02,  2.2274e-02,  3.8936e-02, -2.7046e-02,\n",
      "        -5.3113e-03, -3.9397e-02, -3.1335e-02, -1.6140e-02, -4.2062e-02,\n",
      "         3.8713e-02, -6.0525e-03, -1.2354e-02,  2.9283e-03,  3.6934e-02,\n",
      "        -3.5244e-02,  2.1899e-02, -4.2033e-02,  1.3490e-02,  1.7698e-02,\n",
      "        -9.9195e-03, -3.3406e-02, -7.6533e-03, -1.8563e-02,  2.9927e-03,\n",
      "         1.2747e-02, -9.7465e-03,  9.8595e-03, -7.5400e-03,  3.5003e-03,\n",
      "        -3.8762e-02,  4.0047e-02,  2.1547e-02,  1.0493e-02,  2.4782e-02,\n",
      "         2.2422e-02, -1.6225e-02, -4.2982e-02, -3.0662e-02, -4.2696e-02,\n",
      "        -5.5674e-03, -1.6090e-02,  2.7443e-02, -3.6729e-03,  1.3960e-02,\n",
      "         2.6912e-02, -1.8627e-02,  3.6286e-02, -3.7719e-02,  2.1937e-02,\n",
      "         3.5609e-02, -5.6105e-03,  4.2243e-02,  3.8807e-02, -4.2474e-03,\n",
      "         2.0804e-02, -5.1813e-03, -3.8041e-03,  2.1023e-02,  3.3362e-02,\n",
      "         1.2582e-02,  2.2822e-03,  2.4689e-02, -1.4364e-02,  3.0964e-02,\n",
      "        -3.0834e-02,  3.5685e-02,  2.5133e-02,  4.9547e-04,  2.2896e-03,\n",
      "        -1.9626e-03,  3.4132e-02,  3.6776e-02, -8.7421e-03, -2.4832e-03,\n",
      "        -3.1579e-02,  3.6613e-02, -3.0623e-02, -2.5812e-02, -2.2828e-02,\n",
      "         1.8049e-02, -1.2903e-02,  3.0936e-02, -3.8750e-02, -4.1420e-03,\n",
      "        -3.3997e-02,  1.6849e-02,  1.5373e-02,  3.9094e-02,  5.8209e-03,\n",
      "         4.2369e-02, -1.6760e-02, -3.9107e-02,  3.2237e-02, -3.5574e-02,\n",
      "         2.3184e-02, -1.8568e-02,  1.7624e-02, -1.2919e-02,  1.3408e-02,\n",
      "         1.8820e-03, -1.5265e-02,  1.5819e-02,  6.2671e-03,  3.3616e-02,\n",
      "         2.3343e-02,  1.1074e-02,  2.0561e-02, -2.9569e-02,  4.5503e-03,\n",
      "        -7.6835e-03, -1.9644e-02,  4.3529e-02,  1.8882e-02, -1.0053e-02,\n",
      "        -8.3774e-03, -7.4861e-04, -1.4264e-02,  3.1016e-02,  4.1901e-02,\n",
      "        -1.8436e-02, -2.0658e-02,  1.6914e-02,  2.3248e-02,  2.3143e-03,\n",
      "        -3.8438e-02, -9.4619e-03,  3.1590e-02,  9.8445e-05, -2.6010e-02,\n",
      "        -1.9396e-02, -3.9312e-02,  4.4102e-02, -2.5094e-02, -3.1889e-02,\n",
      "         4.4173e-02, -1.6557e-02,  1.8201e-02, -4.3388e-02,  1.1046e-03,\n",
      "         8.6877e-03,  3.2740e-03,  2.7988e-02,  4.2041e-02,  3.2327e-02,\n",
      "         1.9510e-02,  2.7143e-02,  9.9013e-03,  2.1200e-02, -2.2805e-02,\n",
      "         3.6688e-02, -4.0017e-03, -8.6100e-03,  3.2416e-02, -4.0664e-02,\n",
      "        -4.2778e-02, -3.3636e-02,  2.4982e-02, -3.6267e-02,  2.9164e-02,\n",
      "        -3.1951e-02,  4.0349e-02, -3.8055e-03, -2.5801e-02,  3.5529e-02,\n",
      "         3.8407e-02, -1.4526e-02, -7.1158e-03, -5.5619e-06,  1.9364e-02,\n",
      "         2.3941e-02, -3.5510e-02,  1.7209e-02,  3.4769e-03, -4.0763e-02,\n",
      "         9.4316e-03,  2.2355e-02, -3.2065e-02,  3.1032e-02,  2.1164e-02,\n",
      "         8.2372e-04, -2.0483e-02,  8.9583e-03,  4.3435e-02, -2.9420e-02,\n",
      "        -1.9051e-02,  4.0903e-02,  1.9396e-02, -2.7148e-03,  4.0496e-02,\n",
      "         2.2094e-02,  2.1807e-02, -4.0343e-02,  3.2404e-02, -3.5701e-02,\n",
      "         3.6982e-02, -4.0110e-02,  1.4927e-02,  8.5095e-03,  1.2918e-02,\n",
      "         2.8250e-02,  1.4058e-02, -1.8302e-02,  2.9515e-02, -1.3481e-02,\n",
      "         1.4769e-02,  3.4337e-02, -3.2026e-02, -3.3675e-02,  1.3819e-02,\n",
      "         2.5636e-03, -5.2241e-03, -5.1980e-03, -4.5438e-03, -3.2499e-02,\n",
      "         3.4065e-02, -3.9800e-02, -5.4270e-03,  1.3638e-02, -1.1085e-02,\n",
      "         3.3284e-02, -4.2187e-02,  1.2350e-02,  8.1520e-03,  4.0565e-03,\n",
      "        -9.6183e-03, -3.0075e-03, -1.0840e-02, -3.2788e-02, -3.8180e-02,\n",
      "         4.3352e-02,  1.9780e-02, -4.2274e-02, -2.9754e-04,  3.5154e-02,\n",
      "        -2.5315e-02,  1.8078e-02, -9.8904e-03,  2.4996e-02,  2.5781e-02,\n",
      "        -2.3387e-02, -1.0034e-02, -1.3233e-03,  1.9933e-02,  4.4000e-02,\n",
      "         4.0464e-02,  2.3345e-02,  1.9737e-03, -8.5750e-03,  1.1842e-02,\n",
      "         3.4952e-02,  1.2108e-02, -3.2061e-02,  3.8198e-02,  3.8951e-02,\n",
      "        -3.9608e-02,  1.8159e-02, -1.0015e-02, -2.8376e-02,  2.5055e-02,\n",
      "         3.2782e-02,  2.9690e-03,  1.9138e-02, -1.8338e-02,  2.9518e-02,\n",
      "         1.3944e-02,  1.5854e-02,  4.1115e-02,  3.3414e-02, -3.6629e-02,\n",
      "         3.9050e-02, -3.4146e-02,  3.6815e-02,  2.8731e-02, -3.6484e-02,\n",
      "        -3.3765e-02, -4.1309e-02,  1.1490e-02, -9.2399e-03,  7.7729e-03,\n",
      "        -1.6596e-02,  6.7374e-03, -2.2919e-02,  3.3193e-02,  3.1551e-02,\n",
      "        -2.9135e-02,  1.0340e-02, -3.3130e-02, -4.1319e-02,  9.3324e-03,\n",
      "        -1.1240e-02,  3.2474e-02, -1.6302e-02, -4.3982e-02,  3.8490e-02,\n",
      "         2.8469e-02, -3.9581e-02, -2.6447e-03,  3.7784e-02, -2.7325e-02,\n",
      "        -9.3187e-03, -4.2735e-02, -1.5413e-02, -1.3295e-02, -3.1801e-02,\n",
      "        -3.4597e-02,  1.3462e-02, -3.2460e-02, -3.6206e-02, -2.6092e-02,\n",
      "         2.8806e-02, -2.4899e-02, -3.2192e-02,  4.5896e-03, -3.9760e-02,\n",
      "        -3.7775e-02,  3.2799e-02,  1.3967e-02, -1.0382e-02,  1.4586e-02,\n",
      "        -3.4584e-02, -9.3752e-03,  1.6525e-02, -1.5153e-02,  1.0969e-02,\n",
      "         2.7048e-02,  1.9756e-03, -1.9024e-02,  5.9776e-04, -4.3964e-02,\n",
      "        -1.2830e-02,  2.5078e-02, -2.0712e-02, -2.2161e-02, -1.5702e-02,\n",
      "        -1.9859e-02,  3.5362e-02,  1.1702e-02,  4.2573e-02, -1.0377e-02,\n",
      "         5.4551e-03,  2.2997e-02, -1.6931e-02,  2.3244e-02,  2.1233e-03,\n",
      "        -1.7442e-02, -1.4285e-03, -6.8828e-03, -9.3646e-03, -3.4013e-02,\n",
      "         1.3737e-02, -3.7398e-02, -2.7623e-03,  3.5340e-02, -2.0311e-03,\n",
      "         3.5415e-02,  4.0769e-02, -9.8053e-03,  5.2082e-03, -2.7720e-02,\n",
      "         4.2575e-02,  3.4823e-02, -3.6156e-02, -1.5967e-02, -4.3792e-02,\n",
      "        -2.8148e-02,  2.3445e-02, -3.4168e-02, -3.4323e-02,  3.3348e-02,\n",
      "         1.8782e-02,  1.4532e-02, -1.7616e-02,  2.8086e-02,  1.7565e-02,\n",
      "         2.2350e-03,  2.6273e-02,  3.9699e-02,  7.8447e-03, -3.6185e-02,\n",
      "        -2.9751e-02, -1.4293e-02], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-7.6510e-03, -2.3323e-03, -1.1659e-02,  1.0972e-02, -7.0052e-03,\n",
      "        -1.2261e-02, -1.3014e-02,  5.2710e-03,  5.8856e-03, -9.7263e-04,\n",
      "         5.8087e-03,  1.0417e-02, -2.2343e-03,  2.1377e-02,  3.4199e-03,\n",
      "        -1.6840e-03, -6.8599e-03,  5.9579e-03, -3.8973e-03,  1.6581e-02,\n",
      "        -8.6067e-03, -3.1078e-03,  4.3001e-03,  4.7914e-05,  8.5364e-03,\n",
      "         1.8119e-02, -7.2190e-03, -2.0367e-02, -1.6011e-02, -5.8449e-03,\n",
      "         1.0021e-02,  1.7788e-03, -9.5784e-03,  3.5943e-04, -1.8937e-02,\n",
      "         1.1648e-02, -2.0699e-02,  1.5132e-03, -1.7879e-02, -4.0998e-03,\n",
      "        -7.8234e-03,  7.5657e-04,  6.6268e-03,  6.6900e-03, -2.3315e-03,\n",
      "         7.4630e-03,  8.4561e-03,  1.1856e-02,  2.9090e-03,  7.6420e-03,\n",
      "         1.3029e-02,  6.4411e-03, -1.3387e-02, -4.7889e-03, -1.0762e-03,\n",
      "         5.9704e-03,  7.6920e-03, -4.4019e-03, -3.5891e-03,  1.2929e-02,\n",
      "         2.1372e-02,  8.6580e-03,  9.7432e-03,  9.5680e-04,  8.5964e-03,\n",
      "         1.6929e-02,  4.2720e-03, -1.5667e-02,  8.3653e-03, -7.2505e-03,\n",
      "        -4.1570e-03, -2.7068e-03,  2.3787e-02, -7.3632e-03,  2.2653e-03,\n",
      "         4.6269e-03, -7.5544e-03, -1.0217e-02,  2.0233e-02, -2.0546e-02,\n",
      "        -1.6638e-03, -6.4648e-03, -5.0500e-03,  2.3134e-02, -8.0216e-03,\n",
      "         3.9436e-03, -7.8705e-03, -5.0700e-03,  8.1337e-04, -1.0715e-02,\n",
      "         1.0989e-02,  8.9526e-03, -1.0881e-03,  9.3711e-03, -7.3011e-03,\n",
      "        -6.2049e-03, -8.9696e-04, -1.4779e-02,  4.7897e-03, -1.6230e-02,\n",
      "         1.5736e-02,  2.2384e-02, -3.8983e-03,  1.2206e-02,  3.9892e-03,\n",
      "        -3.4223e-03, -1.8165e-02,  3.1983e-03, -9.7625e-03,  5.5613e-03,\n",
      "         3.8371e-03, -5.2248e-03, -1.1571e-03,  1.1303e-02, -8.6792e-03,\n",
      "        -4.1003e-03, -1.0599e-02,  1.3342e-02, -7.5389e-03,  5.6867e-03,\n",
      "         1.6890e-03,  1.3561e-02,  5.3049e-03,  3.0380e-03,  5.7406e-03,\n",
      "         1.1171e-03, -4.5269e-03,  1.5259e-03,  1.1350e-02,  2.0726e-02,\n",
      "        -1.8991e-03, -6.7389e-03, -5.5630e-03, -6.3526e-03,  1.6038e-02,\n",
      "        -1.5179e-02, -9.7286e-03, -9.6184e-03,  1.0174e-02,  1.0537e-03,\n",
      "        -2.3309e-03,  1.1664e-02, -3.3019e-03,  6.8931e-03,  3.4035e-04,\n",
      "        -1.2971e-02, -1.1432e-02,  5.0969e-03, -1.3896e-02, -9.2167e-03,\n",
      "         1.6298e-02, -2.0459e-02,  1.2755e-02, -2.0260e-02,  2.7622e-02,\n",
      "        -6.3867e-03,  8.3627e-03,  1.6478e-02, -6.0097e-03, -5.0462e-03,\n",
      "         8.3901e-04,  8.6395e-03,  1.3453e-02, -6.6375e-03, -3.2702e-03,\n",
      "        -3.7809e-03, -1.0731e-02,  2.2470e-03, -8.1308e-03, -1.5173e-02,\n",
      "        -1.2875e-02, -3.9041e-03, -3.0040e-03,  1.4097e-03, -1.6347e-03,\n",
      "        -6.1053e-03, -3.1019e-03,  1.5246e-02,  1.7719e-02, -5.2057e-04,\n",
      "         6.5248e-04, -1.6173e-02, -6.9705e-04, -4.1331e-03, -1.1539e-02,\n",
      "        -4.9578e-03,  1.3533e-03,  3.9745e-03, -1.0682e-02,  2.0757e-02,\n",
      "         1.5114e-02, -6.7132e-03, -1.5938e-03, -2.3619e-03, -1.6467e-02,\n",
      "         4.9117e-04,  3.8210e-03,  1.0506e-02, -1.4216e-03, -8.1038e-03,\n",
      "         9.9834e-04, -2.4334e-03, -2.2979e-03,  2.6611e-03, -2.8250e-03,\n",
      "        -1.9996e-03,  7.0152e-03, -6.1388e-03,  9.1272e-03,  1.2089e-02,\n",
      "         1.8303e-04, -2.3285e-02,  7.5353e-03,  6.4216e-03, -6.5273e-03,\n",
      "         6.6750e-04,  8.7128e-03, -1.8604e-02,  1.5495e-03,  3.5911e-03,\n",
      "        -2.4467e-02, -1.0319e-02, -1.5741e-02, -1.9519e-03, -8.8691e-03,\n",
      "        -7.6011e-03, -6.8686e-03, -1.6153e-02, -4.9265e-03, -8.3458e-03,\n",
      "         3.6020e-03, -7.1656e-04,  1.3205e-02,  7.3171e-03,  6.9965e-03,\n",
      "        -5.3112e-03,  1.3139e-02, -2.3745e-02, -9.4627e-04,  8.4239e-03,\n",
      "        -5.3516e-03, -1.6480e-03,  2.9574e-03, -1.4576e-02,  1.8332e-02,\n",
      "         2.0688e-03, -2.9739e-03, -5.6211e-03, -1.6669e-03,  7.1324e-03,\n",
      "         4.8501e-03, -2.5293e-03, -6.6052e-03,  4.2710e-03, -1.7611e-02,\n",
      "        -3.3731e-03,  1.3634e-02, -1.6302e-02, -2.1024e-03, -5.1006e-03,\n",
      "        -3.0086e-03, -2.7165e-03,  4.0500e-03, -2.4748e-02, -4.7935e-03,\n",
      "        -4.3216e-03,  5.9065e-04,  6.6646e-03,  3.3059e-03, -8.5739e-03,\n",
      "        -1.9719e-02,  2.0737e-02,  2.6187e-03,  1.5789e-02, -1.7080e-02,\n",
      "        -8.3761e-03, -1.7653e-02,  3.3193e-03, -6.8953e-06, -6.7901e-03,\n",
      "         8.2924e-04, -6.1810e-04, -6.8581e-03,  1.0984e-02, -9.5782e-03,\n",
      "        -1.0161e-02, -6.0454e-03,  8.9568e-03, -2.3319e-02,  1.9225e-02,\n",
      "        -5.9404e-03,  1.3625e-02, -6.8301e-03, -1.3568e-02,  5.0455e-04,\n",
      "        -4.3107e-03, -2.1040e-02,  8.4280e-03, -1.0367e-02,  6.3088e-03,\n",
      "        -9.4765e-03,  4.3323e-03,  1.8099e-02, -4.3478e-03,  1.4704e-02,\n",
      "        -6.2231e-03,  1.6730e-03,  4.4115e-03,  8.6255e-04,  8.1537e-03,\n",
      "         3.6659e-03, -4.7174e-04,  4.0048e-03,  1.3810e-02,  4.4115e-03,\n",
      "         9.8937e-03, -4.1446e-03,  7.0036e-04,  5.2386e-03,  1.0201e-02,\n",
      "        -3.0833e-03,  2.1299e-03,  9.5169e-03,  1.0885e-02, -4.5716e-03,\n",
      "         1.1510e-02, -3.0433e-03, -6.7082e-03, -9.7087e-03, -1.2940e-02,\n",
      "        -5.1174e-03, -2.5928e-03, -2.5686e-03,  9.9182e-03, -7.6573e-03,\n",
      "         4.0249e-03, -8.8406e-03, -1.6438e-02, -2.9405e-03, -7.1842e-03,\n",
      "         1.7383e-02, -9.2326e-03, -1.5480e-02,  8.3744e-04,  8.9872e-03,\n",
      "        -1.2039e-02, -1.1562e-02, -7.3567e-03,  1.0917e-02, -3.5505e-03,\n",
      "         2.7122e-04, -1.4946e-03,  7.6544e-03, -2.7381e-03, -4.1360e-03,\n",
      "         9.1466e-03,  2.2502e-03, -1.1348e-02,  5.5968e-03, -1.3669e-02,\n",
      "        -5.6930e-03, -6.3472e-03,  2.9199e-03, -4.4707e-03,  1.2544e-02,\n",
      "         8.7874e-03, -9.3763e-04, -4.2364e-03,  7.0163e-03, -9.8974e-03,\n",
      "         8.6195e-03, -6.0723e-03, -1.9205e-02, -4.7747e-03, -2.9880e-03,\n",
      "         3.8208e-03, -3.3659e-04, -1.2499e-02, -7.5184e-03,  9.8683e-03,\n",
      "         3.1109e-03, -2.6638e-03,  4.6767e-04, -1.1240e-02,  4.6573e-03,\n",
      "        -9.1084e-03,  1.2176e-03, -9.2039e-03, -5.4687e-03, -1.5029e-03,\n",
      "         1.7078e-02, -1.1805e-02, -1.9451e-03,  7.9463e-03, -8.5143e-04,\n",
      "        -1.0977e-02,  1.3794e-02, -1.7706e-03, -7.9979e-03,  3.8259e-04,\n",
      "         7.1821e-03, -7.2715e-03,  6.0577e-03, -4.8448e-03,  1.5440e-02,\n",
      "        -1.5500e-03, -8.6624e-03,  1.3269e-02, -1.2831e-03, -2.3735e-04,\n",
      "         1.0391e-02,  7.0527e-04,  1.5818e-03, -1.6918e-02,  1.2142e-02,\n",
      "        -2.9384e-02, -9.9330e-03, -5.8740e-03,  1.1186e-02,  1.3319e-02,\n",
      "        -1.8265e-02,  1.4580e-03,  1.3558e-03, -6.0014e-03,  1.7095e-02,\n",
      "         3.1402e-03,  2.0259e-02,  1.7011e-02, -5.4978e-03, -1.3010e-03,\n",
      "        -3.1166e-03,  1.0050e-02,  1.4559e-02,  1.0020e-02, -1.2723e-02,\n",
      "         3.4199e-03,  1.6919e-03,  4.1065e-03,  5.1537e-03, -3.1577e-03,\n",
      "         1.1153e-02,  2.9746e-03,  2.7423e-02,  1.0004e-02,  9.9569e-03,\n",
      "        -4.7099e-03, -2.1461e-03,  2.4387e-03,  9.3456e-03,  6.6564e-03,\n",
      "         8.5203e-03, -9.1372e-03,  1.1099e-02,  1.6375e-02,  1.2310e-02,\n",
      "        -9.9533e-03,  4.7168e-03,  1.0914e-03, -1.5001e-02, -8.7029e-03,\n",
      "        -6.4092e-03,  6.6732e-03, -6.1885e-04, -9.6311e-03,  2.8703e-05,\n",
      "        -5.2200e-03, -7.5393e-03,  7.3469e-03,  9.9754e-03,  1.2676e-02,\n",
      "         1.0495e-02,  5.4615e-03,  1.0389e-02, -1.3300e-02,  5.7131e-03,\n",
      "        -1.0155e-02, -7.5029e-04, -2.2438e-02, -3.0886e-03, -2.7175e-04,\n",
      "         1.4227e-02,  9.4498e-03,  1.3286e-02, -1.2295e-03, -4.9412e-03,\n",
      "         1.6868e-02,  9.2425e-03, -3.4342e-03, -2.6847e-03, -1.0116e-02,\n",
      "         2.0308e-02, -4.0136e-03,  1.2226e-02, -2.4284e-02,  2.4529e-04,\n",
      "         7.4868e-03, -4.8548e-03,  2.6270e-03,  1.0560e-02,  3.6835e-03,\n",
      "        -1.9259e-02, -2.9428e-03, -1.7540e-02,  9.4662e-03, -4.5120e-03,\n",
      "         1.5883e-02, -2.4225e-03, -2.9808e-03, -2.2615e-03, -3.8152e-03,\n",
      "        -1.0760e-02, -6.2379e-03])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([ 3.5311e-02, -2.8183e-02,  1.1533e-02, -2.9786e-02, -2.7175e-02,\n",
      "        -3.7289e-02,  9.8193e-03,  4.5131e-02,  1.4383e-02, -3.1581e-02,\n",
      "        -1.6843e-02, -3.3684e-03,  3.2196e-02,  3.9603e-02,  3.0596e-02,\n",
      "        -1.0358e-02, -3.9415e-02, -3.2022e-02, -1.2951e-02,  2.1512e-02,\n",
      "        -5.8669e-04, -7.5449e-03,  6.4161e-03,  2.8127e-02,  3.5897e-02,\n",
      "         2.2216e-02, -2.4383e-02, -2.6727e-02, -4.4281e-02, -3.9038e-02,\n",
      "         6.9913e-04,  3.1325e-02, -2.9011e-02,  2.8811e-02, -4.7079e-02,\n",
      "         5.2344e-02, -1.9508e-02,  1.2782e-02, -1.0382e-02,  7.8942e-03,\n",
      "         2.9357e-02,  3.1723e-02,  1.8238e-02,  1.5384e-02, -3.2260e-02,\n",
      "         3.7701e-02,  3.0209e-02,  3.5156e-02,  2.3095e-02,  2.2234e-02,\n",
      "         6.4524e-03, -1.7830e-02, -4.8982e-02, -1.3617e-02, -3.0079e-02,\n",
      "         4.2364e-02,  4.6391e-02,  3.2939e-02, -4.0293e-03,  4.7350e-02,\n",
      "         4.8128e-02, -2.5343e-02,  4.7191e-02, -2.4121e-02,  2.9349e-02,\n",
      "         3.6419e-02, -2.5758e-03, -5.5229e-02, -2.0394e-02, -3.0350e-02,\n",
      "        -2.9560e-02, -5.7846e-04,  4.8641e-02,  1.7197e-02, -4.1110e-02,\n",
      "         1.6568e-02,  2.1051e-02, -2.0514e-02, -7.3801e-03,  2.1988e-02,\n",
      "        -3.1028e-02, -1.7175e-03,  3.4909e-02, -1.6109e-02, -3.3636e-02,\n",
      "        -1.6673e-02,  1.2475e-04, -3.8134e-02,  2.6265e-02, -4.9792e-03,\n",
      "         3.3942e-02, -1.7055e-02,  4.3014e-02,  3.5211e-02, -4.9282e-02,\n",
      "         2.0434e-02,  1.4205e-03, -2.5690e-02,  2.7623e-02,  7.5981e-03,\n",
      "        -3.0220e-03,  6.0223e-02, -4.6796e-02, -1.3384e-02,  2.7380e-02,\n",
      "         9.1056e-03, -8.2724e-03,  6.5145e-03,  1.8213e-03,  3.7587e-02,\n",
      "         4.2956e-04, -3.9273e-02,  1.4604e-02,  2.5857e-03, -4.1452e-02,\n",
      "         1.1371e-02,  2.0893e-02,  1.5627e-02, -9.5315e-03,  3.4163e-02,\n",
      "        -2.0516e-02,  1.5364e-02, -2.7009e-02,  1.2423e-02,  1.0846e-02,\n",
      "        -2.2352e-02,  1.7704e-02,  1.1796e-02, -1.6034e-02, -1.1192e-02,\n",
      "         4.1281e-02, -4.5165e-02,  1.6711e-02,  3.2583e-02, -1.1008e-02,\n",
      "        -2.0490e-02, -4.9126e-02, -4.0953e-02, -5.9658e-03, -4.1008e-02,\n",
      "         3.6382e-02,  5.6116e-03, -1.5656e-02,  9.8214e-03,  3.7274e-02,\n",
      "        -4.8215e-02,  1.0467e-02, -3.6936e-02, -4.0615e-04,  8.4813e-03,\n",
      "         6.3784e-03, -5.3865e-02,  5.1018e-03, -3.8822e-02,  3.0615e-02,\n",
      "         6.3599e-03, -1.3838e-03,  2.6337e-02, -1.3550e-02, -1.5459e-03,\n",
      "        -3.7923e-02,  4.8687e-02,  3.5000e-02,  3.8554e-03,  2.1511e-02,\n",
      "         1.8641e-02, -2.6955e-02, -4.0735e-02, -3.8793e-02, -5.7869e-02,\n",
      "        -1.8443e-02, -1.9994e-02,  2.4439e-02, -2.2632e-03,  1.2326e-02,\n",
      "         2.0806e-02, -2.1729e-02,  5.1532e-02, -2.0000e-02,  2.1416e-02,\n",
      "         3.6261e-02, -2.1783e-02,  4.1546e-02,  3.4673e-02, -1.5787e-02,\n",
      "         1.5846e-02, -3.8280e-03,  1.7041e-04,  1.0341e-02,  5.4119e-02,\n",
      "         2.7696e-02, -4.4310e-03,  2.3095e-02, -1.6726e-02,  1.4497e-02,\n",
      "        -3.0343e-02,  3.9506e-02,  3.5639e-02, -9.2614e-04, -5.8142e-03,\n",
      "        -9.6421e-04,  3.1699e-02,  3.4479e-02, -6.0810e-03, -5.3082e-03,\n",
      "        -3.3579e-02,  4.3628e-02, -3.6762e-02, -1.6684e-02, -1.0739e-02,\n",
      "         1.8232e-02, -3.6188e-02,  3.8472e-02, -3.2328e-02, -1.0669e-02,\n",
      "        -3.3330e-02,  2.5562e-02, -3.2309e-03,  4.0644e-02,  9.4119e-03,\n",
      "         1.7902e-02, -2.7078e-02, -5.4847e-02,  3.0285e-02, -4.4443e-02,\n",
      "         1.5583e-02, -2.5436e-02,  1.4716e-03, -1.7846e-02,  5.0620e-03,\n",
      "         5.4840e-03, -1.5982e-02,  2.9024e-02,  1.3584e-02,  4.0612e-02,\n",
      "         1.8032e-02,  2.4212e-02, -3.1836e-03, -3.0515e-02,  1.2974e-02,\n",
      "        -1.3035e-02, -2.1292e-02,  4.6486e-02,  4.3057e-03,  8.2788e-03,\n",
      "        -6.3086e-03, -3.7225e-03, -1.9885e-02,  2.9349e-02,  4.9033e-02,\n",
      "        -1.3586e-02, -2.3187e-02,  1.0309e-02,  2.7519e-02, -1.5297e-02,\n",
      "        -4.1812e-02,  4.1717e-03,  1.5288e-02, -2.0039e-03, -3.1110e-02,\n",
      "        -2.2405e-02, -4.2028e-02,  4.8152e-02, -4.9842e-02, -3.6682e-02,\n",
      "         3.9851e-02, -1.5966e-02,  2.4865e-02, -4.0082e-02, -7.4693e-03,\n",
      "        -1.1031e-02,  2.4011e-02,  3.0607e-02,  5.7830e-02,  1.5247e-02,\n",
      "         1.1134e-02,  9.4899e-03,  1.3221e-02,  2.1193e-02, -2.9595e-02,\n",
      "         3.7517e-02, -4.6198e-03, -1.5468e-02,  4.3401e-02, -5.0242e-02,\n",
      "        -5.2939e-02, -3.9681e-02,  3.3939e-02, -5.9586e-02,  4.8389e-02,\n",
      "        -3.7891e-02,  5.3974e-02, -1.0636e-02, -3.9370e-02,  3.6034e-02,\n",
      "         3.4096e-02, -3.5566e-02,  1.3121e-03, -1.0373e-02,  2.5673e-02,\n",
      "         1.4465e-02, -3.1178e-02,  3.5308e-02, -8.7093e-04, -2.6059e-02,\n",
      "         3.2084e-03,  2.4028e-02, -2.7653e-02,  3.1894e-02,  2.9318e-02,\n",
      "         4.4896e-03, -2.0955e-02,  1.2963e-02,  5.7245e-02, -2.5008e-02,\n",
      "        -9.1568e-03,  3.6758e-02,  2.0097e-02,  2.5239e-03,  5.0697e-02,\n",
      "         1.9011e-02,  2.3937e-02, -3.0826e-02,  4.3288e-02, -4.0273e-02,\n",
      "         4.8493e-02, -4.3153e-02,  8.2187e-03, -1.1992e-03, -2.2667e-05,\n",
      "         2.3132e-02,  1.1465e-02, -2.0871e-02,  3.9434e-02, -2.1138e-02,\n",
      "         1.8794e-02,  2.5497e-02, -4.8465e-02, -3.6615e-02,  6.6349e-03,\n",
      "         1.9947e-02, -1.4457e-02, -2.0678e-02, -3.7063e-03, -2.3512e-02,\n",
      "         2.2026e-02, -5.1362e-02, -1.2784e-02,  2.4554e-02, -1.4636e-02,\n",
      "         3.3555e-02, -4.3682e-02,  2.0005e-02,  5.4139e-03, -7.9541e-05,\n",
      "        -4.7175e-04, -7.5733e-04, -2.2188e-02, -2.7191e-02, -5.1850e-02,\n",
      "         3.7659e-02,  1.3433e-02, -3.9354e-02, -4.7683e-03,  4.7698e-02,\n",
      "        -1.6527e-02,  1.7140e-02, -1.4127e-02,  3.2012e-02,  1.5884e-02,\n",
      "        -1.4768e-02, -1.6106e-02, -2.0528e-02,  1.5159e-02,  4.1012e-02,\n",
      "         4.4284e-02,  2.3008e-02, -1.0525e-02, -1.6093e-02,  2.1710e-02,\n",
      "         3.8063e-02,  9.4442e-03, -3.1594e-02,  2.6958e-02,  4.3609e-02,\n",
      "        -4.8717e-02,  1.9377e-02, -1.9219e-02, -3.3844e-02,  2.3552e-02,\n",
      "         4.9860e-02, -8.8357e-03,  1.7193e-02, -1.0392e-02,  2.8667e-02,\n",
      "         2.9674e-03,  2.9649e-02,  3.9344e-02,  2.5416e-02, -3.6247e-02,\n",
      "         4.6232e-02, -4.1418e-02,  4.2872e-02,  2.3886e-02, -2.1044e-02,\n",
      "        -3.5315e-02, -4.9971e-02,  2.4759e-02, -1.0523e-02,  7.5356e-03,\n",
      "        -6.2046e-03,  7.4426e-03, -2.1337e-02,  1.6276e-02,  4.3693e-02,\n",
      "        -5.8519e-02,  4.0733e-04, -3.9004e-02, -3.0133e-02,  2.2652e-02,\n",
      "        -2.9505e-02,  3.3932e-02, -1.4946e-02, -4.9984e-02,  5.5584e-02,\n",
      "         3.1609e-02, -1.9322e-02,  1.4366e-02,  3.2286e-02, -2.8626e-02,\n",
      "        -1.2435e-02, -3.2684e-02, -8.5393e-04, -3.2752e-03, -4.4524e-02,\n",
      "        -3.1177e-02,  1.5154e-02, -2.8354e-02, -3.1052e-02, -2.9250e-02,\n",
      "         3.9960e-02, -2.1924e-02, -4.7692e-03,  1.4593e-02, -2.9804e-02,\n",
      "        -4.2485e-02,  3.0653e-02,  1.6405e-02, -1.0364e-03,  2.1243e-02,\n",
      "        -2.6063e-02, -1.8512e-02,  2.7624e-02,  1.2227e-03,  2.3279e-02,\n",
      "         1.7095e-02,  6.6924e-03, -1.7933e-02, -1.4404e-02, -5.2667e-02,\n",
      "        -1.9239e-02,  3.1751e-02, -2.1331e-02, -3.1792e-02, -1.5674e-02,\n",
      "        -2.5079e-02,  2.7822e-02,  1.9049e-02,  5.2549e-02,  2.2989e-03,\n",
      "         1.5950e-02,  2.8459e-02, -6.5415e-03,  9.9432e-03,  7.8364e-03,\n",
      "        -2.7597e-02, -2.1788e-03, -2.9320e-02, -1.2453e-02, -3.4285e-02,\n",
      "         2.7964e-02, -2.7949e-02,  1.0523e-02,  3.4110e-02, -6.9722e-03,\n",
      "         5.2284e-02,  5.0011e-02, -1.3240e-02,  2.5235e-03, -3.7836e-02,\n",
      "         6.2883e-02,  3.0810e-02, -2.3930e-02, -4.0251e-02, -4.3547e-02,\n",
      "        -2.0661e-02,  1.8590e-02, -3.1541e-02, -2.3763e-02,  3.7031e-02,\n",
      "        -4.7758e-04,  1.1589e-02, -3.5156e-02,  3.7552e-02,  1.3053e-02,\n",
      "         1.8118e-02,  2.3851e-02,  3.6719e-02,  5.5832e-03, -4.0000e-02,\n",
      "        -4.0511e-02, -2.0531e-02], requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0083, -0.0290,  0.0223,  ...,  0.0403,  0.0090,  0.0361],\n",
      "        [-0.0300,  0.0415,  0.0186,  ...,  0.0205, -0.0057, -0.0167],\n",
      "        [ 0.0421,  0.0112, -0.0440,  ...,  0.0057,  0.0310,  0.0297],\n",
      "        ...,\n",
      "        [-0.0272, -0.0386,  0.0283,  ..., -0.0341,  0.0328, -0.0359],\n",
      "        [-0.0274,  0.0337,  0.0124,  ...,  0.0007,  0.0036, -0.0382],\n",
      "        [ 0.0020, -0.0164,  0.0432,  ...,  0.0195, -0.0168,  0.0258]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-0.0039,  0.0019, -0.0039,  ...,  0.0013,  0.0064, -0.0295],\n",
      "        [-0.0150, -0.0022,  0.0099,  ...,  0.0015, -0.0190,  0.0115],\n",
      "        [ 0.0118,  0.0085,  0.0138,  ..., -0.0032,  0.0067,  0.0063],\n",
      "        ...,\n",
      "        [ 0.0042, -0.0073,  0.0056,  ...,  0.0021, -0.0132, -0.0036],\n",
      "        [ 0.0087,  0.0155,  0.0003,  ...,  0.0036,  0.0052, -0.0199],\n",
      "        [-0.0001,  0.0052,  0.0049,  ...,  0.0058, -0.0004, -0.0071]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0123, -0.0270,  0.0184,  ...,  0.0416,  0.0153,  0.0067],\n",
      "        [-0.0450,  0.0394,  0.0285,  ...,  0.0219, -0.0247, -0.0052],\n",
      "        [ 0.0538,  0.0197, -0.0302,  ...,  0.0025,  0.0377,  0.0361],\n",
      "        ...,\n",
      "        [-0.0230, -0.0460,  0.0339,  ..., -0.0319,  0.0196, -0.0394],\n",
      "        [-0.0187,  0.0493,  0.0127,  ...,  0.0043,  0.0088, -0.0580],\n",
      "        [ 0.0019, -0.0112,  0.0481,  ...,  0.0253, -0.0172,  0.0186]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 0.0364,  0.0227, -0.0362,  0.0319, -0.0298, -0.0338, -0.0397,  0.0186,\n",
      "         0.0067,  0.0196, -0.0311,  0.0008,  0.0231, -0.0305, -0.0333,  0.0080,\n",
      "        -0.0287, -0.0111, -0.0014,  0.0160], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-5.8623e-03, -1.4531e-02, -1.1643e-02, -1.5247e-02, -1.1439e-02,\n",
      "        -8.9786e-03,  1.2911e-02,  7.5486e-03, -1.8950e-03, -1.5397e-02,\n",
      "         1.6371e-02, -1.3932e-03, -4.9872e-03, -2.8092e-02, -2.0035e-03,\n",
      "        -9.6777e-03, -6.5202e-05,  5.4156e-03,  1.7174e-02, -5.5983e-03])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([ 0.0305,  0.0081, -0.0479,  0.0166, -0.0413, -0.0428, -0.0268,  0.0261,\n",
      "         0.0049,  0.0042, -0.0147, -0.0006,  0.0181, -0.0586, -0.0353, -0.0017,\n",
      "        -0.0288, -0.0057,  0.0158,  0.0104], requires_grad=True)\n",
      "\n",
      "-=-=--=-=--=-=-=-=\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-42c02dc5487f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodification_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hle_test/lib/python3.7/site-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        #self.conv1 = nn.Conv2d(2, 2, 13)\n",
    "        #self.conv2 = nn.Conv2d(2, 2, 1)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(658, 512)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 20)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (1, 1))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        #x = F.max_pool2d(F.relu(self.conv2(x)), 1)\n",
    "        #x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \"\"\"\n",
    "    def foward2(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \"\"\"\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "initial_seed = torch.random.seed()\n",
    "net = Net()\n",
    "# print(net)\n",
    "# print(net.parameters())\n",
    "# flattened = []\n",
    "# total = 0\n",
    "# for p in net.parameters():\n",
    "#     print(p)\n",
    "# #     print(p)\n",
    "# #     print(p.shape)\n",
    "#     f = torch.flatten(p)\n",
    "#     print(f.shape)\n",
    "#     length = len(f)\n",
    "#     print(length)\n",
    "#     total += length\n",
    "#     for i in range(length):\n",
    "#         flattened.append(f[i].item())\n",
    "# #     print(f)\n",
    "# #     flattened.append(list(f))\n",
    "# # print(net.parameters().shape)\n",
    "# # print(total)\n",
    "# # print(flattened[0])\n",
    "# # noise = torch.empty(total).normal_(mean=0,std=0.1)\n",
    "# print(noise[0])\n",
    "\n",
    "modification_seed = torch.random.seed()\n",
    "flattened = []\n",
    "with torch.no_grad():\n",
    "    for p in net.parameters():\n",
    "        print(\"Starting weights:\")\n",
    "        print(p)\n",
    "        s = p.shape\n",
    "        print(\"Noise vector:\")\n",
    "        noise = torch.empty(s).normal_(mean=0,std=0.01)\n",
    "        print(noise)\n",
    "        p += noise\n",
    "        print(\"New weights:\")\n",
    "        print(p)\n",
    "#     print(f)\n",
    "#     flattened.append(list(f))\n",
    "# print(net.parameters().shape)\n",
    "# print(total)\n",
    "# print(flattened[0])\n",
    "# noise = torch.empty(t\n",
    "\n",
    "print()\n",
    "print(\"-=-=--=-=--=-=-=-=\")\n",
    "print()\n",
    "\n",
    "\n",
    "torch.random.manual_seed(initial_seed)\n",
    "net = Net()\n",
    "\n",
    "torch.random.manual_seed(modification_seed)\n",
    "with torch.no_grad():\n",
    "    for p in net.parameters():\n",
    "        print(\"Starting weights:\")\n",
    "        print(p)\n",
    "        s = p.shape\n",
    "        print(\"Noise vector:\")\n",
    "        noise = torch.empty(s).normal_(mean=0,std=0.01)\n",
    "        print(noise)\n",
    "        p += noise\n",
    "        print(\"New weights:\")\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_tensor(mylist):\n",
    "    encoded_observations = np.array(mylist).reshape(1,658)\n",
    "    tensor_observations = torch.FloatTensor(encoded_observations)\n",
    "    return tensor_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_encoded_observations = get_encoded_observations(obs_encoder, state, 0)\n",
    "#encoded_observations = np.array(list_encoded_observations).reshape(1,658)\n",
    "#tensor_observations = torch.FloatTensor(encoded_observations)\n",
    "#net(tensor_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = tensor_observations\n",
    "#out = net(input)\n",
    "#print(out)\n",
    "#net.zero_grad()\n",
    "#out.backward(torch.randn(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def make_action(array):\\n        index = np.rgmax(array)\\n        return index\\n\\n\\n    def get_weights():\\n        #Pytorch code to get an array with all the weights of the network\\n        weights  = [] #np.zeros()\\n\\n    def set_wegiths(weights):\\n        #Pytorch code to set the weigths\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PytorchAgent:\n",
    "\n",
    "    def __init__(self,game,seeds=[],mutation_sd=0.01):\n",
    "        self.mutation_sd = mutation_sd\n",
    "        if not seeds:\n",
    "            initial_seed = self.make_torch_seed()\n",
    "            self.seeds=[initial_seed]\n",
    "        else:\n",
    "            self.seeds = seeds\n",
    "        for i,s in enumerate(self.seeds):\n",
    "            if i==0:\n",
    "                torch.random.manual_seed(s)\n",
    "                self.net = Net()\n",
    "            else:\n",
    "                self.mutate(mutation_sd,s)\n",
    "        self.game = game\n",
    "        self.obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "        self.fitness=0.0\n",
    "\n",
    "    def act(self, state):\n",
    "        with torch.no_grad():\n",
    "            encoded_observations = get_encoded_observations(self.obs_encoder, state, state.cur_player())\n",
    "            input_tensor = list_to_tensor(encoded_observations)\n",
    "            output_tensor = self.net(input_tensor)\n",
    "            weight = output_tensor.tolist()[0]#weight of 20 possible moves\n",
    "            rank = sorted(range(len(weight)), key=lambda k: weight[k]) # rank of 20 possible moves in weight\n",
    "            index = sorted(range(len(rank)), key=lambda k: rank[k]) # index of sorted rank of 20 possible moves\n",
    "            observation = state.observation(state.cur_player())# need to make sure whether observation = state works\n",
    "            for i in index:\n",
    "#                 print(\"checking move:\" + str(self.game.get_move(i)))\n",
    "                if str(self.game.get_move(i)) in str(observation.legal_moves()):# Is there a way of not using str?\n",
    "#                     print(\"valid\")\n",
    "                    return self.game.get_move(i)\n",
    "#                 else:\n",
    "#                     print(\"invalid, checking next possible move in priority list\")\n",
    "        #here you probably need to check if it is a valid action\n",
    "        # There's a code in the HLE that gets the legal actions from a state (a \"mask\")\n",
    "        # you can do mask*model.forward()\n",
    "        # This will multiply all ILLEGAL actions by zero\n",
    "    \n",
    "    # If seed is none, create a new seed and append to self.seeds. Otherwise, just use the given seed, but not append\n",
    "    def mutate(self,sd=0.01,seed=None):\n",
    "        if seed is None:\n",
    "            seed = self.make_torch_seed()\n",
    "            self.seeds.append(seed)\n",
    "        with torch.no_grad():\n",
    "            torch.random.manual_seed(seed)\n",
    "            for p in net.parameters():\n",
    "                shape = p.shape\n",
    "                noise = torch.empty(shape).normal_(mean=0.0,std=sd)\n",
    "                p += noise\n",
    "    \n",
    "    def make_torch_seed(self):\n",
    "        while True:\n",
    "            seed = torch.random.seed()\n",
    "            if seed < 2**63:\n",
    "                return seed\n",
    "        \n",
    "\"\"\"\n",
    "    def make_action(array):\n",
    "        index = np.rgmax(array)\n",
    "        return index\n",
    "\n",
    "\n",
    "    def get_weights():\n",
    "        #Pytorch code to get an array with all the weights of the network\n",
    "        weights  = [] #np.zeros()\n",
    "\n",
    "    def set_wegiths(weights):\n",
    "        #Pytorch code to set the weigths\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_parameters = {\"players\": 2, \"random_start_player\": True}\n",
    "game = pyhanabi.HanabiGame(game_parameters)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "state = game.new_initial_state()\n",
    "\n",
    "pyagent = PytorchAgent(game)\n",
    "\n",
    "population_size = 5\n",
    "num_games = 5\n",
    "num_generations = 500\n",
    "# one run of game\n",
    "score=0\n",
    "\n",
    "# population = [PytorchAgent(game) for p in range(population_size)]\n",
    "\n",
    "    \n",
    "while not state.is_terminal():\n",
    "    if state.score() >=score:\n",
    "        score = state.score()\n",
    "    if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:\n",
    "        state.deal_random_card()\n",
    "        continue\n",
    "\n",
    "    #print_state(state)\n",
    "\n",
    "    #observation = state.observation(state.cur_player())\n",
    "    #print_observation(observation)\n",
    "    #print(observation.legal_moves())\n",
    "    #print_encoded_observations(obs_encoder, state, game.num_players())\n",
    "    #encoded_observations = get_encoded_observations(obs_encoder, state, state.cur_player())\n",
    "    #mytensor = list_to_tensor(encoded_observations)\n",
    "    #legal_moves = state.legal_moves()\n",
    "    # print(\"\")\n",
    "    # print(\"Number of legal moves: {}\".format(len(legal_moves)))\n",
    "    current_life_token = state.life_tokens()\n",
    "    current_fireworks = state.fireworks()\n",
    "    move  = pyagent.act(state)\n",
    "    # move = np.random.choice(legal_moves)\n",
    "    # print(\"Chose random legal move: {}\".format(move))\n",
    "\n",
    "    state.apply_move(move)\n",
    "print(\"game finished\")\n",
    "print(state.fireworks())\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_start_player=true\n",
      "seed=877116702\n",
      "max_life_tokens=3\n",
      "hand_size=5\n",
      "observation_type=1\n",
      "max_information_tokens=8\n",
      "ranks=5\n",
      "colors=5\n",
      "players=2\n",
      "<__main__.PytorchAgent object at 0x7f8217a68fd0>\n",
      "Population Size is \n",
      "1928\n",
      "130143\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "Time 22:11:37. Best of generation 0 has fitness 1.8\n",
      "0\n",
      "Population Size is \n",
      "2352\n",
      "130143\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "1328\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 658])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512, 512])\n",
      " 200\n",
      " 512\n",
      " torch.Size([512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20, 512])\n",
      " 200\n",
      " 20\n",
      " torch.Size([20])\n",
      "Time 22:11:38. Best of generation 1 has fitness 1.6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "def play_game(game_parameters,agent):\n",
    "    game = pyhanabi.HanabiGame(game_parameters)\n",
    "    obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "    state = game.new_initial_state()\n",
    "    score=0\n",
    "    \n",
    "    while not state.is_terminal():\n",
    "        if state.score() >=score:\n",
    "            score = state.score()\n",
    "        if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:\n",
    "            state.deal_random_card()\n",
    "            continue\n",
    "\n",
    "\n",
    "        current_life_token = state.life_tokens()\n",
    "        current_fireworks = state.fireworks()\n",
    "        move  = agent.act(state)\n",
    "\n",
    "        state.apply_move(move)\n",
    "    return score\n",
    "\n",
    "game_parameters = {\"players\": 2, \"random_start_player\": True}\n",
    "game = pyhanabi.HanabiGame(game_parameters)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "\n",
    "# pyagent = PytorchAgent(game)\n",
    "\n",
    "population_size = 10\n",
    "num_games = 5\n",
    "num_generations = 2\n",
    "# one run of game\n",
    "\n",
    "population = [PytorchAgent(game) for p in range(population_size)]\n",
    "print(population[0])\n",
    "\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    # Evaluate each agent\n",
    "    for agent in population:\n",
    "        total_score = 0.0\n",
    "        for g in range(num_games):\n",
    "            score = play_game(game_parameters,agent)\n",
    "            total_score+=score\n",
    "#             print(\"Gen {} game {} had score {}\".format((gen,g,score)))\n",
    "        agent.fitness = float(total_score)/float(num_games)\n",
    "    \n",
    "    # Sort by fitness\n",
    "    population.sort(key = lambda x: x.fitness, reverse=True)\n",
    "    \n",
    "    # Create new population by discarding the bottom half, duplicating the top half, then mutating one of the copies\n",
    "    for i, a in enumerate(population):\n",
    "        if i >= population_size/2:\n",
    "            parent_index = i - population_size/2\n",
    "            parent_seeds = population[i].seeds\n",
    "            child = PytorchAgent(game,parent_seeds)\n",
    "            child.mutate()\n",
    "        else:\n",
    "            agent.mutate()\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print (\"Population Size is \".format(get_size([x.seeds for x in population])))\n",
    "    print(get_size([x.seeds for x in population]))\n",
    "    print(get_size([x.net for x in population]))\n",
    "    for p in population:\n",
    "        n = p.net\n",
    "        print(get_size(n.parameters()))\n",
    "        for param in n.parameters():\n",
    "            print(\" \" + str(get_size(param)))\n",
    "            print(\" \" + str(len(param)))\n",
    "            print(\" \" +str(param.shape))\n",
    "#             print(param)\n",
    "    print('Time {}. Best of generation {} has fitness {}'.format(current_time,gen, population[0].fitness))\n",
    "    cmd = 'ps -o pid,user,%mem,command -p ' + str(os.getpid())\n",
    "    print(os.system(cmd))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'is_terminal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b74cbe644526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrl_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hanabi-Full'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_players\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpyhanabi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHANCE_PLAYER_ID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal_random_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'is_terminal'"
     ]
    }
   ],
   "source": [
    "environment = rl_env.make('Hanabi-Full', num_players=2)\n",
    "state = environment.reset()\n",
    "while not state.is_terminal():\n",
    "    if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:  \n",
    "        state.deal_random_card()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(get_encoded_observations(obs_encoder, state, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_observations = torch.FloatTensor(get_encoded_observations(obs_encoder, state, 0))\n",
    "net(tensor_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net(tensor_observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_value = net(tensor_observations).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_value.index(max(move_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_observations(encoder, state, player_num):\n",
    "    codes = encoder.encode(state.observation(player_num))\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.cur_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_observations = get_encoded_observations(obs_encoder, state, state.cur_player())\n",
    "mytensor = list_to_tensor(encoded_observations)\n",
    "legal_moves = state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.new_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.life_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.fireworks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = rl_env.make('Hanabi-Full', num_players=2)\n",
    "state = environment.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = environment.reset()\n",
    "type(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = pyhanabi.HanabiGame()\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hle_test)",
   "language": "python",
   "name": "hle_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
