{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhanabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "#import checkpointer\n",
    "#import iteration_statistics\n",
    "#import dqn_agent\n",
    "#import gin.tf\n",
    "import rl_env\n",
    "import numpy as np\n",
    "#import rainbow_agent\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "import rl_env\n",
    "#import run_paired_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cma\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_encoded_observations(encoder, state, num_players):\n",
    "    print(\"--- EncodedObservations ---\")\n",
    "    print(\"Observation encoding shape: {}\".format(encoder.shape()))\n",
    "    print(\"Current actual player: {}\".format(state.cur_player()))\n",
    "    for i in range(num_players):\n",
    "      print(\"Encoded observation for player {}: {}\".format(\n",
    "          i, encoder.encode(state.observation(i))))\n",
    "    print(\"--- EndEncodedObservations ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_observations(encoder, state, player_num):\n",
    "    codes = encoder.encode(state.observation(player_num))\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_observation(observation):\n",
    "    \"\"\"Print some basic information about an agent observation.\"\"\"\n",
    "    print(\"--- Observation ---\")\n",
    "    print(observation)\n",
    "\n",
    "    print(\"### Information about the observation retrieved separately ###\")\n",
    "    print(\"### Current player, relative to self: {}\".format(\n",
    "        observation.cur_player_offset()))\n",
    "    print(\"### Observed hands: {}\".format(observation.observed_hands()))\n",
    "    print(\"### Card knowledge: {}\".format(observation.card_knowledge()))\n",
    "    print(\"### Discard pile: {}\".format(observation.discard_pile()))\n",
    "    print(\"### Fireworks: {}\".format(observation.fireworks()))\n",
    "    print(\"### Deck size: {}\".format(observation.deck_size()))\n",
    "    move_string = \"### Last moves:\"\n",
    "    for move_tuple in observation.last_moves():\n",
    "      move_string += \" {}\".format(move_tuple)\n",
    "    print(move_string)\n",
    "    print(\"### Information tokens: {}\".format(observation.information_tokens()))\n",
    "    print(\"### Life tokens: {}\".format(observation.life_tokens()))\n",
    "    print(\"### Legal moves: {}\".format(observation.legal_moves()))\n",
    "    print(\"--- EndObservation ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state(state):\n",
    "    \"\"\"Print some basic information about the state.\"\"\"\n",
    "    print(\"\")\n",
    "    print(\"Current player: {}\".format(state.cur_player()))\n",
    "    print(state)\n",
    "\n",
    "    # Example of more queries to provide more about this state. For\n",
    "    # example, bots could use these methods to to get information\n",
    "    # about the state in order to act accordingly.\n",
    "    print(\"### Information about the state retrieved separately ###\")\n",
    "    print(\"### Information tokens: {}\".format(state.information_tokens()))\n",
    "    print(\"### Life tokens: {}\".format(state.life_tokens()))\n",
    "    print(\"### Fireworks: {}\".format(state.fireworks()))\n",
    "    print(\"### Deck size: {}\".format(state.deck_size()))\n",
    "    print(\"### Discard pile: {}\".format(str(state.discard_pile())))\n",
    "    print(\"### Player hands: {}\".format(str(state.player_hands())))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from rl_env import Agent\n",
    "\n",
    "\n",
    "class RandomAgent():\n",
    "    def act(self, observation):\n",
    "        \"\"\"Act based on an observation.\"\"\"\n",
    "        return random.choice(observation.legal_moves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = RandomAgent()\n",
    "agent = RandomAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0237,  0.0330,  0.0011,  ..., -0.0103, -0.0133,  0.0004],\n",
      "        [ 0.0122, -0.0131, -0.0356,  ..., -0.0039, -0.0022,  0.0201],\n",
      "        [-0.0022,  0.0086,  0.0279,  ...,  0.0361,  0.0166,  0.0304],\n",
      "        ...,\n",
      "        [-0.0092,  0.0322, -0.0241,  ...,  0.0096, -0.0103, -0.0087],\n",
      "        [ 0.0180, -0.0312,  0.0187,  ...,  0.0127, -0.0182, -0.0193],\n",
      "        [ 0.0059, -0.0143,  0.0309,  ..., -0.0328, -0.0028,  0.0095]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-6.9450e-03, -1.5235e-02,  7.9131e-03,  ...,  5.8520e-04,\n",
      "         -2.9831e-03,  1.2100e-02],\n",
      "        [-4.7380e-03, -1.2625e-02, -4.0337e-03,  ..., -8.0156e-03,\n",
      "         -9.6245e-03, -3.4100e-02],\n",
      "        [-1.7643e-02,  9.3007e-03,  4.7756e-03,  ..., -1.1302e-02,\n",
      "          1.8555e-02, -8.3201e-03],\n",
      "        ...,\n",
      "        [-4.0443e-03,  1.9675e-02, -2.2734e-03,  ...,  8.8859e-05,\n",
      "         -7.3026e-03, -1.3819e-02],\n",
      "        [-1.1535e-02, -8.8894e-03,  3.8106e-03,  ...,  2.2996e-03,\n",
      "         -3.7596e-03, -4.7373e-03],\n",
      "        [-4.0853e-03,  3.2619e-03, -1.2322e-02,  ..., -6.7489e-03,\n",
      "         -2.5484e-03, -1.4917e-02]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0307,  0.0178,  0.0091,  ..., -0.0097, -0.0162,  0.0125],\n",
      "        [ 0.0075, -0.0258, -0.0397,  ..., -0.0119, -0.0118, -0.0140],\n",
      "        [-0.0199,  0.0179,  0.0327,  ...,  0.0248,  0.0352,  0.0221],\n",
      "        ...,\n",
      "        [-0.0132,  0.0519, -0.0263,  ...,  0.0097, -0.0176, -0.0225],\n",
      "        [ 0.0065, -0.0401,  0.0225,  ...,  0.0150, -0.0219, -0.0240],\n",
      "        [ 0.0018, -0.0110,  0.0185,  ..., -0.0395, -0.0054, -0.0054]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 1.4571e-03,  1.1684e-02, -3.8857e-02,  2.9334e-02, -6.2060e-03,\n",
      "        -3.4289e-02, -6.7285e-03, -6.8867e-04,  1.6934e-02, -2.6735e-02,\n",
      "         3.7517e-02, -2.3452e-03, -2.7403e-02, -3.4110e-02, -1.8014e-02,\n",
      "         2.5064e-02, -2.5537e-02,  1.9997e-02,  3.0967e-02, -3.6368e-02,\n",
      "         2.2660e-02,  4.6121e-03, -1.1069e-02, -1.5624e-02, -3.3749e-02,\n",
      "        -1.3260e-02, -2.4256e-02,  1.9954e-02, -1.7542e-05, -1.0559e-02,\n",
      "        -1.1213e-02, -1.1453e-02,  1.6367e-02,  2.1198e-02,  1.1284e-03,\n",
      "         3.7197e-02, -9.3022e-03,  1.4402e-02,  3.3086e-02,  8.5421e-03,\n",
      "         3.5334e-02,  2.9502e-02,  1.6194e-02,  1.7928e-02, -1.3915e-03,\n",
      "         1.5302e-02,  2.2160e-02,  3.6018e-02, -8.1769e-03, -5.6960e-03,\n",
      "         2.9585e-03,  3.7638e-02,  1.5351e-02, -8.9441e-03,  2.7402e-02,\n",
      "        -1.8595e-02, -2.0317e-02,  3.5040e-02, -5.9367e-03, -6.9274e-03,\n",
      "         3.5066e-02,  3.8832e-02,  7.1674e-03, -2.8892e-02, -2.3911e-04,\n",
      "        -1.6917e-02,  1.4326e-03, -3.2044e-02,  3.4049e-02,  1.4486e-02,\n",
      "         3.7020e-02,  2.8834e-02,  3.2684e-02,  3.3040e-02, -3.8595e-02,\n",
      "         9.6827e-03, -2.6530e-02, -2.9896e-02,  3.3155e-02,  2.0235e-02,\n",
      "        -1.7612e-03,  3.2209e-02, -2.0574e-02,  2.8615e-02, -8.0915e-03,\n",
      "        -3.8118e-02,  2.0253e-02,  2.9917e-02,  6.8485e-03, -3.5090e-02,\n",
      "        -3.0203e-02,  3.3730e-02, -1.7943e-02,  1.8563e-02, -9.6757e-03,\n",
      "         3.0422e-02, -4.4059e-03,  1.2409e-03, -3.3327e-02,  5.5343e-03,\n",
      "         2.5810e-02, -6.9683e-03,  3.6685e-03, -7.0255e-03,  5.1465e-03,\n",
      "         3.8821e-02,  2.1756e-02, -1.4698e-02, -3.5446e-02,  3.2396e-02,\n",
      "         1.1817e-02,  7.7849e-03, -2.7352e-02,  4.1374e-03, -1.3594e-02,\n",
      "        -1.6798e-02, -6.7917e-03,  8.3877e-03,  9.8587e-03,  3.2074e-02,\n",
      "        -8.9440e-03, -2.3392e-03,  2.6278e-02,  2.0269e-02,  1.6744e-02,\n",
      "         3.1335e-02,  8.1335e-03,  2.7808e-02,  1.4456e-03, -3.3154e-02,\n",
      "         2.3118e-02,  1.6762e-02, -7.0150e-03,  9.8606e-03, -8.9108e-03,\n",
      "        -3.8956e-02,  7.8683e-03, -1.3213e-02, -1.6484e-02,  3.4098e-02,\n",
      "         1.1488e-02, -3.8148e-02,  1.4759e-03, -2.6582e-02,  2.4588e-02,\n",
      "         2.1772e-02,  6.2725e-03, -5.3579e-03, -1.0166e-02, -2.9309e-02,\n",
      "        -2.8315e-02,  3.6946e-02, -3.7893e-02, -1.3912e-02, -1.9292e-02,\n",
      "        -9.6151e-03,  2.4518e-02,  3.5562e-02,  7.8660e-03, -3.7495e-02,\n",
      "         7.3393e-04, -3.4352e-02, -8.7969e-03, -2.4277e-02,  1.9034e-02,\n",
      "        -2.7110e-02, -2.2756e-02, -3.7485e-02, -8.2565e-03,  2.2849e-02,\n",
      "        -1.7151e-02, -5.2879e-03, -6.8706e-03,  2.3662e-02,  3.5863e-02,\n",
      "         2.3423e-02,  3.5643e-02, -8.7756e-03,  2.6861e-02, -3.1757e-02,\n",
      "        -1.4479e-02, -2.4921e-02, -3.2665e-02,  3.6715e-02,  3.8092e-02,\n",
      "         2.6592e-02, -2.3045e-02, -1.3125e-02, -2.0620e-02,  1.4741e-02,\n",
      "        -1.1799e-02, -3.6147e-02, -2.5327e-02, -2.8753e-02,  1.2979e-02,\n",
      "         5.3173e-03,  4.7098e-04,  4.2693e-03,  2.6522e-02, -6.5600e-03,\n",
      "        -6.7684e-03,  2.0532e-02, -2.1859e-02,  2.7751e-02, -2.6313e-02,\n",
      "         1.5291e-03,  2.0610e-02,  1.5425e-02,  3.4220e-02,  3.2498e-02,\n",
      "         1.5894e-02, -6.0629e-03, -5.1480e-03,  9.4265e-03,  3.5316e-02,\n",
      "         3.6757e-02, -3.7167e-02,  2.0367e-02, -6.6226e-03,  3.4510e-02,\n",
      "        -1.1818e-02, -6.1173e-03, -3.1749e-03, -5.8222e-03, -1.4810e-02,\n",
      "         2.8528e-02, -1.8888e-02,  3.0698e-02, -1.0448e-03, -3.6000e-02,\n",
      "        -4.6840e-03,  1.8991e-02,  3.8744e-02, -3.4495e-02, -2.0517e-02,\n",
      "         3.2326e-02,  3.5672e-02, -1.2081e-04, -2.6008e-02, -3.0411e-02,\n",
      "         2.9481e-02, -1.7474e-02, -3.2692e-02, -3.4238e-02,  2.8788e-03,\n",
      "         3.7244e-02, -3.4609e-02, -1.2371e-02,  1.5141e-03, -1.6092e-02,\n",
      "        -8.1480e-03, -3.0328e-02,  1.3933e-02, -1.0273e-02,  1.0707e-02,\n",
      "        -1.9585e-02,  9.5513e-03,  1.3151e-02, -2.1412e-02,  2.7904e-03,\n",
      "         1.6369e-02,  1.6870e-02,  7.8642e-04, -2.3142e-02, -2.4443e-02,\n",
      "        -2.0125e-02, -2.0154e-02, -8.3954e-03,  2.7365e-02,  1.0690e-02,\n",
      "        -3.1045e-02,  1.6936e-02, -2.8512e-02,  2.1698e-02, -3.7575e-02,\n",
      "         3.2819e-02,  2.8948e-02,  1.8256e-02,  2.1402e-02, -2.7563e-02,\n",
      "         1.5661e-02,  2.6004e-02,  1.2394e-02,  2.6827e-02,  1.8998e-02,\n",
      "         1.9704e-02,  2.7396e-02, -3.2965e-02,  3.2533e-02,  2.8293e-02,\n",
      "        -1.5777e-02,  1.7515e-02, -1.4723e-03,  2.9369e-02, -3.6859e-03,\n",
      "         5.2858e-03,  3.0932e-02,  1.5453e-02, -9.8144e-03, -1.1886e-02,\n",
      "        -1.9144e-02,  3.2152e-02, -6.2120e-03, -3.8366e-02, -3.6939e-02,\n",
      "        -1.9181e-02, -6.4661e-03,  2.9435e-02, -3.0361e-03,  1.6529e-02,\n",
      "        -1.4904e-02,  2.4634e-02, -2.7325e-02,  3.7867e-03,  3.2370e-02,\n",
      "         2.4900e-02,  3.0786e-02,  1.1282e-02,  1.9384e-03,  7.3841e-03,\n",
      "        -3.0563e-02,  3.5182e-02,  1.5647e-02,  2.8511e-02,  2.5765e-02,\n",
      "        -2.0721e-02,  1.5137e-03, -1.1284e-02,  7.5310e-03,  2.8101e-02,\n",
      "        -2.7613e-03,  2.3584e-02, -7.2293e-03, -3.1197e-02, -2.2043e-02,\n",
      "        -3.1045e-02,  3.6183e-02,  3.2057e-02, -3.0002e-02,  3.5192e-02,\n",
      "        -2.1292e-02, -1.1934e-02, -2.9852e-02,  3.3393e-02, -3.8200e-02,\n",
      "        -1.3218e-02, -4.3538e-03, -1.4784e-02, -3.6752e-02, -2.4578e-02,\n",
      "        -2.6851e-02,  4.9061e-04,  3.1533e-02,  3.0373e-02,  2.6182e-02,\n",
      "        -7.9565e-03, -1.4107e-03,  3.3654e-02, -2.8924e-02, -3.6976e-02,\n",
      "        -1.8107e-02, -3.7313e-02,  1.5869e-02,  3.8480e-02, -3.5929e-03,\n",
      "        -1.8379e-02, -3.5804e-02, -3.6142e-02, -3.6785e-02,  2.6272e-02,\n",
      "        -2.4973e-02,  1.4348e-02,  3.2389e-02,  8.6544e-03, -1.4133e-02,\n",
      "        -1.9423e-02, -3.2586e-02, -8.7981e-03,  1.0895e-02, -3.1677e-02,\n",
      "         1.7550e-02,  1.9677e-02, -2.8887e-02,  3.7921e-02, -1.1766e-03,\n",
      "         2.0060e-03, -3.8185e-02,  1.8992e-02,  3.2566e-02, -2.5864e-02,\n",
      "         2.7789e-02, -3.9563e-03, -3.3637e-02, -1.2958e-02, -2.1043e-02,\n",
      "        -3.7858e-02, -3.6980e-02,  2.9362e-02,  1.9331e-02, -1.4183e-02,\n",
      "        -9.4486e-03, -3.0543e-02, -1.0440e-03,  3.1642e-04, -1.1405e-02,\n",
      "         2.6600e-02, -7.9407e-03, -2.6569e-03, -1.2312e-02,  3.8205e-02,\n",
      "         1.9867e-02,  2.1921e-02, -2.4014e-02, -7.3649e-03, -2.8424e-02,\n",
      "         3.1908e-02,  3.7638e-02,  1.4550e-02, -1.7576e-02,  3.4383e-02,\n",
      "         1.2100e-02,  3.0224e-02, -3.0940e-02,  7.2482e-03,  2.7033e-02,\n",
      "        -2.6471e-02,  1.9347e-03,  3.2925e-02,  2.3547e-02, -1.5555e-02,\n",
      "        -9.6623e-03,  3.5168e-02, -2.9409e-02,  2.5546e-03,  1.4394e-02,\n",
      "        -2.8313e-02, -8.6241e-03, -4.3118e-03,  2.7051e-02, -7.2241e-03,\n",
      "        -5.7323e-03,  2.1308e-02, -2.0617e-02,  2.6948e-02,  3.1984e-02,\n",
      "         2.9144e-02, -5.2679e-03,  3.2862e-02,  1.1702e-02, -4.1077e-03,\n",
      "         1.1755e-02, -1.6000e-03,  3.0699e-02, -6.8979e-03, -2.8545e-02,\n",
      "        -2.3657e-02,  2.4432e-02, -1.4326e-02, -2.6972e-02,  3.5352e-02,\n",
      "        -5.2632e-03, -1.9127e-02,  3.8247e-02,  3.4663e-02,  2.2454e-02,\n",
      "         4.4059e-03, -1.5464e-02, -1.8327e-02,  3.7175e-02,  3.3885e-02,\n",
      "         5.0164e-04, -1.0695e-02,  1.5839e-04, -1.8559e-02, -2.3635e-02,\n",
      "        -7.0284e-03,  4.2829e-03, -8.4636e-03,  3.0330e-02,  1.5265e-02,\n",
      "        -2.2874e-02, -3.8837e-02,  1.0833e-02,  5.7237e-03, -1.0686e-03,\n",
      "        -3.3613e-02,  6.6540e-03,  5.2062e-04,  7.8705e-04, -3.7904e-02,\n",
      "         3.2579e-02,  3.6961e-02, -4.9433e-03,  1.5531e-02,  1.2470e-02,\n",
      "         1.5924e-02, -1.0553e-02,  1.5584e-02, -2.8804e-03,  9.0822e-03,\n",
      "         1.5495e-02, -2.7027e-02, -4.9973e-03, -3.1711e-02,  2.8531e-02,\n",
      "         3.8918e-02, -2.2507e-02, -4.4569e-04,  2.9319e-02,  1.5214e-02,\n",
      "        -1.2954e-02, -2.2043e-02], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([ 1.3756e-03,  4.5980e-03,  3.7939e-03, -7.7852e-03, -2.9017e-02,\n",
      "        -5.0885e-03,  2.6817e-03, -1.1545e-02,  9.1310e-03,  2.6894e-04,\n",
      "        -2.0248e-03,  1.4292e-02,  1.0658e-02, -1.1142e-02,  1.0970e-02,\n",
      "        -2.9865e-02, -1.3215e-04, -7.2958e-03,  2.5216e-03,  1.3389e-02,\n",
      "        -8.6078e-03,  4.4483e-03, -1.2849e-02, -1.7043e-02,  5.9887e-03,\n",
      "        -4.0135e-04,  7.2116e-03, -1.5255e-02,  1.7212e-02,  8.2829e-03,\n",
      "        -6.4154e-03,  6.6331e-03,  3.7897e-03,  4.3633e-03, -1.9940e-03,\n",
      "         8.2459e-03, -4.7338e-03,  2.3757e-03,  1.7429e-02,  1.0271e-02,\n",
      "        -1.7144e-02,  1.7814e-02,  3.6619e-03,  1.1447e-02,  5.6813e-03,\n",
      "        -9.9218e-03, -2.2244e-03, -1.1186e-02, -6.9574e-04,  4.1303e-04,\n",
      "         2.0049e-04,  1.3755e-02, -4.8303e-03,  6.3960e-03,  3.4718e-03,\n",
      "         3.5030e-03,  1.9888e-02, -3.3125e-03, -1.0956e-02, -2.7062e-03,\n",
      "        -4.8036e-03, -1.3163e-03, -6.2852e-03,  3.3790e-03,  9.2314e-03,\n",
      "        -7.6379e-03,  4.7978e-04,  5.0958e-04, -9.4145e-03,  6.6897e-03,\n",
      "        -1.4597e-02,  1.0469e-03,  1.2936e-03, -9.7737e-03, -7.3141e-03,\n",
      "        -1.5414e-02, -3.6087e-03, -6.5920e-04,  1.3151e-02, -9.9478e-03,\n",
      "        -7.3275e-03,  1.2504e-02, -7.6946e-03,  1.3283e-02, -1.0671e-02,\n",
      "         1.2209e-02,  1.7037e-02,  5.1712e-03,  7.8425e-03,  1.5781e-02,\n",
      "        -4.5259e-03, -8.6143e-03,  2.4449e-03,  6.4312e-03,  6.5307e-04,\n",
      "         4.7031e-03,  9.2378e-03,  8.7347e-03, -5.8932e-03,  9.7473e-03,\n",
      "         1.3078e-02, -8.7109e-03, -3.6882e-03, -6.3338e-03, -8.6626e-03,\n",
      "        -1.9532e-02, -6.7671e-03, -1.1646e-03,  9.2732e-03,  5.1876e-03,\n",
      "         1.4779e-02, -4.5229e-03,  1.5193e-02, -6.4572e-03,  9.2608e-03,\n",
      "         4.2099e-03, -1.3354e-02,  7.2486e-04,  7.5352e-03,  1.0637e-02,\n",
      "        -6.8742e-03,  1.8080e-04, -1.4124e-02, -2.7005e-02, -1.1439e-03,\n",
      "         4.5324e-03, -1.3483e-03, -2.7482e-04,  1.5721e-02,  4.6999e-03,\n",
      "        -1.8872e-02, -1.4368e-02, -6.6304e-03, -4.8475e-03, -2.1009e-03,\n",
      "        -2.0282e-03,  4.6125e-03,  2.7568e-03,  1.8711e-02, -3.8878e-03,\n",
      "        -5.5949e-03,  6.1709e-03, -1.7629e-04,  7.9636e-03, -1.0925e-03,\n",
      "        -9.4803e-03,  4.7735e-03, -1.7004e-02,  2.6822e-03, -1.6082e-02,\n",
      "         6.9655e-04, -6.6807e-03, -3.3717e-03,  3.3341e-03, -4.9031e-03,\n",
      "         1.2405e-02,  1.2290e-02,  6.1091e-03,  2.0004e-03, -6.6514e-03,\n",
      "         1.3450e-02, -8.3270e-03,  5.2614e-04,  1.2172e-02,  3.1023e-03,\n",
      "         5.5393e-03,  3.6749e-03, -1.7585e-03, -1.7010e-02,  1.4439e-02,\n",
      "        -8.2672e-03,  1.7275e-02,  2.1586e-02,  2.0659e-03, -1.3273e-02,\n",
      "         6.3444e-04,  7.9875e-04,  7.6130e-03,  9.0971e-03,  4.5349e-03,\n",
      "        -2.5006e-02, -1.0572e-02, -1.2278e-02, -5.9347e-03,  1.5485e-02,\n",
      "         2.4611e-05,  2.7648e-03,  2.3263e-02,  9.6942e-03,  6.7697e-03,\n",
      "        -3.2376e-03,  8.4708e-03,  1.8460e-02, -5.4294e-03, -1.2090e-02,\n",
      "        -1.4446e-02,  7.5866e-03, -1.5262e-02, -3.9133e-03,  5.6630e-06,\n",
      "        -2.1710e-02, -1.6363e-02, -9.4190e-03, -2.8888e-03,  2.5601e-03,\n",
      "         2.0032e-02,  3.2686e-04, -3.6120e-03,  1.4501e-02, -2.9411e-04,\n",
      "         4.7887e-03, -1.1688e-02, -1.4112e-02, -4.2028e-04,  4.9677e-03,\n",
      "        -1.2596e-02,  2.7944e-03,  2.2219e-03, -1.2704e-02,  3.2860e-03,\n",
      "        -1.2941e-02,  1.5051e-02, -8.6751e-04, -3.3978e-03, -9.9226e-03,\n",
      "        -9.1325e-03,  2.0988e-02,  4.7109e-03, -1.8081e-02, -1.2897e-02,\n",
      "         1.2575e-02,  1.4689e-02,  1.5492e-02,  1.2262e-02, -5.5283e-03,\n",
      "        -5.5364e-03, -1.5830e-02,  1.6568e-02,  1.1355e-03,  6.1227e-03,\n",
      "         1.9933e-02, -7.0474e-03, -2.1556e-02,  3.9277e-03,  5.3284e-03,\n",
      "         2.7237e-03,  2.2262e-02,  7.6524e-03, -6.7685e-03,  1.0869e-02,\n",
      "         7.5673e-03, -1.7315e-02, -1.5649e-02, -1.6377e-02, -7.9618e-03,\n",
      "         6.3545e-03,  5.6248e-03, -4.3374e-03, -8.6163e-03, -1.3172e-02,\n",
      "         1.2636e-02, -5.6533e-03,  7.0212e-03,  1.4185e-03,  7.2842e-03,\n",
      "         3.4398e-03, -1.3096e-02,  2.8731e-02,  2.0616e-02,  4.2801e-03,\n",
      "        -5.0921e-03,  3.7159e-03, -1.4754e-02,  1.4969e-03, -9.0508e-03,\n",
      "        -1.1804e-02, -5.0232e-03, -8.7564e-03, -1.3130e-02,  1.5509e-04,\n",
      "        -1.9099e-02,  2.2287e-02, -4.7164e-03, -1.8580e-02,  5.8539e-03,\n",
      "         3.1258e-03,  2.4087e-03, -6.1456e-03,  5.7259e-03, -8.4998e-03,\n",
      "         1.7903e-02, -3.2003e-03, -2.5270e-03, -2.1600e-04,  4.9163e-03,\n",
      "        -1.1786e-02, -2.3726e-02,  2.8819e-03,  2.0056e-02,  3.0026e-03,\n",
      "        -1.6474e-02, -6.9542e-03, -1.2488e-02, -1.2529e-03, -4.3140e-03,\n",
      "        -1.0952e-02, -2.1896e-03, -1.1665e-03,  6.5304e-03, -5.2160e-03,\n",
      "        -3.0441e-03, -6.7796e-04,  4.8638e-03, -9.7320e-03,  2.1937e-03,\n",
      "         3.6599e-03,  1.0293e-02,  1.0463e-02,  1.2214e-02, -3.2601e-03,\n",
      "        -7.8037e-03, -1.4387e-04,  2.0345e-03,  1.5863e-03,  2.5695e-04,\n",
      "        -1.3131e-03,  2.1318e-02,  1.7182e-02, -5.6016e-03,  1.4623e-03,\n",
      "         3.8618e-03, -9.5211e-04,  4.1350e-03, -1.5097e-02,  9.8272e-03,\n",
      "         1.7362e-03, -1.1587e-02, -1.1056e-03, -8.4922e-03,  1.2754e-02,\n",
      "         9.2804e-03,  1.6959e-03,  1.3848e-05,  1.1562e-02,  5.9863e-03,\n",
      "         1.1847e-02,  5.2445e-03, -3.5612e-03,  3.5237e-03, -2.0480e-03,\n",
      "        -5.7033e-03, -7.4311e-04,  2.0860e-02,  5.0558e-03,  2.0161e-03,\n",
      "        -1.9004e-02, -1.1196e-02, -6.7252e-03,  6.3655e-03, -8.2520e-03,\n",
      "         1.0743e-03,  1.2309e-02, -4.2580e-03, -1.3702e-02,  1.3638e-02,\n",
      "        -8.3788e-03,  1.0235e-02,  1.8045e-02, -1.1404e-02,  1.4663e-03,\n",
      "        -1.2612e-02,  9.4091e-03,  5.7276e-03, -8.6437e-03,  1.2601e-02,\n",
      "        -1.1762e-02, -1.7485e-03, -5.8983e-04, -5.1840e-04, -2.3854e-03,\n",
      "         6.6445e-03,  8.6396e-03,  9.1490e-04, -2.4505e-04, -1.5182e-02,\n",
      "         1.0518e-02,  4.6545e-03,  1.5831e-02, -2.6951e-03,  6.6276e-03,\n",
      "        -5.1613e-03,  1.3043e-02, -9.0022e-03, -1.0642e-03,  3.5260e-03,\n",
      "        -1.0193e-02, -4.1392e-04,  8.9487e-03,  9.3289e-03, -7.2074e-04,\n",
      "        -2.6457e-03,  1.8598e-02, -3.7450e-03,  6.4516e-03,  1.3395e-02,\n",
      "         1.8443e-02, -1.8461e-03, -8.4578e-03, -8.5973e-03,  9.7397e-03,\n",
      "         5.5342e-03,  2.4492e-04, -1.5290e-03,  2.1028e-03, -2.5354e-02,\n",
      "        -4.5134e-03,  6.1939e-03,  1.3692e-02,  6.6651e-03, -5.7240e-03,\n",
      "         8.0324e-03, -3.4757e-03,  9.4426e-03,  1.1328e-02,  1.4528e-03,\n",
      "        -9.5513e-03,  7.1822e-03, -1.5834e-02, -1.3168e-02, -4.2019e-03,\n",
      "         1.2132e-03,  4.4838e-03,  3.3253e-02, -5.1936e-03, -1.7752e-03,\n",
      "         1.0582e-02, -9.7605e-03, -4.8069e-03,  7.0964e-03,  1.0870e-02,\n",
      "        -9.9008e-03, -9.4823e-03,  8.6945e-03, -5.0422e-03, -5.1706e-03,\n",
      "         1.1931e-02, -1.5109e-03, -8.7206e-03,  9.4777e-03,  5.5644e-03,\n",
      "        -1.3789e-03, -4.6685e-03, -1.1708e-02,  2.2404e-03,  1.0185e-02,\n",
      "         1.0037e-02,  1.4631e-02, -1.0703e-02,  5.6274e-03,  5.2927e-03,\n",
      "         1.0777e-02,  4.9653e-03,  5.7371e-03, -2.4969e-03,  1.4468e-02,\n",
      "         2.1741e-03,  1.6891e-02,  3.4537e-03, -3.2461e-04,  6.4839e-03,\n",
      "        -1.5457e-02, -1.3739e-02, -1.1395e-03, -5.9542e-03,  6.0757e-03,\n",
      "        -8.9562e-03, -2.2373e-03, -1.0634e-02,  1.4199e-02,  8.6078e-03,\n",
      "         1.9000e-02,  2.6321e-02, -5.2902e-05,  5.6217e-03,  1.2591e-02,\n",
      "         1.4976e-03, -3.7548e-03, -4.4439e-03, -6.9233e-03, -1.5766e-02,\n",
      "        -3.5464e-03, -6.1605e-04, -8.8010e-03, -1.0624e-02, -7.4810e-03,\n",
      "         1.1899e-04, -2.6282e-03, -5.1321e-03,  9.6723e-03, -2.3658e-03,\n",
      "        -4.3910e-03, -5.4853e-03,  1.1061e-02,  1.0877e-02,  1.1033e-03,\n",
      "        -6.9018e-03, -9.2911e-03, -1.8048e-03, -8.3012e-04,  9.7170e-04,\n",
      "        -1.9952e-02,  2.2040e-02])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([ 2.8326e-03,  1.6282e-02, -3.5063e-02,  2.1549e-02, -3.5223e-02,\n",
      "        -3.9377e-02, -4.0469e-03, -1.2234e-02,  2.6065e-02, -2.6467e-02,\n",
      "         3.5492e-02,  1.1947e-02, -1.6745e-02, -4.5252e-02, -7.0436e-03,\n",
      "        -4.8011e-03, -2.5669e-02,  1.2701e-02,  3.3489e-02, -2.2979e-02,\n",
      "         1.4052e-02,  9.0604e-03, -2.3918e-02, -3.2667e-02, -2.7760e-02,\n",
      "        -1.3661e-02, -1.7044e-02,  4.6985e-03,  1.7195e-02, -2.2758e-03,\n",
      "        -1.7628e-02, -4.8197e-03,  2.0157e-02,  2.5561e-02, -8.6561e-04,\n",
      "         4.5443e-02, -1.4036e-02,  1.6777e-02,  5.0515e-02,  1.8813e-02,\n",
      "         1.8190e-02,  4.7316e-02,  1.9855e-02,  2.9375e-02,  4.2898e-03,\n",
      "         5.3798e-03,  1.9936e-02,  2.4832e-02, -8.8726e-03, -5.2830e-03,\n",
      "         3.1590e-03,  5.1393e-02,  1.0521e-02, -2.5480e-03,  3.0874e-02,\n",
      "        -1.5092e-02, -4.2839e-04,  3.1727e-02, -1.6892e-02, -9.6336e-03,\n",
      "         3.0262e-02,  3.7516e-02,  8.8216e-04, -2.5513e-02,  8.9923e-03,\n",
      "        -2.4555e-02,  1.9124e-03, -3.1534e-02,  2.4635e-02,  2.1176e-02,\n",
      "         2.2422e-02,  2.9881e-02,  3.3978e-02,  2.3266e-02, -4.5909e-02,\n",
      "        -5.7317e-03, -3.0138e-02, -3.0555e-02,  4.6306e-02,  1.0288e-02,\n",
      "        -9.0887e-03,  4.4713e-02, -2.8268e-02,  4.1899e-02, -1.8763e-02,\n",
      "        -2.5909e-02,  3.7290e-02,  3.5088e-02,  1.4691e-02, -1.9308e-02,\n",
      "        -3.4729e-02,  2.5116e-02, -1.5499e-02,  2.4994e-02, -9.0227e-03,\n",
      "         3.5125e-02,  4.8319e-03,  9.9756e-03, -3.9220e-02,  1.5282e-02,\n",
      "         3.8888e-02, -1.5679e-02, -1.9715e-05, -1.3359e-02, -3.5161e-03,\n",
      "         1.9289e-02,  1.4989e-02, -1.5863e-02, -2.6173e-02,  3.7583e-02,\n",
      "         2.6596e-02,  3.2620e-03, -1.2159e-02, -2.3198e-03, -4.3327e-03,\n",
      "        -1.2588e-02, -2.0146e-02,  9.1125e-03,  1.7394e-02,  4.2711e-02,\n",
      "        -1.5818e-02, -2.1584e-03,  1.2154e-02, -6.7357e-03,  1.5600e-02,\n",
      "         3.5868e-02,  6.7852e-03,  2.7534e-02,  1.7167e-02, -2.8454e-02,\n",
      "         4.2461e-03,  2.3943e-03, -1.3645e-02,  5.0132e-03, -1.1012e-02,\n",
      "        -4.0984e-02,  1.2481e-02, -1.0457e-02,  2.2268e-03,  3.0210e-02,\n",
      "         5.8935e-03, -3.1977e-02,  1.2996e-03, -1.8619e-02,  2.3495e-02,\n",
      "         1.2292e-02,  1.1046e-02, -2.2362e-02, -7.4839e-03, -4.5390e-02,\n",
      "        -2.7619e-02,  3.0266e-02, -4.1265e-02, -1.0577e-02, -2.4195e-02,\n",
      "         2.7895e-03,  3.6808e-02,  4.1671e-02,  9.8665e-03, -4.4147e-02,\n",
      "         1.4184e-02, -4.2679e-02, -8.2708e-03, -1.2105e-02,  2.2137e-02,\n",
      "        -2.1570e-02, -1.9081e-02, -3.9243e-02, -2.5266e-02,  3.7287e-02,\n",
      "        -2.5418e-02,  1.1988e-02,  1.4715e-02,  2.5728e-02,  2.2590e-02,\n",
      "         2.4057e-02,  3.6441e-02, -1.1626e-03,  3.5958e-02, -2.7222e-02,\n",
      "        -3.9485e-02, -3.5493e-02, -4.4943e-02,  3.0780e-02,  5.3577e-02,\n",
      "         2.6617e-02, -2.0280e-02,  1.0139e-02, -1.0926e-02,  2.1511e-02,\n",
      "        -1.5037e-02, -2.7676e-02, -6.8667e-03, -3.4182e-02,  8.8875e-04,\n",
      "        -9.1288e-03,  8.0576e-03, -1.0993e-02,  2.2609e-02, -6.5543e-03,\n",
      "        -2.8478e-02,  4.1690e-03, -3.1278e-02,  2.4862e-02, -2.3753e-02,\n",
      "         2.1561e-02,  2.0937e-02,  1.1813e-02,  4.8721e-02,  3.2204e-02,\n",
      "         2.0682e-02, -1.7751e-02, -1.9260e-02,  9.0063e-03,  4.0283e-02,\n",
      "         2.4161e-02, -3.4372e-02,  2.2588e-02, -1.9326e-02,  3.7796e-02,\n",
      "        -2.4759e-02,  8.9333e-03, -4.0424e-03, -9.2200e-03, -2.4733e-02,\n",
      "         1.9396e-02,  2.1005e-03,  3.5409e-02, -1.9126e-02, -4.8897e-02,\n",
      "         7.8915e-03,  3.3680e-02,  5.4237e-02, -2.2233e-02, -2.6046e-02,\n",
      "         2.6790e-02,  1.9842e-02,  1.6447e-02, -2.4872e-02, -2.4288e-02,\n",
      "         4.9414e-02, -2.4521e-02, -5.4249e-02, -3.0311e-02,  8.2073e-03,\n",
      "         3.9967e-02, -1.2347e-02, -4.7190e-03, -5.2544e-03, -5.2228e-03,\n",
      "        -5.8067e-04, -4.7642e-02, -1.7162e-03, -2.6650e-02,  2.7451e-03,\n",
      "        -1.3231e-02,  1.5176e-02,  8.8132e-03, -3.0028e-02, -1.0381e-02,\n",
      "         2.9005e-02,  1.1217e-02,  7.8077e-03, -2.1724e-02, -1.7159e-02,\n",
      "        -1.6685e-02, -3.3250e-02,  2.0336e-02,  4.7981e-02,  1.4970e-02,\n",
      "        -3.6137e-02,  2.0652e-02, -4.3266e-02,  2.3194e-02, -4.6626e-02,\n",
      "         2.1015e-02,  2.3925e-02,  9.4993e-03,  8.2727e-03, -2.7408e-02,\n",
      "        -3.4376e-03,  4.8291e-02,  7.6780e-03,  8.2472e-03,  2.4852e-02,\n",
      "         2.2830e-02,  2.9805e-02, -3.9110e-02,  3.8259e-02,  1.9793e-02,\n",
      "         2.1260e-03,  1.4314e-02, -3.9993e-03,  2.9153e-02,  1.2304e-03,\n",
      "        -6.5003e-03,  7.2057e-03,  1.8335e-02,  1.0242e-02, -8.8837e-03,\n",
      "        -3.5618e-02,  2.5198e-02, -1.8700e-02, -3.9618e-02, -4.1253e-02,\n",
      "        -3.0133e-02, -8.6557e-03,  2.8269e-02,  3.4943e-03,  1.1313e-02,\n",
      "        -1.7948e-02,  2.3956e-02, -2.2462e-02, -5.9453e-03,  3.4564e-02,\n",
      "         2.8560e-02,  4.1079e-02,  2.1745e-02,  1.4152e-02,  4.1239e-03,\n",
      "        -3.8367e-02,  3.5038e-02,  1.7682e-02,  3.0097e-02,  2.6022e-02,\n",
      "        -2.2034e-02,  2.2832e-02,  5.8986e-03,  1.9294e-03,  2.9563e-02,\n",
      "         1.1005e-03,  2.2632e-02, -3.0943e-03, -4.6293e-02, -1.2216e-02,\n",
      "        -2.9309e-02,  2.4596e-02,  3.0951e-02, -3.8494e-02,  4.7946e-02,\n",
      "        -1.2011e-02, -1.0238e-02, -2.9838e-02,  4.4956e-02, -3.2213e-02,\n",
      "        -1.3716e-03,  8.9070e-04, -1.8345e-02, -3.3228e-02, -2.6626e-02,\n",
      "        -3.2554e-02, -2.5251e-04,  5.2393e-02,  3.5429e-02,  2.8199e-02,\n",
      "        -2.6960e-02, -1.2606e-02,  2.6929e-02, -2.2559e-02, -4.5228e-02,\n",
      "        -1.7033e-02, -2.5003e-02,  1.1611e-02,  2.4778e-02,  1.0045e-02,\n",
      "        -2.6757e-02, -2.5569e-02, -1.8097e-02, -4.8189e-02,  2.7739e-02,\n",
      "        -3.7584e-02,  2.3757e-02,  3.8116e-02,  1.0706e-05, -1.5323e-03,\n",
      "        -3.1185e-02, -3.4334e-02, -9.3880e-03,  1.0377e-02, -3.4063e-02,\n",
      "         2.4195e-02,  2.8317e-02, -2.7972e-02,  3.7676e-02, -1.6359e-02,\n",
      "         1.2524e-02, -3.3531e-02,  3.4823e-02,  2.9871e-02, -1.9236e-02,\n",
      "         2.2627e-02,  9.0868e-03, -4.2639e-02, -1.4022e-02, -1.7517e-02,\n",
      "        -4.8051e-02, -3.7394e-02,  3.8310e-02,  2.8660e-02, -1.4904e-02,\n",
      "        -1.2094e-02, -1.1946e-02, -4.7889e-03,  6.7680e-03,  1.9902e-03,\n",
      "         4.5043e-02, -9.7869e-03, -1.1115e-02, -2.0910e-02,  4.7945e-02,\n",
      "         2.5402e-02,  2.2166e-02, -2.5543e-02, -5.2621e-03, -5.3778e-02,\n",
      "         2.7395e-02,  4.3832e-02,  2.8242e-02, -1.0911e-02,  2.8659e-02,\n",
      "         2.0132e-02,  2.6748e-02, -2.1498e-02,  1.8577e-02,  2.8485e-02,\n",
      "        -3.6022e-02,  9.1169e-03,  1.7091e-02,  1.0379e-02, -1.9757e-02,\n",
      "        -8.4492e-03,  3.9652e-02,  3.8444e-03, -2.6390e-03,  1.2619e-02,\n",
      "        -1.7731e-02, -1.8385e-02, -9.1187e-03,  3.4148e-02,  3.6455e-03,\n",
      "        -1.5633e-02,  1.1826e-02, -1.1923e-02,  2.1906e-02,  2.6813e-02,\n",
      "         4.1076e-02, -6.7788e-03,  2.4142e-02,  2.1180e-02,  1.4567e-03,\n",
      "         1.0376e-02, -6.2684e-03,  1.8990e-02, -4.6574e-03, -1.8360e-02,\n",
      "        -1.3620e-02,  3.9064e-02, -2.5028e-02, -2.1345e-02,  4.0645e-02,\n",
      "         5.5141e-03, -1.4162e-02,  4.3984e-02,  3.2166e-02,  3.6922e-02,\n",
      "         6.5800e-03,  1.4273e-03, -1.4874e-02,  3.6850e-02,  4.0369e-02,\n",
      "        -1.4955e-02, -2.4434e-02, -9.8112e-04, -2.4513e-02, -1.7560e-02,\n",
      "        -1.5985e-02,  2.0456e-03, -1.9098e-02,  4.4529e-02,  2.3873e-02,\n",
      "        -3.8739e-03, -1.2516e-02,  1.0780e-02,  1.1345e-02,  1.1523e-02,\n",
      "        -3.2115e-02,  2.8992e-03, -3.9232e-03, -6.1363e-03, -5.3670e-02,\n",
      "         2.9033e-02,  3.6345e-02, -1.3744e-02,  4.9068e-03,  4.9889e-03,\n",
      "         1.6043e-02, -1.3181e-02,  1.0452e-02,  6.7919e-03,  6.7164e-03,\n",
      "         1.1104e-02, -3.2513e-02,  6.0641e-03, -2.0834e-02,  2.9634e-02,\n",
      "         3.2016e-02, -3.1798e-02, -2.2505e-03,  2.8489e-02,  1.6186e-02,\n",
      "        -3.2905e-02, -2.6748e-06], requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0148,  0.0114, -0.0197,  ...,  0.0010,  0.0338,  0.0139],\n",
      "        [ 0.0428, -0.0345,  0.0342,  ...,  0.0346,  0.0287, -0.0220],\n",
      "        [ 0.0225, -0.0067, -0.0218,  ...,  0.0053,  0.0110, -0.0384],\n",
      "        ...,\n",
      "        [-0.0072, -0.0198, -0.0143,  ...,  0.0149,  0.0295, -0.0083],\n",
      "        [ 0.0199, -0.0114,  0.0175,  ..., -0.0113,  0.0049, -0.0151],\n",
      "        [ 0.0036, -0.0304, -0.0033,  ..., -0.0056, -0.0103,  0.0053]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[ 1.2290e-02, -6.2292e-03,  9.1716e-03,  ..., -5.1260e-03,\n",
      "         -5.6997e-03,  4.5875e-03],\n",
      "        [ 7.4701e-03,  3.9868e-03,  1.1375e-02,  ...,  7.5561e-03,\n",
      "          6.1507e-03,  1.1122e-02],\n",
      "        [ 1.0998e-02, -1.8261e-04,  7.9098e-03,  ...,  8.0186e-03,\n",
      "          1.1379e-02,  3.3129e-03],\n",
      "        ...,\n",
      "        [-5.8144e-03,  1.3903e-02,  1.1906e-02,  ..., -2.7491e-03,\n",
      "          8.2212e-03, -1.1837e-02],\n",
      "        [ 9.9062e-05, -4.5853e-03,  7.1749e-03,  ...,  8.9042e-03,\n",
      "         -2.6395e-03,  4.0757e-04],\n",
      "        [-1.2613e-02,  1.8211e-02, -1.4346e-02,  ...,  7.0519e-03,\n",
      "          2.1033e-03,  1.4051e-02]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0271,  0.0052, -0.0105,  ..., -0.0041,  0.0281,  0.0185],\n",
      "        [ 0.0502, -0.0305,  0.0456,  ...,  0.0422,  0.0349, -0.0109],\n",
      "        [ 0.0335, -0.0068, -0.0139,  ...,  0.0133,  0.0223, -0.0351],\n",
      "        ...,\n",
      "        [-0.0130, -0.0059, -0.0024,  ...,  0.0122,  0.0377, -0.0201],\n",
      "        [ 0.0200, -0.0160,  0.0247,  ..., -0.0024,  0.0023, -0.0147],\n",
      "        [-0.0090, -0.0122, -0.0176,  ...,  0.0014, -0.0082,  0.0194]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([-2.3110e-03, -2.2152e-02, -4.2151e-02, -4.5219e-03, -3.1903e-02,\n",
      "         3.8496e-02, -4.2331e-02,  3.2062e-02,  3.9434e-02, -1.3171e-02,\n",
      "         2.3233e-02, -3.4327e-02, -4.3136e-02,  3.1547e-02, -4.3385e-02,\n",
      "         6.7574e-03, -2.1125e-02, -7.6257e-03, -1.9210e-02,  2.2512e-02,\n",
      "         2.1574e-02, -2.7331e-02,  4.3234e-03, -1.8093e-02,  2.2732e-02,\n",
      "         6.9188e-03, -3.7806e-02,  3.8168e-02,  2.8024e-02,  2.7842e-02,\n",
      "        -2.4073e-02,  1.2967e-02,  3.6976e-02,  3.3667e-02,  3.3057e-02,\n",
      "         2.3536e-02,  3.2421e-02,  3.4973e-02, -3.7080e-02,  2.7840e-02,\n",
      "         1.4861e-02, -4.0111e-02,  4.6334e-03,  3.7245e-03,  3.2610e-02,\n",
      "        -1.1343e-02,  9.5095e-03, -3.8244e-02,  3.8141e-02, -1.4368e-02,\n",
      "         3.3763e-03,  3.1123e-02,  4.2963e-03,  2.0443e-02,  2.5653e-02,\n",
      "        -2.9140e-02,  4.3071e-02,  4.0890e-02,  1.4306e-03,  3.5296e-02,\n",
      "        -3.5188e-02,  3.7752e-02,  3.7622e-02, -1.2839e-02, -3.1442e-02,\n",
      "        -3.7296e-02, -1.2358e-02,  2.1210e-02, -4.0592e-02,  1.1544e-02,\n",
      "         8.3779e-03, -2.1804e-02,  6.1654e-03, -2.8752e-02,  3.5605e-02,\n",
      "        -4.1349e-02, -1.5618e-02, -4.3712e-02,  2.2316e-02,  3.3237e-02,\n",
      "         4.4232e-03,  1.4047e-02,  2.7647e-02,  3.1642e-03,  3.6826e-02,\n",
      "        -2.7797e-02,  1.4323e-02, -2.2076e-02,  2.9357e-02, -2.9001e-02,\n",
      "        -9.8856e-03, -3.9912e-02,  1.1689e-02,  3.1883e-02, -1.3127e-02,\n",
      "        -3.3048e-03, -3.3814e-02, -3.3640e-02,  2.4671e-02,  2.1776e-02,\n",
      "         4.0167e-02,  1.2311e-02, -1.8178e-02, -2.2499e-02, -4.0705e-02,\n",
      "         2.8795e-02,  2.9661e-02, -2.0108e-02, -2.0250e-02, -3.6668e-02,\n",
      "         1.6906e-02, -1.5461e-02,  3.0585e-02,  1.0208e-02,  1.2272e-02,\n",
      "         1.8137e-02, -1.8865e-02, -2.1350e-02, -2.2413e-02, -1.6889e-02,\n",
      "        -3.4664e-02,  1.6065e-02,  6.3364e-03, -2.7918e-02, -3.4431e-02,\n",
      "        -3.1114e-02,  2.8800e-02,  9.0763e-03,  4.3893e-02, -3.2179e-02,\n",
      "        -2.4082e-03,  2.4892e-02, -3.1575e-02, -2.8637e-02, -3.3726e-02,\n",
      "         2.3406e-02,  2.0021e-02,  1.5421e-03,  5.1370e-03,  2.3193e-02,\n",
      "         5.5115e-04, -2.0712e-02, -1.9701e-02, -1.9276e-02,  1.8791e-02,\n",
      "        -1.2437e-02, -3.6326e-02, -3.9551e-02, -3.7846e-02,  2.5430e-02,\n",
      "         1.6842e-02,  5.6047e-03, -3.7565e-02,  2.2751e-03, -1.9804e-02,\n",
      "         3.1429e-02,  4.2871e-02,  3.4917e-02, -2.7287e-02, -3.6810e-02,\n",
      "         2.1696e-02, -4.3770e-02,  3.7510e-02, -3.9176e-02, -2.3527e-02,\n",
      "         4.2994e-02,  6.6103e-04,  3.0909e-02, -1.4175e-02, -7.5400e-03,\n",
      "        -2.9423e-03,  3.6074e-02,  8.2198e-03,  4.2137e-03,  3.0217e-02,\n",
      "        -8.0932e-03, -3.4565e-02, -1.5988e-02,  3.0663e-02,  9.3310e-03,\n",
      "         4.2280e-02,  2.5618e-02, -2.7833e-04, -3.1210e-02, -8.6770e-03,\n",
      "        -2.7846e-03, -2.0624e-02, -8.8608e-03,  6.2175e-03,  9.3229e-03,\n",
      "         2.7212e-03,  1.9900e-02,  2.7173e-02,  3.4707e-02,  1.1092e-02,\n",
      "        -2.2299e-02,  4.2578e-02,  2.0201e-02,  1.1639e-02,  1.9279e-02,\n",
      "        -3.3360e-03, -2.2639e-02, -4.1536e-02, -3.6597e-02,  2.7271e-02,\n",
      "         3.1030e-02,  2.5291e-02, -4.3356e-02, -2.2788e-02,  4.2864e-02,\n",
      "        -7.9348e-03, -4.1875e-02, -3.4436e-02, -2.8929e-02,  3.0318e-02,\n",
      "         2.2318e-02, -6.6685e-03, -3.9210e-02,  2.6148e-02, -6.8037e-03,\n",
      "        -3.4742e-02, -4.3949e-04, -2.8148e-02, -1.4924e-02, -3.6652e-02,\n",
      "        -4.7820e-03, -2.9244e-02,  3.6177e-02,  1.3816e-02, -2.9005e-02,\n",
      "         2.7126e-02,  3.1881e-02, -7.4301e-03,  2.9892e-02,  2.6165e-02,\n",
      "        -4.1293e-02, -2.1694e-02, -2.1115e-02, -2.2222e-02, -2.9044e-02,\n",
      "        -4.3523e-03, -1.3720e-02, -1.0214e-02,  2.1727e-02,  3.4501e-02,\n",
      "        -8.8264e-03, -2.1596e-02, -1.0249e-02,  1.1572e-02,  4.2560e-02,\n",
      "        -2.8301e-02, -1.0354e-02, -2.0836e-02,  3.2973e-02,  2.4796e-02,\n",
      "        -2.5101e-02,  3.3008e-02,  2.3140e-02,  2.0137e-02, -5.0133e-04,\n",
      "        -1.9634e-02,  2.5857e-02,  2.7455e-02,  1.5513e-02, -2.5218e-02,\n",
      "        -4.2360e-02,  2.5091e-02,  3.8525e-02, -1.3773e-02, -4.3822e-02,\n",
      "        -2.3402e-02,  2.1905e-03, -3.6238e-02,  7.8094e-03, -4.3302e-02,\n",
      "         8.9599e-04,  3.2957e-02,  2.5707e-02, -7.1383e-03,  5.8512e-03,\n",
      "        -3.0659e-02,  4.2457e-02,  1.2190e-02,  3.7365e-02,  2.3884e-03,\n",
      "        -2.7132e-02, -2.7480e-02, -3.1944e-02,  1.8174e-02,  3.9271e-02,\n",
      "         9.7127e-03,  1.5035e-02,  2.4630e-02,  1.6610e-02,  1.0694e-02,\n",
      "         1.1113e-02,  3.7152e-02, -2.0087e-02, -4.4597e-03,  3.0296e-02,\n",
      "         5.6993e-03, -6.6627e-03, -3.2959e-02,  3.5097e-02,  2.8812e-02,\n",
      "         1.4047e-02,  3.3363e-02, -2.2690e-03, -4.2945e-02,  2.3362e-02,\n",
      "         1.5180e-02, -3.6406e-02, -1.5457e-02, -3.0849e-02,  3.0491e-02,\n",
      "        -1.2179e-02,  3.4432e-02,  4.0712e-02,  1.2296e-02,  3.8691e-02,\n",
      "        -1.3819e-02, -6.7344e-03,  1.1187e-02,  1.0893e-02,  2.6435e-02,\n",
      "        -1.6253e-02,  2.0707e-02,  1.2016e-02, -3.7187e-02, -1.8240e-02,\n",
      "         4.4166e-02,  3.1312e-02, -3.0330e-02, -4.2743e-02,  3.5034e-02,\n",
      "        -3.1387e-02,  4.7061e-03,  3.5348e-02,  2.5487e-02, -3.4396e-02,\n",
      "         1.1623e-02,  2.2045e-02,  2.5656e-02, -3.7086e-02,  2.3761e-02,\n",
      "         3.7160e-02,  3.0463e-04, -3.8455e-02,  7.7859e-04,  1.6942e-02,\n",
      "        -8.4760e-03, -1.4306e-02,  1.7397e-02, -2.9711e-02,  1.9434e-02,\n",
      "        -1.5405e-02,  1.2726e-02,  4.0154e-02, -3.0825e-02, -2.0231e-02,\n",
      "        -6.3531e-03, -3.1207e-02, -3.5547e-02,  1.6951e-02, -3.4679e-02,\n",
      "        -2.0874e-02,  2.2021e-02, -2.6197e-02,  1.8164e-02,  7.8212e-05,\n",
      "        -1.1453e-02, -1.7341e-02,  2.9454e-03,  3.9100e-02, -7.3047e-03,\n",
      "         2.0297e-02, -2.7312e-03, -2.8234e-02, -3.8446e-02, -1.7412e-02,\n",
      "        -4.8346e-03, -1.0013e-03,  2.3399e-02,  3.2043e-02, -2.6433e-02,\n",
      "        -3.3625e-02, -1.2329e-03, -2.5628e-02, -1.6798e-02,  1.3280e-02,\n",
      "        -4.2454e-02, -2.7790e-03, -3.0306e-02, -2.5130e-02,  4.0749e-02,\n",
      "         2.7411e-02, -3.8417e-02,  3.7997e-02, -9.9984e-03,  4.1873e-03,\n",
      "        -3.4041e-02,  2.7183e-02, -1.4454e-02,  3.9867e-02,  3.5660e-02,\n",
      "        -8.2032e-03,  4.2453e-03,  2.3654e-02, -2.3484e-02, -3.6326e-02,\n",
      "        -3.2784e-03,  3.1303e-02, -3.1440e-02,  1.5474e-02,  5.9288e-03,\n",
      "         7.4803e-03,  1.6088e-02, -4.7918e-03,  4.3268e-02,  4.2007e-02,\n",
      "         3.6010e-02,  4.3419e-02,  4.4077e-02,  3.9172e-02, -3.1749e-03,\n",
      "         2.2481e-02,  1.4050e-02, -1.7947e-02, -1.3346e-03,  3.5572e-02,\n",
      "         3.0363e-02, -3.6262e-02,  2.7766e-02, -1.6873e-02, -2.4398e-02,\n",
      "        -3.5589e-02, -2.5672e-02,  1.2373e-02,  4.2978e-02, -1.9641e-02,\n",
      "         1.9703e-02,  3.7834e-02,  3.2419e-02, -4.0786e-02, -4.3660e-02,\n",
      "        -4.9941e-03,  1.5810e-02,  3.8628e-02,  3.0123e-02, -1.2559e-02,\n",
      "         2.5676e-02, -5.7849e-03, -3.2014e-02, -2.5984e-02,  1.1831e-02,\n",
      "         4.0022e-02,  3.3172e-02, -9.3870e-03, -2.7443e-02,  1.1670e-02,\n",
      "         7.2446e-03, -3.2803e-02,  1.8002e-02, -2.6822e-02, -4.1525e-02,\n",
      "         2.8707e-02, -1.6021e-03,  1.0096e-02,  1.4531e-02, -1.0318e-02,\n",
      "         3.4926e-02, -2.4956e-02,  4.0078e-02,  1.5745e-02, -2.7654e-02,\n",
      "        -2.9966e-02, -4.4028e-02, -2.7750e-02, -1.3014e-03, -1.9097e-03,\n",
      "         3.6507e-02, -2.9678e-02,  3.4837e-02,  2.7471e-02, -1.3187e-03,\n",
      "        -8.1918e-03,  1.9102e-02, -2.3808e-03,  2.2846e-02,  3.0811e-02,\n",
      "         1.3952e-03,  4.2411e-02,  4.4133e-02,  1.9159e-02,  7.6876e-03,\n",
      "        -3.8027e-02, -2.4187e-02, -3.1720e-02,  1.5707e-02, -2.7253e-02,\n",
      "        -1.4493e-02,  1.6140e-02, -2.8883e-02, -4.2677e-02,  1.7394e-02,\n",
      "        -1.5658e-03,  3.6268e-02,  2.8025e-02, -1.6558e-02, -1.9458e-02,\n",
      "        -2.2167e-02,  1.5223e-02], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-9.5533e-03,  6.4809e-03,  8.9022e-03, -1.6467e-03, -6.9656e-03,\n",
      "        -8.6036e-03,  7.8417e-03,  6.9797e-03,  5.9053e-04,  1.4571e-02,\n",
      "         1.4709e-03, -5.3613e-03,  4.6540e-03, -2.8754e-03,  7.1824e-03,\n",
      "        -2.7608e-03,  6.9064e-03, -3.8242e-03,  3.7573e-03,  5.8300e-03,\n",
      "        -1.4159e-02, -1.1300e-02, -6.8377e-03,  6.7610e-03, -1.0661e-02,\n",
      "        -1.1069e-02, -9.3735e-04, -1.3434e-02,  4.6700e-03, -1.7091e-02,\n",
      "        -1.1238e-02,  1.8026e-02,  5.3332e-04, -1.1999e-02, -6.8695e-03,\n",
      "         7.1900e-03, -6.9378e-03, -3.1468e-03, -3.5582e-03,  2.5714e-03,\n",
      "        -1.7665e-03,  5.0040e-03,  1.3929e-02,  1.0384e-02, -2.0651e-02,\n",
      "        -2.5567e-03, -2.9755e-03, -1.0535e-02,  5.2615e-03, -1.0542e-02,\n",
      "        -3.5029e-03,  7.2859e-03,  1.1808e-02,  1.4532e-03, -4.9215e-03,\n",
      "        -2.1181e-02, -7.0469e-03,  1.2989e-02,  2.1026e-02,  8.9301e-03,\n",
      "        -8.5872e-04, -1.0185e-03, -1.6901e-03,  1.1750e-02,  5.5881e-03,\n",
      "        -9.9113e-03, -5.4097e-04,  2.1934e-02,  1.8018e-02, -1.2045e-02,\n",
      "         6.0765e-03, -6.5927e-03, -1.9674e-03, -8.2687e-03, -2.6094e-03,\n",
      "        -4.8348e-03, -1.2436e-03, -2.2712e-03, -2.5437e-03, -4.5397e-03,\n",
      "         8.8460e-03,  1.4170e-02, -1.7670e-04,  2.7568e-03,  1.2868e-02,\n",
      "        -1.2289e-03,  1.3726e-02, -1.2562e-02, -3.5309e-03,  8.8400e-03,\n",
      "         1.6266e-03, -4.2348e-03,  1.3552e-02, -8.3910e-03,  1.0358e-02,\n",
      "        -7.7708e-03,  1.0902e-02,  1.2675e-02, -4.4376e-03, -8.4641e-03,\n",
      "         1.5601e-02,  4.2382e-03,  4.0397e-03, -4.5848e-03, -8.7856e-05,\n",
      "         5.8156e-04, -1.2429e-02, -1.9468e-02, -5.5471e-04,  9.1370e-04,\n",
      "         5.6153e-04, -1.8053e-02,  1.3383e-02,  7.8331e-03,  1.6706e-03,\n",
      "        -7.3815e-03, -1.1607e-02,  4.0830e-03,  6.3740e-03, -4.3358e-03,\n",
      "        -4.1740e-03,  1.7730e-02,  6.8485e-03, -1.3463e-03,  4.3362e-03,\n",
      "        -2.7847e-03,  1.6301e-02,  5.8507e-03,  1.6075e-03,  7.8645e-03,\n",
      "         2.1049e-03, -9.3286e-03,  6.8005e-03,  6.2158e-03, -2.1798e-03,\n",
      "         1.0413e-02,  1.3483e-03, -1.6653e-02, -3.9312e-03,  6.4707e-03,\n",
      "         7.2570e-03,  5.1869e-03,  1.8001e-02, -2.3789e-02,  4.7439e-03,\n",
      "        -3.4245e-03,  2.7846e-03,  3.9638e-03,  1.5878e-02, -1.9787e-03,\n",
      "         5.7899e-03, -1.2524e-02, -9.8421e-03, -5.0595e-03, -1.3043e-02,\n",
      "         6.6199e-04, -1.0366e-02, -2.0694e-02,  3.5565e-03, -5.2903e-03,\n",
      "         4.3041e-03, -5.6005e-04, -2.1293e-03,  1.2048e-02, -2.8170e-03,\n",
      "         1.4781e-02, -1.9215e-02, -4.2667e-04,  2.7257e-03,  1.1455e-02,\n",
      "        -3.4719e-03,  2.2342e-04, -3.1709e-02, -5.7049e-03, -7.8483e-03,\n",
      "         1.2967e-02,  1.6122e-02,  5.7372e-05, -7.7903e-03,  1.2231e-02,\n",
      "         7.0299e-03, -1.0587e-02,  3.0551e-03, -4.7515e-03, -6.8875e-03,\n",
      "        -6.3054e-03,  1.9356e-03, -1.1221e-02, -7.4704e-03,  8.2292e-03,\n",
      "        -1.0353e-02, -6.5642e-03,  3.9324e-03,  1.1897e-02, -1.8512e-02,\n",
      "        -7.9579e-03, -3.5279e-03, -1.3546e-02, -1.9402e-03, -1.4966e-03,\n",
      "        -1.7653e-02, -5.0593e-03,  1.2939e-03, -6.5109e-03,  1.1807e-02,\n",
      "        -2.1777e-02,  3.6299e-03,  1.8417e-02, -3.9919e-03,  8.1737e-03,\n",
      "        -3.4809e-03,  7.3557e-03,  6.6123e-03, -8.2584e-03, -1.1765e-02,\n",
      "         2.0670e-02,  1.5299e-02,  2.1777e-03,  3.7479e-03, -3.8425e-03,\n",
      "         6.9254e-04,  8.4549e-04, -4.3647e-03,  4.3024e-03,  6.6916e-03,\n",
      "         2.8435e-02, -5.0327e-03, -1.1222e-02, -1.9980e-02, -8.3792e-06,\n",
      "        -3.1956e-02, -9.5205e-03,  3.1977e-03,  2.0146e-02,  1.7966e-03,\n",
      "        -6.7579e-03,  1.0335e-03, -9.8447e-03,  4.2281e-03,  3.8612e-03,\n",
      "        -9.8777e-03, -1.3753e-02, -1.9003e-02, -2.2423e-03, -7.6482e-05,\n",
      "        -3.4919e-03, -3.2899e-03, -6.9842e-03,  2.2484e-03,  3.6466e-03,\n",
      "         1.5500e-02,  4.3177e-03,  3.1582e-03, -6.0779e-03, -1.8384e-02,\n",
      "         1.4549e-02, -3.3525e-03, -1.0868e-02, -2.6884e-03,  6.3514e-03,\n",
      "        -1.2819e-02, -1.3500e-02, -1.2035e-02,  2.2868e-03,  1.4286e-03,\n",
      "         1.4314e-02, -8.5072e-03, -4.6741e-03, -3.5357e-03, -5.4220e-03,\n",
      "         4.5214e-03, -1.1451e-02,  1.4107e-02,  1.9890e-03,  9.8319e-03,\n",
      "         2.0268e-02,  1.9355e-03, -1.7206e-02, -8.7326e-03, -6.0488e-04,\n",
      "        -2.7379e-03, -1.0707e-02, -2.6626e-02, -3.8113e-03,  1.8860e-02,\n",
      "        -6.6226e-03, -7.0303e-03,  2.1200e-03, -3.7435e-03, -1.5214e-03,\n",
      "        -2.1430e-03, -6.8066e-03,  1.2054e-03, -4.9978e-03, -2.4398e-03,\n",
      "        -2.4889e-03,  4.7706e-03,  8.4058e-03, -1.0547e-04,  1.3033e-02,\n",
      "         4.2668e-03, -5.8180e-03,  8.9020e-03,  6.2827e-03,  6.5531e-04,\n",
      "        -4.3963e-03,  8.4150e-03, -5.9549e-03, -1.2967e-02, -1.5135e-02,\n",
      "         1.1449e-02, -9.2274e-03,  2.1026e-02,  5.5933e-03, -4.1955e-03,\n",
      "         1.3674e-02,  2.0628e-02,  1.9574e-02, -6.8835e-03,  1.1885e-02,\n",
      "        -5.8993e-03,  4.0593e-03, -1.6428e-02,  1.9925e-03, -6.3899e-03,\n",
      "        -3.6138e-03, -2.3848e-03, -6.3648e-03, -9.7288e-03, -1.8622e-03,\n",
      "        -4.5522e-03, -1.5936e-02, -1.0656e-02,  5.0584e-03,  4.1884e-03,\n",
      "        -1.8236e-04,  1.5612e-02,  7.9607e-03,  6.0024e-03, -7.1731e-03,\n",
      "        -1.0528e-03,  1.7203e-02, -1.4892e-03, -1.4965e-02, -1.6061e-03,\n",
      "         3.1537e-02,  1.2235e-03,  5.6815e-03, -1.8077e-02, -1.0510e-02,\n",
      "         5.4808e-03,  6.8653e-03,  3.8199e-03,  1.6890e-02, -1.4903e-03,\n",
      "         7.3884e-03,  2.0765e-04, -1.9948e-02, -1.7594e-02,  1.8072e-02,\n",
      "         3.1728e-03, -7.9052e-03,  9.1407e-03,  7.1035e-03, -9.1698e-03,\n",
      "         2.2246e-03,  4.0143e-03, -7.3777e-04, -1.7154e-02,  1.0883e-02,\n",
      "        -6.0957e-03, -5.8501e-03, -2.3265e-03,  1.7837e-02,  1.4487e-02,\n",
      "         6.3863e-04, -5.3828e-03, -8.0302e-03, -9.7945e-03, -2.1713e-02,\n",
      "         1.9694e-02, -6.2683e-03,  1.1288e-02,  2.6805e-02,  4.3478e-03,\n",
      "        -2.7311e-03,  6.8355e-04, -1.1534e-02,  4.9265e-03, -2.5433e-02,\n",
      "        -1.1549e-02,  3.4232e-03, -1.2731e-02, -8.8624e-03,  5.2234e-03,\n",
      "        -2.4442e-03,  9.5812e-03, -1.3291e-02,  2.2202e-03,  6.7610e-03,\n",
      "        -3.1825e-03, -6.1191e-03,  7.6450e-03, -9.2764e-03, -6.4891e-04,\n",
      "        -7.9384e-03,  8.6851e-03, -1.1024e-03,  4.2401e-03,  1.0610e-02,\n",
      "        -6.3775e-03, -1.7576e-03, -2.9659e-02,  5.3190e-03,  5.5482e-04,\n",
      "         1.5769e-02,  6.6662e-03, -3.2060e-03, -5.2307e-03,  8.6038e-03,\n",
      "         1.2682e-03, -9.6801e-03, -1.1505e-02,  3.6931e-03, -2.3084e-03,\n",
      "        -9.5587e-03,  1.7430e-04,  2.5360e-02,  6.6870e-03,  2.3575e-03,\n",
      "        -2.4275e-03, -1.2683e-02, -1.7536e-02, -2.5592e-03,  1.4449e-02,\n",
      "        -1.3346e-02, -2.8821e-03, -1.5858e-02, -2.7576e-03, -1.5390e-02,\n",
      "        -1.2481e-03,  2.1553e-02, -9.3417e-03,  9.5867e-03,  4.1222e-03,\n",
      "        -8.0378e-03,  1.7721e-02,  7.5144e-03, -7.4363e-03,  9.0274e-03,\n",
      "         1.1926e-02, -1.8191e-02, -1.3017e-02, -4.2142e-03, -1.3454e-02,\n",
      "         3.6644e-04, -3.4932e-02, -5.8272e-03, -3.0636e-03,  8.5527e-04,\n",
      "         2.8858e-03, -4.1359e-03,  6.3733e-03, -9.4717e-03,  5.0812e-04,\n",
      "        -4.7928e-03,  3.9295e-03, -1.4303e-02,  6.4035e-03, -7.5030e-03,\n",
      "        -1.0153e-02,  1.0408e-02,  1.4058e-02, -2.4785e-02, -1.3592e-02,\n",
      "        -9.5922e-04,  1.5798e-02, -1.0545e-02,  9.8509e-03, -1.1975e-02,\n",
      "         3.4745e-03,  4.2603e-03,  1.0413e-02,  9.6890e-03, -7.2754e-04,\n",
      "        -1.1083e-02, -5.0343e-03, -9.2509e-03,  1.3369e-02, -2.4293e-03,\n",
      "         8.0471e-03, -1.7139e-02, -1.4630e-03,  1.6615e-02,  1.5286e-04,\n",
      "        -3.1700e-03,  1.9400e-02, -1.7364e-03,  6.2824e-03,  8.9898e-03,\n",
      "        -3.5556e-03, -1.6460e-03, -1.2732e-02,  5.1276e-04,  5.4062e-03,\n",
      "         1.0055e-02,  1.2920e-02,  9.7446e-04, -5.7772e-03,  7.2960e-03,\n",
      "        -7.2799e-04,  3.8726e-03])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0119, -0.0157, -0.0332, -0.0062, -0.0389,  0.0299, -0.0345,  0.0390,\n",
      "         0.0400,  0.0014,  0.0247, -0.0397, -0.0385,  0.0287, -0.0362,  0.0040,\n",
      "        -0.0142, -0.0114, -0.0155,  0.0283,  0.0074, -0.0386, -0.0025, -0.0113,\n",
      "         0.0121, -0.0042, -0.0387,  0.0247,  0.0327,  0.0108, -0.0353,  0.0310,\n",
      "         0.0375,  0.0217,  0.0262,  0.0307,  0.0255,  0.0318, -0.0406,  0.0304,\n",
      "         0.0131, -0.0351,  0.0186,  0.0141,  0.0120, -0.0139,  0.0065, -0.0488,\n",
      "         0.0434, -0.0249, -0.0001,  0.0384,  0.0161,  0.0219,  0.0207, -0.0503,\n",
      "         0.0360,  0.0539,  0.0225,  0.0442, -0.0360,  0.0367,  0.0359, -0.0011,\n",
      "        -0.0259, -0.0472, -0.0129,  0.0431, -0.0226, -0.0005,  0.0145, -0.0284,\n",
      "         0.0042, -0.0370,  0.0330, -0.0462, -0.0169, -0.0460,  0.0198,  0.0287,\n",
      "         0.0133,  0.0282,  0.0275,  0.0059,  0.0497, -0.0290,  0.0280, -0.0346,\n",
      "         0.0258, -0.0202, -0.0083, -0.0441,  0.0252,  0.0235, -0.0028, -0.0111,\n",
      "        -0.0229, -0.0210,  0.0202,  0.0133,  0.0558,  0.0165, -0.0141, -0.0271,\n",
      "        -0.0408,  0.0294,  0.0172, -0.0396, -0.0208, -0.0358,  0.0175, -0.0335,\n",
      "         0.0440,  0.0180,  0.0139,  0.0108, -0.0305, -0.0173, -0.0160, -0.0212,\n",
      "        -0.0388,  0.0338,  0.0132, -0.0293, -0.0301, -0.0339,  0.0451,  0.0149,\n",
      "         0.0455, -0.0243, -0.0003,  0.0156, -0.0248, -0.0224, -0.0359,  0.0338,\n",
      "         0.0214, -0.0151,  0.0012,  0.0297,  0.0078, -0.0155, -0.0017, -0.0431,\n",
      "         0.0235, -0.0159, -0.0335, -0.0356, -0.0220,  0.0235,  0.0226, -0.0069,\n",
      "        -0.0474, -0.0028, -0.0328,  0.0321,  0.0325,  0.0142, -0.0237, -0.0421,\n",
      "         0.0260, -0.0443,  0.0354, -0.0271, -0.0263,  0.0578, -0.0186,  0.0305,\n",
      "        -0.0114,  0.0039, -0.0064,  0.0363, -0.0235, -0.0015,  0.0224,  0.0049,\n",
      "        -0.0184, -0.0159,  0.0229,  0.0216,  0.0493,  0.0150,  0.0028, -0.0360,\n",
      "        -0.0156, -0.0091, -0.0187, -0.0201, -0.0013,  0.0176, -0.0076,  0.0133,\n",
      "         0.0311,  0.0466, -0.0074, -0.0303,  0.0391,  0.0067,  0.0097,  0.0178,\n",
      "        -0.0210, -0.0277, -0.0402, -0.0431,  0.0391,  0.0093,  0.0289, -0.0249,\n",
      "        -0.0268,  0.0510, -0.0114, -0.0345, -0.0278, -0.0372,  0.0186,  0.0430,\n",
      "         0.0086, -0.0370,  0.0299, -0.0106, -0.0340,  0.0004, -0.0325, -0.0106,\n",
      "        -0.0300,  0.0237, -0.0343,  0.0250, -0.0062, -0.0290, -0.0048,  0.0224,\n",
      "        -0.0042,  0.0500,  0.0280, -0.0481, -0.0207, -0.0310, -0.0180, -0.0252,\n",
      "        -0.0142, -0.0275, -0.0292,  0.0195,  0.0344, -0.0123, -0.0249, -0.0172,\n",
      "         0.0138,  0.0462, -0.0128, -0.0060, -0.0177,  0.0269,  0.0064, -0.0106,\n",
      "         0.0297,  0.0123,  0.0174,  0.0059, -0.0325,  0.0124,  0.0154,  0.0178,\n",
      "        -0.0238, -0.0280,  0.0166,  0.0339, -0.0173, -0.0492, -0.0189, -0.0093,\n",
      "        -0.0221,  0.0098, -0.0335,  0.0212,  0.0349,  0.0085, -0.0159,  0.0052,\n",
      "        -0.0334,  0.0318, -0.0144,  0.0336,  0.0212, -0.0338, -0.0345, -0.0298,\n",
      "         0.0144,  0.0377,  0.0076,  0.0082,  0.0258,  0.0116,  0.0083,  0.0086,\n",
      "         0.0419, -0.0117, -0.0046,  0.0433,  0.0100, -0.0125, -0.0241,  0.0414,\n",
      "         0.0295,  0.0097,  0.0418, -0.0082, -0.0559,  0.0082,  0.0266, -0.0456,\n",
      "         0.0056, -0.0253,  0.0263,  0.0015,  0.0551,  0.0603,  0.0054,  0.0506,\n",
      "        -0.0197, -0.0027, -0.0052,  0.0129,  0.0200, -0.0199,  0.0183,  0.0057,\n",
      "        -0.0469, -0.0201,  0.0396,  0.0154, -0.0410, -0.0377,  0.0392, -0.0316,\n",
      "         0.0203,  0.0433,  0.0315, -0.0416,  0.0106,  0.0392,  0.0242, -0.0521,\n",
      "         0.0222,  0.0687,  0.0015, -0.0328, -0.0173,  0.0064, -0.0030, -0.0074,\n",
      "         0.0212, -0.0128,  0.0179, -0.0080,  0.0129,  0.0202, -0.0484, -0.0022,\n",
      "        -0.0032, -0.0391, -0.0264,  0.0241, -0.0438, -0.0186,  0.0260, -0.0269,\n",
      "         0.0010,  0.0110, -0.0175, -0.0232,  0.0006,  0.0569,  0.0072,  0.0209,\n",
      "        -0.0081, -0.0363, -0.0482, -0.0391,  0.0149, -0.0073,  0.0347,  0.0588,\n",
      "        -0.0221, -0.0364, -0.0005, -0.0372, -0.0119, -0.0122, -0.0540,  0.0006,\n",
      "        -0.0430, -0.0340,  0.0460,  0.0250, -0.0288,  0.0247, -0.0078,  0.0109,\n",
      "        -0.0372,  0.0211, -0.0068,  0.0306,  0.0350, -0.0161,  0.0129,  0.0226,\n",
      "        -0.0192, -0.0257, -0.0097,  0.0295, -0.0611,  0.0208,  0.0065,  0.0232,\n",
      "         0.0228, -0.0080,  0.0380,  0.0506,  0.0373,  0.0337,  0.0326,  0.0429,\n",
      "        -0.0055,  0.0129,  0.0142,  0.0074,  0.0054,  0.0379,  0.0279, -0.0489,\n",
      "         0.0102, -0.0194, -0.0099, -0.0489, -0.0286, -0.0035,  0.0402, -0.0350,\n",
      "         0.0185,  0.0594,  0.0231, -0.0312, -0.0395, -0.0130,  0.0335,  0.0461,\n",
      "         0.0227, -0.0035,  0.0376, -0.0240, -0.0450, -0.0302, -0.0016,  0.0404,\n",
      "        -0.0018, -0.0152, -0.0305,  0.0125,  0.0101, -0.0369,  0.0244, -0.0363,\n",
      "        -0.0410,  0.0239,  0.0023, -0.0042,  0.0209, -0.0178,  0.0248, -0.0145,\n",
      "         0.0541, -0.0090, -0.0412, -0.0309, -0.0282, -0.0383,  0.0085, -0.0139,\n",
      "         0.0400, -0.0254,  0.0452,  0.0372, -0.0020, -0.0193,  0.0141, -0.0116,\n",
      "         0.0362,  0.0284,  0.0094,  0.0253,  0.0427,  0.0358,  0.0078, -0.0412,\n",
      "        -0.0048, -0.0335,  0.0220, -0.0183, -0.0180,  0.0145, -0.0416, -0.0422,\n",
      "         0.0228,  0.0085,  0.0492,  0.0290, -0.0223, -0.0122, -0.0229,  0.0191],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0202,  0.0127, -0.0396,  ...,  0.0137,  0.0049, -0.0033],\n",
      "        [-0.0384,  0.0156, -0.0075,  ...,  0.0326,  0.0006, -0.0412],\n",
      "        [-0.0080,  0.0090, -0.0083,  ...,  0.0404, -0.0306,  0.0216],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0371,  0.0227,  ...,  0.0177, -0.0386,  0.0122],\n",
      "        [-0.0439, -0.0425,  0.0030,  ..., -0.0411,  0.0249,  0.0306],\n",
      "        [-0.0339,  0.0425, -0.0389,  ...,  0.0206, -0.0423,  0.0070]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[ 0.0137,  0.0010,  0.0009,  ...,  0.0034, -0.0112, -0.0071],\n",
      "        [-0.0021,  0.0006,  0.0032,  ...,  0.0228,  0.0062, -0.0004],\n",
      "        [-0.0094, -0.0180, -0.0009,  ..., -0.0088,  0.0055,  0.0186],\n",
      "        ...,\n",
      "        [ 0.0018,  0.0174,  0.0004,  ...,  0.0042, -0.0125, -0.0114],\n",
      "        [-0.0174, -0.0004,  0.0178,  ...,  0.0041,  0.0250,  0.0086],\n",
      "        [ 0.0214,  0.0052, -0.0071,  ..., -0.0082, -0.0071, -0.0187]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0339,  0.0137, -0.0387,  ...,  0.0171, -0.0064, -0.0104],\n",
      "        [-0.0405,  0.0162, -0.0042,  ...,  0.0553,  0.0068, -0.0416],\n",
      "        [-0.0174, -0.0090, -0.0092,  ...,  0.0316, -0.0252,  0.0402],\n",
      "        ...,\n",
      "        [ 0.0347, -0.0197,  0.0231,  ...,  0.0219, -0.0511,  0.0007],\n",
      "        [-0.0613, -0.0428,  0.0207,  ..., -0.0371,  0.0499,  0.0392],\n",
      "        [-0.0126,  0.0476, -0.0460,  ...,  0.0124, -0.0494, -0.0116]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 0.0009,  0.0109,  0.0426,  0.0312, -0.0004,  0.0010,  0.0295,  0.0404,\n",
      "         0.0243,  0.0122, -0.0110, -0.0252, -0.0309,  0.0211,  0.0130,  0.0095,\n",
      "        -0.0310,  0.0243,  0.0430,  0.0204], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-0.0249,  0.0113,  0.0135,  0.0050,  0.0067, -0.0032, -0.0149,  0.0076,\n",
      "        -0.0103, -0.0013,  0.0017,  0.0074,  0.0034, -0.0061,  0.0089,  0.0057,\n",
      "         0.0058, -0.0008, -0.0094,  0.0125])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0241,  0.0221,  0.0561,  0.0362,  0.0063, -0.0022,  0.0146,  0.0479,\n",
      "         0.0140,  0.0109, -0.0093, -0.0178, -0.0275,  0.0150,  0.0219,  0.0152,\n",
      "        -0.0252,  0.0236,  0.0336,  0.0329], requires_grad=True)\n",
      "\n",
      "-=-=--=-=--=-=-=-=\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-839c3d997ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodification_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def make_torch_seed():\n",
    "    while True:\n",
    "        seed = torch.random.seed()\n",
    "        if seed < 2**63:\n",
    "            return seed\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    #TODO: Try other network architectures (smaller layers)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        #self.conv1 = nn.Conv2d(2, 2, 13)\n",
    "        #self.conv2 = nn.Conv2d(2, 2, 1)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(658, 512)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 20)\n",
    "\n",
    "    \n",
    "    #TODO: Try other activation func\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (1, 1))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        #x = F.max_pool2d(F.relu(self.conv2(x)), 1)\n",
    "        #x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \"\"\"\n",
    "    def foward2(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \"\"\"\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "initial_seed = torch.random.seed()\n",
    "net = Net()\n",
    "# print(net)\n",
    "# print(net.parameters())\n",
    "# flattened = []\n",
    "# total = 0\n",
    "# for p in net.parameters():\n",
    "#     print(p)\n",
    "# #     print(p)\n",
    "# #     print(p.shape)\n",
    "#     f = torch.flatten(p)\n",
    "#     print(f.shape)\n",
    "#     length = len(f)\n",
    "#     print(length)\n",
    "#     total += length\n",
    "#     for i in range(length):\n",
    "#         flattened.append(f[i].item())\n",
    "# #     print(f)\n",
    "# #     flattened.append(list(f))\n",
    "# # print(net.parameters().shape)\n",
    "# # print(total)\n",
    "# # print(flattened[0])\n",
    "# # noise = torch.empty(total).normal_(mean=0,std=0.1)\n",
    "# print(noise[0])\n",
    "\n",
    "modification_seed = torch.random.seed()\n",
    "flattened = []\n",
    "with torch.no_grad():\n",
    "    for p in net.parameters():\n",
    "        print(\"Starting weights:\")\n",
    "        print(p)\n",
    "        s = p.shape\n",
    "        print(\"Noise vector:\")\n",
    "        noise = torch.empty(s).normal_(mean=0,std=0.01)\n",
    "        print(noise)\n",
    "        p += noise\n",
    "        print(\"New weights:\")\n",
    "        print(p)\n",
    "#     print(f)\n",
    "#     flattened.append(list(f))\n",
    "# print(net.parameters().shape)\n",
    "# print(total)\n",
    "# print(flattened[0])\n",
    "# noise = torch.empty(t\n",
    "\n",
    "print()\n",
    "print(\"-=-=--=-=--=-=-=-=\")\n",
    "print()\n",
    "\n",
    "\n",
    "net2 = copy.deepcopy(net)\n",
    "# net2.load_state_dict(net.state_dict())\n",
    "\n",
    "#Copy\n",
    "\n",
    "    \n",
    "    \n",
    "torch.random.manual_seed(modification_seed)\n",
    "with torch.no_grad():\n",
    "    for p in net.parameters():\n",
    "        print(\"Starting weights:\")\n",
    "        print(p)\n",
    "        s = p.shape\n",
    "        print(\"Noise vector:\")\n",
    "        noise = torch.empty(s).normal_(mean=0,std=0.01)\n",
    "        print(noise)\n",
    "        p += noise\n",
    "        print(\"New weights:\")\n",
    "        print(p)\n",
    "        \n",
    "    \n",
    "print(\"\")\n",
    "print(\"-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"aaa\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p2 in net2.parameters():\n",
    "        print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_tensor(mylist):\n",
    "    encoded_observations = np.array(mylist).reshape(1,658)\n",
    "    tensor_observations = torch.FloatTensor(encoded_observations)\n",
    "    return tensor_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_encoded_observations = get_encoded_observations(obs_encoder, state, 0)\n",
    "#encoded_observations = np.array(list_encoded_observations).reshape(1,658)\n",
    "#tensor_observations = torch.FloatTensor(encoded_observations)\n",
    "#net(tensor_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = tensor_observations\n",
    "#out = net(input)\n",
    "#print(out)\n",
    "#net.zero_grad()\n",
    "#out.backward(torch.randn(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def make_action(array):\\n        index = np.rgmax(array)\\n        return index\\n\\n\\n    def get_weights():\\n        #Pytorch code to get an array with all the weights of the network\\n        weights  = [] #np.zeros()\\n\\n    def set_wegiths(weights):\\n        #Pytorch code to set the weigths\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PytorchAgent:\n",
    "\n",
    "    def __init__(self,game,net=None,mutation_sd=0.01):\n",
    "        if net is None:\n",
    "            self.net = Net()\n",
    "        else:\n",
    "            self.net = copy.deepcopy(net)\n",
    "        self.game = game #TODO is there a way to factoor this out?\n",
    "        self.obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "        self.fitness=0.0\n",
    "\n",
    "    def act(self, state):\n",
    "        with torch.no_grad():\n",
    "            encoded_observations = get_encoded_observations(self.obs_encoder, state, state.cur_player())\n",
    "            input_tensor = list_to_tensor(encoded_observations)\n",
    "            output_tensor = self.net(input_tensor)\n",
    "            weight = output_tensor.tolist()[0]#weight of 20 possible moves\n",
    "            rank = sorted(range(len(weight)), key=lambda k: weight[k]) # rank of 20 possible moves in weight\n",
    "            index = sorted(range(len(rank)), key=lambda k: rank[k]) # index of sorted rank of 20 possible moves\n",
    "            observation = state.observation(state.cur_player())# need to make sure whether observation = state works\n",
    "            for i in index:\n",
    "#                 print(\"checking move:\" + str(self.game.get_move(i)))\n",
    "                if str(self.game.get_move(i)) in str(observation.legal_moves()):# Is there a way of not using str?\n",
    "#                     print(\"valid\")\n",
    "                    return self.game.get_move(i)\n",
    "#                 else:\n",
    "#                     print(\"invalid, checking next possible move in priority list\")\n",
    "        #here you probably need to check if it is a valid action\n",
    "        # There's a code in the HLE that gets the legal actions from a state (a \"mask\")\n",
    "        # you can do mask*model.forward()\n",
    "        # This will multiply all ILLEGAL actions by zero\n",
    "    \n",
    "    # If seed is none, create a new seed and append to self.seeds. Otherwise, just use the given seed, but not append\n",
    "    #TODO: Try other values for mutation rate\n",
    "    def mutate(self,sd=0.001,seed=None): #TODO: Posssibly try to ranomly change only a few of the parametes usign a mutation rate (low priorty)?\n",
    "        if seed is None:\n",
    "            seed = self.make_torch_seed()\n",
    "        with torch.no_grad():\n",
    "            torch.random.manual_seed(seed)\n",
    "            for p in net.parameters():\n",
    "                shape = p.shape\n",
    "                noise = torch.empty(shape).normal_(mean=0.0,std=sd)\n",
    "                p += noise\n",
    "    \n",
    "    def make_torch_seed(self):\n",
    "        while True:\n",
    "            seed = torch.random.seed()\n",
    "            if seed < 2**63:\n",
    "                return seed\n",
    "        \n",
    "\"\"\"\n",
    "    def make_action(array):\n",
    "        index = np.rgmax(array)\n",
    "        return index\n",
    "\n",
    "\n",
    "    def get_weights():\n",
    "        #Pytorch code to get an array with all the weights of the network\n",
    "        weights  = [] #np.zeros()\n",
    "\n",
    "    def set_wegiths(weights):\n",
    "        #Pytorch code to set the weigths\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/CMA-ES/pycma/blob/master/cma/fitness_functions.py\n",
    "def rastrigin(x):\n",
    "  \"\"\"Rastrigin test objective function, shifted by 10. units away from origin\"\"\"\n",
    "  x = np.copy(x)\n",
    "  x -= 10.0\n",
    "  if not np.isscalar(x[0]):\n",
    "    N = len(x[0])\n",
    "    return -np.array([10 * N + sum(xi**2 - 10 * np.cos(2 * np.pi * xi)) for xi in x])\n",
    "  N = len(x)\n",
    "  return -(10 * N + sum(x**2 - 10 * np.cos(2 * np.pi * x)))\n",
    "\n",
    "fit_func = rastrigin\n",
    "\n",
    "\n",
    "\n",
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "  history = []\n",
    "  for j in range(MAX_ITERATION):\n",
    "    solutions = solver.ask()\n",
    "    fitness_list = np.zeros(solver.popsize)\n",
    "    for i in range(solver.popsize):\n",
    "      fitness_list[i] = fit_func(solutions[i])\n",
    "    solver.tell(fitness_list)\n",
    "    result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "    history.append(result[1])\n",
    "    if (j+1) % 100 == 0:\n",
    "      print(\"fitness at iteration\", (j+1), result[1])\n",
    "  print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "  print(\"fitness score at this local optimum:\", result[1])\n",
    "  return history\n",
    "\n",
    "\n",
    "def fit_func(agent):\n",
    "    total_score = 0.0\n",
    "    for g in range(num_games):\n",
    "        score = play_game(game_parameters,agent)\n",
    "        total_score+=score\n",
    "    print(\"Gen {} Agent {} had totalscore {}\".format(gen,counter,total_score))\n",
    "    agent.fitness = float(total_score)/float(num_games)\n",
    "\n",
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "  history = []\n",
    "  for j in range(MAX_ITERATION):\n",
    "    solutions = solver.ask()\n",
    "    fitness_list = np.zeros(solver.popsize)\n",
    "    for i in range(solver.popsize):\n",
    "      fitness_list[i] = fit_func(solutions[i])\n",
    "    solver.tell(fitness_list)\n",
    "    result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "    history.append(result[1])\n",
    "    if (j+1) % 100 == 0:\n",
    "      print(\"fitness at iteration\", (j+1), result[1])\n",
    "  print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "  print(\"fitness score at this local optimum:\", result[1])\n",
    "  return history\n",
    "\n",
    "# defines genetic algorithm solver\n",
    "NPOPULATION = 20\n",
    "NPARAMS = 658\n",
    "MAX_ITERATION = 100\n",
    "ga = SimpleGA(NPARAMS,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=NPOPULATION,   # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )\n",
    "\n",
    "class esAgent:\n",
    "\n",
    "    def __init__(self,game,net=None,mutation_sd=0.01):\n",
    "        self.solver = ga\n",
    "        self.game = game #TODO is there a way to factoor this out?\n",
    "        self.obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "        self.fitness=0.0\n",
    "\n",
    "    def act(self, state):\n",
    "        with torch.no_grad():\n",
    "            encoded_observations = get_encoded_observations(self.obs_encoder, state, state.cur_player())\n",
    "            input_para = encoded_observations\n",
    "            output_para = self.net(input_tensor)\n",
    "            weight = output_tensor.tolist()[0]#weight of 20 possible moves\n",
    "            rank = sorted(range(len(weight)), key=lambda k: weight[k]) # rank of 20 possible moves in weight\n",
    "            index = sorted(range(len(rank)), key=lambda k: rank[k]) # index of sorted rank of 20 possible moves\n",
    "            observation = state.observation(state.cur_player())# need to make sure whether observation = state works\n",
    "            for i in index:\n",
    "#                 print(\"checking move:\" + str(self.game.get_move(i)))\n",
    "                if str(self.game.get_move(i)) in str(observation.legal_moves()):# Is there a way of not using str?\n",
    "#                     print(\"valid\")\n",
    "                    return self.game.get_move(i)\n",
    "#                 else:\n",
    "#                     print(\"invalid, checking next possible move in priority list\")\n",
    "        #here you probably need to check if it is a valid action\n",
    "        # There's a code in the HLE that gets the legal actions from a state (a \"mask\")\n",
    "        # you can do mask*model.forward()\n",
    "        # This will multiply all ILLEGAL actions by zero\n",
    "    \n",
    "    # If seed is none, create a new seed and append to self.seeds. Otherwise, just use the given seed, but not append\n",
    "    #TODO: Try other values for mutation rate\n",
    "    def mutate(self,sd=0.001,seed=None): #TODO: Posssibly try to ranomly change only a few of the parametes usign a mutation rate (low priorty)?\n",
    "        if seed is None:\n",
    "            seed = self.make_torch_seed()\n",
    "        with torch.no_grad():\n",
    "            torch.random.manual_seed(seed)\n",
    "            for p in net.parameters():\n",
    "                shape = p.shape\n",
    "                noise = torch.empty(shape).normal_(mean=0.0,std=sd)\n",
    "                p += noise\n",
    "    \n",
    "    def make_torch_seed(self):\n",
    "        while True:\n",
    "            seed = torch.random.seed()\n",
    "            if seed < 2**63:\n",
    "                return seed\n",
    "        \n",
    "\"\"\"\n",
    "    def make_action(array):\n",
    "        index = np.rgmax(array)\n",
    "        return index\n",
    "\n",
    "\n",
    "    def get_weights():\n",
    "        #Pytorch code to get an array with all the weights of the network\n",
    "        weights  = [] #np.zeros()\n",
    "\n",
    "    def set_wegiths(weights):\n",
    "        #Pytorch code to set the weigths\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_start_player=true\n",
      "seed=1206770686\n",
      "max_life_tokens=3\n",
      "hand_size=5\n",
      "observation_type=1\n",
      "max_information_tokens=8\n",
      "ranks=5\n",
      "colors=5\n",
      "players=2\n",
      "game finished\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "game_parameters = {\"players\": 2, \"random_start_player\": True}\n",
    "game = pyhanabi.HanabiGame(game_parameters)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "state = game.new_initial_state()\n",
    "\n",
    "pyagent = PytorchAgent(game)\n",
    "\n",
    "population_size = 5\n",
    "num_games = 5\n",
    "num_generations = 500\n",
    "# one run of game\n",
    "score=0\n",
    "\n",
    "# population = [PytorchAgent(game) for p in range(population_size)]\n",
    "\n",
    "    \n",
    "while not state.is_terminal():\n",
    "    if state.score() >=score:\n",
    "        score = state.score()\n",
    "    if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:\n",
    "        state.deal_random_card()\n",
    "        continue\n",
    "\n",
    "    #print_state(state)\n",
    "\n",
    "    #observation = state.observation(state.cur_player())\n",
    "    #print_observation(observation)\n",
    "    #print(observation.legal_moves())\n",
    "    #print_encoded_observations(obs_encoder, state, game.num_players())\n",
    "    #encoded_observations = get_encoded_observations(obs_encoder, state, state.cur_player())\n",
    "    #mytensor = list_to_tensor(encoded_observations)\n",
    "    #legal_moves = state.legal_moves()\n",
    "    # print(\"\")\n",
    "    # print(\"Number of legal moves: {}\".format(len(legal_moves)))\n",
    "    current_life_token = state.life_tokens()\n",
    "    current_fireworks = state.fireworks()\n",
    "    move  = pyagent.act(state)\n",
    "    # move = np.random.choice(legal_moves)\n",
    "    # print(\"Chose random legal move: {}\".format(move))\n",
    "\n",
    "    state.apply_move(move)\n",
    "print(\"game finished\")\n",
    "print(state.fireworks())\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_start_player=true\n",
      "seed=216654956\n",
      "max_life_tokens=3\n",
      "hand_size=5\n",
      "observation_type=1\n",
      "max_information_tokens=8\n",
      "ranks=5\n",
      "colors=5\n",
      "players=2\n",
      "<__main__.PytorchAgent object at 0x1a9bfcff90>\n",
      "Gen 0 Agent 0 had totalscore 123.0\n",
      "Gen 0 Agent 1 had totalscore 146.0\n",
      "Gen 0 Agent 2 had totalscore 120.0\n",
      "Gen 0 Agent 3 had totalscore 134.0\n",
      "Gen 0 Agent 4 had totalscore 114.0\n",
      "Gen 0 Agent 5 had totalscore 115.0\n",
      "Gen 0 Agent 6 had totalscore 127.0\n",
      "Gen 0 Agent 7 had totalscore 116.0\n",
      "Gen 0 Agent 8 had totalscore 119.0\n",
      "Gen 0 Agent 9 had totalscore 120.0\n",
      "Gen 0 Agent 10 had totalscore 121.0\n",
      "Gen 0 Agent 11 had totalscore 120.0\n",
      "Gen 0 Agent 12 had totalscore 136.0\n",
      "Gen 0 Agent 13 had totalscore 115.0\n",
      "Gen 0 Agent 14 had totalscore 117.0\n",
      "Gen 0 Agent 15 had totalscore 118.0\n",
      "Gen 0 Agent 16 had totalscore 137.0\n",
      "Gen 0 Agent 17 had totalscore 115.0\n",
      "Gen 0 Agent 18 had totalscore 139.0\n",
      "Gen 0 Agent 19 had totalscore 138.0\n",
      "Time 15:17:21. Before sorting Best of generation 0 has fitness 1.23\n",
      "Time 15:17:21. Before sorting 2ndBest of generation 0 has fitness 1.46\n",
      "Time 15:17:21. Before sorting 3rdBest of generation 0 has fitness 1.2\n",
      "Time 15:17:21. Before sorting 10thBest of generation 0 has fitness 1.2\n",
      "Time 15:17:21. Before sorting 20thBest of generation 0 has fitness 1.38\n",
      "Time 15:17:21. After sorting Best of generation 0 has fitness 1.46\n",
      "Time 15:17:21. After sorting 2ndBest of generation 0 has fitness 1.39\n",
      "Time 15:17:21. After sorting 3rdBest of generation 0 has fitness 1.38\n",
      "Time 15:17:21. After sorting 10thBest of generation 0 has fitness 1.2\n",
      "Time 15:17:21. After sorting 20thBest of generation 0 has fitness 1.14\n",
      "0\n",
      "Gen 1 Agent 0 had totalscore 105.0\n",
      "Gen 1 Agent 1 had totalscore 115.0\n",
      "Gen 1 Agent 2 had totalscore 124.0\n",
      "Gen 1 Agent 3 had totalscore 133.0\n",
      "Gen 1 Agent 4 had totalscore 118.0\n",
      "Gen 1 Agent 5 had totalscore 108.0\n",
      "Gen 1 Agent 6 had totalscore 112.0\n",
      "Gen 1 Agent 7 had totalscore 113.0\n",
      "Gen 1 Agent 8 had totalscore 135.0\n",
      "Gen 1 Agent 9 had totalscore 144.0\n",
      "Gen 1 Agent 10 had totalscore 118.0\n",
      "Gen 1 Agent 11 had totalscore 128.0\n",
      "Gen 1 Agent 12 had totalscore 125.0\n",
      "Gen 1 Agent 13 had totalscore 148.0\n",
      "Gen 1 Agent 14 had totalscore 130.0\n",
      "Gen 1 Agent 15 had totalscore 118.0\n",
      "Gen 1 Agent 16 had totalscore 124.0\n",
      "Gen 1 Agent 17 had totalscore 126.0\n",
      "Gen 1 Agent 18 had totalscore 140.0\n",
      "Gen 1 Agent 19 had totalscore 132.0\n",
      "Time 15:19:03. Before sorting Best of generation 1 has fitness 1.05\n",
      "Time 15:19:03. Before sorting 2ndBest of generation 1 has fitness 1.15\n",
      "Time 15:19:03. Before sorting 3rdBest of generation 1 has fitness 1.24\n",
      "Time 15:19:03. Before sorting 10thBest of generation 1 has fitness 1.44\n",
      "Time 15:19:03. Before sorting 20thBest of generation 1 has fitness 1.32\n",
      "Time 15:19:03. After sorting Best of generation 1 has fitness 1.48\n",
      "Time 15:19:03. After sorting 2ndBest of generation 1 has fitness 1.44\n",
      "Time 15:19:03. After sorting 3rdBest of generation 1 has fitness 1.4\n",
      "Time 15:19:03. After sorting 10thBest of generation 1 has fitness 1.25\n",
      "Time 15:19:03. After sorting 20thBest of generation 1 has fitness 1.05\n",
      "0\n",
      "Gen 2 Agent 0 had totalscore 130.0\n",
      "Gen 2 Agent 1 had totalscore 128.0\n",
      "Gen 2 Agent 2 had totalscore 125.0\n",
      "Gen 2 Agent 3 had totalscore 134.0\n",
      "Gen 2 Agent 4 had totalscore 121.0\n",
      "Gen 2 Agent 5 had totalscore 136.0\n",
      "Gen 2 Agent 6 had totalscore 100.0\n",
      "Gen 2 Agent 7 had totalscore 117.0\n",
      "Gen 2 Agent 8 had totalscore 123.0\n",
      "Gen 2 Agent 9 had totalscore 129.0\n",
      "Gen 2 Agent 10 had totalscore 101.0\n",
      "Gen 2 Agent 11 had totalscore 134.0\n",
      "Gen 2 Agent 12 had totalscore 152.0\n",
      "Gen 2 Agent 13 had totalscore 139.0\n",
      "Gen 2 Agent 14 had totalscore 133.0\n",
      "Gen 2 Agent 15 had totalscore 119.0\n",
      "Gen 2 Agent 16 had totalscore 127.0\n",
      "Gen 2 Agent 17 had totalscore 127.0\n",
      "Gen 2 Agent 18 had totalscore 125.0\n",
      "Gen 2 Agent 19 had totalscore 104.0\n",
      "Time 15:19:42. Before sorting Best of generation 2 has fitness 1.3\n",
      "Time 15:19:42. Before sorting 2ndBest of generation 2 has fitness 1.28\n",
      "Time 15:19:42. Before sorting 3rdBest of generation 2 has fitness 1.25\n",
      "Time 15:19:42. Before sorting 10thBest of generation 2 has fitness 1.29\n",
      "Time 15:19:42. Before sorting 20thBest of generation 2 has fitness 1.04\n",
      "Time 15:19:42. After sorting Best of generation 2 has fitness 1.52\n",
      "Time 15:19:42. After sorting 2ndBest of generation 2 has fitness 1.39\n",
      "Time 15:19:42. After sorting 3rdBest of generation 2 has fitness 1.36\n",
      "Time 15:19:42. After sorting 10thBest of generation 2 has fitness 1.27\n",
      "Time 15:19:42. After sorting 20thBest of generation 2 has fitness 1.0\n",
      "0\n",
      "Gen 3 Agent 0 had totalscore 127.0\n",
      "Gen 3 Agent 1 had totalscore 134.0\n",
      "Gen 3 Agent 2 had totalscore 111.0\n",
      "Gen 3 Agent 3 had totalscore 129.0\n",
      "Gen 3 Agent 4 had totalscore 110.0\n",
      "Gen 3 Agent 5 had totalscore 129.0\n",
      "Gen 3 Agent 6 had totalscore 139.0\n",
      "Gen 3 Agent 7 had totalscore 121.0\n",
      "Gen 3 Agent 8 had totalscore 129.0\n",
      "Gen 3 Agent 9 had totalscore 111.0\n",
      "Gen 3 Agent 10 had totalscore 120.0\n",
      "Gen 3 Agent 11 had totalscore 144.0\n",
      "Gen 3 Agent 12 had totalscore 108.0\n",
      "Gen 3 Agent 13 had totalscore 121.0\n",
      "Gen 3 Agent 14 had totalscore 127.0\n",
      "Gen 3 Agent 15 had totalscore 136.0\n",
      "Gen 3 Agent 16 had totalscore 146.0\n",
      "Gen 3 Agent 17 had totalscore 107.0\n",
      "Gen 3 Agent 18 had totalscore 129.0\n",
      "Gen 3 Agent 19 had totalscore 120.0\n",
      "Time 15:20:25. Before sorting Best of generation 3 has fitness 1.27\n",
      "Time 15:20:25. Before sorting 2ndBest of generation 3 has fitness 1.34\n",
      "Time 15:20:25. Before sorting 3rdBest of generation 3 has fitness 1.11\n",
      "Time 15:20:25. Before sorting 10thBest of generation 3 has fitness 1.11\n",
      "Time 15:20:25. Before sorting 20thBest of generation 3 has fitness 1.2\n",
      "Time 15:20:25. After sorting Best of generation 3 has fitness 1.46\n",
      "Time 15:20:25. After sorting 2ndBest of generation 3 has fitness 1.44\n",
      "Time 15:20:25. After sorting 3rdBest of generation 3 has fitness 1.39\n",
      "Time 15:20:25. After sorting 10thBest of generation 3 has fitness 1.27\n",
      "Time 15:20:25. After sorting 20thBest of generation 3 has fitness 1.07\n",
      "0\n",
      "Gen 4 Agent 0 had totalscore 141.0\n",
      "Gen 4 Agent 1 had totalscore 135.0\n",
      "Gen 4 Agent 2 had totalscore 131.0\n",
      "Gen 4 Agent 3 had totalscore 121.0\n",
      "Gen 4 Agent 4 had totalscore 120.0\n",
      "Gen 4 Agent 5 had totalscore 126.0\n",
      "Gen 4 Agent 6 had totalscore 123.0\n",
      "Gen 4 Agent 7 had totalscore 114.0\n",
      "Gen 4 Agent 8 had totalscore 134.0\n",
      "Gen 4 Agent 9 had totalscore 128.0\n",
      "Gen 4 Agent 10 had totalscore 157.0\n",
      "Gen 4 Agent 11 had totalscore 124.0\n",
      "Gen 4 Agent 12 had totalscore 132.0\n",
      "Gen 4 Agent 13 had totalscore 121.0\n",
      "Gen 4 Agent 14 had totalscore 130.0\n",
      "Gen 4 Agent 15 had totalscore 118.0\n",
      "Gen 4 Agent 16 had totalscore 123.0\n",
      "Gen 4 Agent 17 had totalscore 97.0\n",
      "Gen 4 Agent 18 had totalscore 119.0\n",
      "Gen 4 Agent 19 had totalscore 126.0\n",
      "Time 15:21:10. Before sorting Best of generation 4 has fitness 1.41\n",
      "Time 15:21:10. Before sorting 2ndBest of generation 4 has fitness 1.35\n",
      "Time 15:21:10. Before sorting 3rdBest of generation 4 has fitness 1.31\n",
      "Time 15:21:10. Before sorting 10thBest of generation 4 has fitness 1.28\n",
      "Time 15:21:10. Before sorting 20thBest of generation 4 has fitness 1.26\n",
      "Time 15:21:10. After sorting Best of generation 4 has fitness 1.57\n",
      "Time 15:21:10. After sorting 2ndBest of generation 4 has fitness 1.41\n",
      "Time 15:21:10. After sorting 3rdBest of generation 4 has fitness 1.35\n",
      "Time 15:21:10. After sorting 10thBest of generation 4 has fitness 1.26\n",
      "Time 15:21:10. After sorting 20thBest of generation 4 has fitness 0.97\n",
      "0\n",
      "Gen 5 Agent 0 had totalscore 139.0\n",
      "Gen 5 Agent 1 had totalscore 137.0\n",
      "Gen 5 Agent 2 had totalscore 113.0\n",
      "Gen 5 Agent 3 had totalscore 129.0\n",
      "Gen 5 Agent 4 had totalscore 120.0\n",
      "Gen 5 Agent 5 had totalscore 123.0\n",
      "Gen 5 Agent 6 had totalscore 139.0\n",
      "Gen 5 Agent 7 had totalscore 109.0\n",
      "Gen 5 Agent 8 had totalscore 118.0\n",
      "Gen 5 Agent 9 had totalscore 125.0\n",
      "Gen 5 Agent 10 had totalscore 121.0\n",
      "Gen 5 Agent 11 had totalscore 110.0\n",
      "Gen 5 Agent 12 had totalscore 147.0\n",
      "Gen 5 Agent 13 had totalscore 117.0\n",
      "Gen 5 Agent 14 had totalscore 100.0\n",
      "Gen 5 Agent 15 had totalscore 115.0\n",
      "Gen 5 Agent 16 had totalscore 110.0\n",
      "Gen 5 Agent 17 had totalscore 120.0\n",
      "Gen 5 Agent 18 had totalscore 95.0\n",
      "Gen 5 Agent 19 had totalscore 119.0\n",
      "Time 15:21:44. Before sorting Best of generation 5 has fitness 1.39\n",
      "Time 15:21:44. Before sorting 2ndBest of generation 5 has fitness 1.37\n",
      "Time 15:21:44. Before sorting 3rdBest of generation 5 has fitness 1.13\n",
      "Time 15:21:44. Before sorting 10thBest of generation 5 has fitness 1.25\n",
      "Time 15:21:44. Before sorting 20thBest of generation 5 has fitness 1.19\n",
      "Time 15:21:44. After sorting Best of generation 5 has fitness 1.47\n",
      "Time 15:21:44. After sorting 2ndBest of generation 5 has fitness 1.39\n",
      "Time 15:21:44. After sorting 3rdBest of generation 5 has fitness 1.39\n",
      "Time 15:21:44. After sorting 10thBest of generation 5 has fitness 1.2\n",
      "Time 15:21:44. After sorting 20thBest of generation 5 has fitness 0.95\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 6 Agent 0 had totalscore 120.0\n",
      "Gen 6 Agent 1 had totalscore 142.0\n",
      "Gen 6 Agent 2 had totalscore 135.0\n",
      "Gen 6 Agent 3 had totalscore 111.0\n",
      "Gen 6 Agent 4 had totalscore 101.0\n",
      "Gen 6 Agent 5 had totalscore 116.0\n",
      "Gen 6 Agent 6 had totalscore 131.0\n",
      "Gen 6 Agent 7 had totalscore 130.0\n",
      "Gen 6 Agent 8 had totalscore 133.0\n",
      "Gen 6 Agent 9 had totalscore 134.0\n",
      "Gen 6 Agent 10 had totalscore 122.0\n",
      "Gen 6 Agent 11 had totalscore 159.0\n",
      "Gen 6 Agent 12 had totalscore 155.0\n",
      "Gen 6 Agent 13 had totalscore 123.0\n",
      "Gen 6 Agent 14 had totalscore 111.0\n",
      "Gen 6 Agent 15 had totalscore 139.0\n",
      "Gen 6 Agent 16 had totalscore 117.0\n",
      "Gen 6 Agent 17 had totalscore 120.0\n",
      "Gen 6 Agent 18 had totalscore 139.0\n",
      "Gen 6 Agent 19 had totalscore 133.0\n",
      "Time 15:22:15. Before sorting Best of generation 6 has fitness 1.2\n",
      "Time 15:22:15. Before sorting 2ndBest of generation 6 has fitness 1.42\n",
      "Time 15:22:15. Before sorting 3rdBest of generation 6 has fitness 1.35\n",
      "Time 15:22:15. Before sorting 10thBest of generation 6 has fitness 1.34\n",
      "Time 15:22:15. Before sorting 20thBest of generation 6 has fitness 1.33\n",
      "Time 15:22:15. After sorting Best of generation 6 has fitness 1.59\n",
      "Time 15:22:15. After sorting 2ndBest of generation 6 has fitness 1.55\n",
      "Time 15:22:15. After sorting 3rdBest of generation 6 has fitness 1.42\n",
      "Time 15:22:15. After sorting 10thBest of generation 6 has fitness 1.31\n",
      "Time 15:22:15. After sorting 20thBest of generation 6 has fitness 1.01\n",
      "0\n",
      "Gen 7 Agent 0 had totalscore 138.0\n",
      "Gen 7 Agent 1 had totalscore 141.0\n",
      "Gen 7 Agent 2 had totalscore 125.0\n",
      "Gen 7 Agent 3 had totalscore 125.0\n",
      "Gen 7 Agent 4 had totalscore 121.0\n",
      "Gen 7 Agent 5 had totalscore 129.0\n",
      "Gen 7 Agent 6 had totalscore 117.0\n",
      "Gen 7 Agent 7 had totalscore 149.0\n",
      "Gen 7 Agent 8 had totalscore 107.0\n",
      "Gen 7 Agent 9 had totalscore 123.0\n",
      "Gen 7 Agent 10 had totalscore 125.0\n",
      "Gen 7 Agent 11 had totalscore 113.0\n",
      "Gen 7 Agent 12 had totalscore 130.0\n",
      "Gen 7 Agent 13 had totalscore 123.0\n",
      "Gen 7 Agent 14 had totalscore 137.0\n",
      "Gen 7 Agent 15 had totalscore 148.0\n",
      "Gen 7 Agent 16 had totalscore 114.0\n",
      "Gen 7 Agent 17 had totalscore 110.0\n",
      "Gen 7 Agent 18 had totalscore 118.0\n",
      "Gen 7 Agent 19 had totalscore 134.0\n",
      "Time 15:22:46. Before sorting Best of generation 7 has fitness 1.38\n",
      "Time 15:22:46. Before sorting 2ndBest of generation 7 has fitness 1.41\n",
      "Time 15:22:46. Before sorting 3rdBest of generation 7 has fitness 1.25\n",
      "Time 15:22:46. Before sorting 10thBest of generation 7 has fitness 1.23\n",
      "Time 15:22:46. Before sorting 20thBest of generation 7 has fitness 1.34\n",
      "Time 15:22:46. After sorting Best of generation 7 has fitness 1.49\n",
      "Time 15:22:46. After sorting 2ndBest of generation 7 has fitness 1.48\n",
      "Time 15:22:46. After sorting 3rdBest of generation 7 has fitness 1.41\n",
      "Time 15:22:46. After sorting 10thBest of generation 7 has fitness 1.25\n",
      "Time 15:22:46. After sorting 20thBest of generation 7 has fitness 1.07\n",
      "0\n",
      "Gen 8 Agent 0 had totalscore 103.0\n",
      "Gen 8 Agent 1 had totalscore 125.0\n",
      "Gen 8 Agent 2 had totalscore 132.0\n",
      "Gen 8 Agent 3 had totalscore 134.0\n",
      "Gen 8 Agent 4 had totalscore 124.0\n",
      "Gen 8 Agent 5 had totalscore 151.0\n",
      "Gen 8 Agent 6 had totalscore 130.0\n",
      "Gen 8 Agent 7 had totalscore 124.0\n",
      "Gen 8 Agent 8 had totalscore 127.0\n",
      "Gen 8 Agent 9 had totalscore 114.0\n",
      "Gen 8 Agent 10 had totalscore 132.0\n",
      "Gen 8 Agent 11 had totalscore 129.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-6d76a980f896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtotal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mtotal_score\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gen {} Agent {} had totalscore {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-6d76a980f896>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(game_parameters, agent)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcurrent_life_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlife_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcurrent_fireworks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfireworks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmove\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-1575f5409029>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mencoded_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_encoded_observations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#weight of 20 possible moves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# rank of 20 possible moves in weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-839c3d997ed4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#x = x.view(-1, self.num_flat_features(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "def play_game(game_parameters,agent):\n",
    "    game = pyhanabi.HanabiGame(game_parameters)\n",
    "    obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "    state = game.new_initial_state()\n",
    "    score=0\n",
    "    \n",
    "    while not state.is_terminal():\n",
    "        if state.score() >=score:\n",
    "            score = state.score()\n",
    "        if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:\n",
    "            state.deal_random_card()\n",
    "            continue\n",
    "\n",
    "\n",
    "        current_life_token = state.life_tokens()\n",
    "        current_fireworks = state.fireworks()\n",
    "        move  = agent.act(state)\n",
    "\n",
    "        state.apply_move(move)\n",
    "    return score\n",
    "\n",
    "game_parameters = {\"players\": 2, \"random_start_player\": True}\n",
    "game = pyhanabi.HanabiGame(game_parameters)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "\n",
    "# pyagent = PytorchAgent(game)\n",
    "\n",
    "#TODO: Try different values for these hyperparameters\n",
    "population_size = 20\n",
    "num_games = 100\n",
    "num_generations = 1000\n",
    "# one run of game\n",
    "\n",
    "#TODO: Try to load the initial parameters of a few of the individuals from our Rainbow AIIIDE experiments.\n",
    "population = [PytorchAgent(game) for p in range(population_size)]\n",
    "print(population[0])\n",
    "\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    # Evaluate each agent\n",
    "    counter = 0\n",
    "    for agent in population:\n",
    "        total_score = 0.0\n",
    "        for g in range(num_games):\n",
    "            score = play_game(game_parameters,agent)\n",
    "            total_score+=score\n",
    "        print(\"Gen {} Agent {} had totalscore {}\".format(gen,counter,total_score))\n",
    "        agent.fitness = float(total_score)/float(num_games)\n",
    "        counter+=1\n",
    "    print('Time {}. Before sorting Best of generation {} has fitness {}'.format(current_time,gen, population[0].fitness))\n",
    "    print('Time {}. Before sorting 2ndBest of generation {} has fitness {}'.format(current_time,gen, population[1].fitness))\n",
    "    print('Time {}. Before sorting 3rdBest of generation {} has fitness {}'.format(current_time,gen, population[2].fitness))\n",
    "    print('Time {}. Before sorting 10thBest of generation {} has fitness {}'.format(current_time,gen, population[9].fitness))\n",
    "    print('Time {}. Before sorting 20thBest of generation {} has fitness {}'.format(current_time,gen, population[19].fitness))\n",
    "    \n",
    "    # Sort by fitness\n",
    "    population.sort(key = lambda x: x.fitness, reverse=True)\n",
    "    new_population=[]\n",
    "    \n",
    "    print('Time {}. After sorting Best of generation {} has fitness {}'.format(current_time,gen, population[0].fitness))\n",
    "    print('Time {}. After sorting 2ndBest of generation {} has fitness {}'.format(current_time,gen, population[1].fitness))\n",
    "    print('Time {}. After sorting 3rdBest of generation {} has fitness {}'.format(current_time,gen, population[2].fitness))\n",
    "    print('Time {}. After sorting 10thBest of generation {} has fitness {}'.format(current_time,gen, population[9].fitness))\n",
    "    print('Time {}. After sorting 20thBest of generation {} has fitness {}'.format(current_time,gen, population[19].fitness))\n",
    "\n",
    "    \n",
    "    # Create new population by discarding the bottom half, duplicating the top half, then mutating one of the copies\n",
    "    \"\"\"\n",
    "    mu = 5\n",
    "    for i, a in enumerate(population): #TODO: Try other strategies such as make parent selection more likely for high fitness parents, elitism for the top k agents, etc\n",
    "        if i >= population_size/mu:\n",
    "            parent_index = int(i % (population_size/mu)) #Here it could be something like random parent (weighted by fitness)\n",
    "            parent = population[parent_index]\n",
    "            child = PytorchAgent(game,parent.net)\n",
    "            child.mutate(sd = 0.001)\n",
    "            new_population.append(child)\n",
    "        else:\n",
    "            #agent.mutate(sd =0.001)\n",
    "            new_population.append(agent)\n",
    "    population = new_population\n",
    "    \"\"\"\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "#     print (\"Population Size is \".format(get_size([x.seeds for x in population])))\n",
    "#     print(get_size([x.seeds for x in population]))\n",
    "#     print(get_size([x.net for x in population]))\n",
    "#     for p in population:\n",
    "#         n = p.net\n",
    "#         print(get_size(n.parameters()))\n",
    "#         for param in n.parameters():\n",
    "#             print(\" \" + str(get_size(param)))\n",
    "#             print(\" \" + str(len(param)))\n",
    "#             print(\" \" +str(param.shape))\n",
    "#             print(param)\n",
    "    cmd = 'ps -o pid,user,%mem,command -p ' + str(os.getpid())\n",
    "    print(os.system(cmd))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18\n",
      "1.18\n",
      "1.18\n",
      "1.18\n",
      "1.03\n",
      "1.47\n",
      "1.22\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(population[i].fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0].fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[1].fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[99].fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = rl_env.make('Hanabi-Full', num_players=2)\n",
    "state = environment.reset()\n",
    "while not state.is_terminal():\n",
    "    if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:  \n",
    "        state.deal_random_card()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(get_encoded_observations(obs_encoder, state, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_observations = torch.FloatTensor(get_encoded_observations(obs_encoder, state, 0))\n",
    "net(tensor_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net(tensor_observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_value = net(tensor_observations).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_value.index(max(move_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_observations(encoder, state, player_num):\n",
    "    codes = encoder.encode(state.observation(player_num))\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.cur_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_observations = get_encoded_observations(obs_encoder, state, state.cur_player())\n",
    "mytensor = list_to_tensor(encoded_observations)\n",
    "legal_moves = state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.new_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.life_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.fireworks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = rl_env.make('Hanabi-Full', num_players=2)\n",
    "state = environment.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = environment.reset()\n",
    "type(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = pyhanabi.HanabiGame()\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.pickle` not found.\n"
     ]
    }
   ],
   "source": [
    "tf.pickle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = \"ckpt\"\n",
    "iteration_number = 8500\n",
    "_base_directory = \"SelfPlay/SelfPlay1_7500_1735\"\n",
    "filename = '{}.{}'.format(file_prefix, iteration_number)\n",
    "filename =  os.path.join(_base_directory, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"SelfPlay/SelfPlay1_7500_1735/ckpt.7500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.gfile.GFile(filename, 'rb') as fin:\n",
    "    file_content = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'eval_mode', 'training_steps', 'batch_staged', 'current_iteration', 'logs'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_content['state'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v1.train' from '/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/_api/v1/train/__init__.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "  \"\"\"Returns the current epsilon parameter for the agent's e-greedy policy.\n",
    "\n",
    "  Args:\n",
    "    decay_period: float, the decay period for epsilon.\n",
    "    step: Integer, the number of training steps completed so far.\n",
    "    warmup_steps: int, the number of steps taken before training starts.\n",
    "    epsilon: float, the epsilon value.\n",
    "\n",
    "  Returns:\n",
    "    A float, the linearly decaying epsilon value.\n",
    "  \"\"\"\n",
    "  steps_left = decay_period + warmup_steps - step\n",
    "  bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "  bonus = np.clip(bonus, 0.0, 1.0 - epsilon)\n",
    "  return epsilon + bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn_template(state, num_actions, layer_size=512, num_layers=1):\n",
    "  r\"\"\"Builds a DQN Network mapping states to Q-values.\n",
    "\n",
    "  Args:\n",
    "    state: A `tf.placeholder` for the RL state.\n",
    "    num_actions: int, number of actions that the RL agent can take.\n",
    "    layer_size: int, number of hidden units per layer.\n",
    "    num_layers: int, Number of hidden layers.\n",
    "\n",
    "  Returns:\n",
    "    net: A `tf.Graphdef` for DQN:\n",
    "      `\\theta : \\mathcal{X}\\rightarrow\\mathbb{R}^{|\\mathcal{A}|}`\n",
    "  \"\"\"\n",
    "  weights_initializer = slim.variance_scaling_initializer(\n",
    "      factor=1.0 / np.sqrt(3.0), mode='FAN_IN', uniform=True)\n",
    "\n",
    "  net = tf.cast(state, tf.float32)\n",
    "  net = tf.squeeze(net, axis=2)\n",
    "  for _ in range(num_layers):\n",
    "    net = slim.fully_connected(net, layer_size,\n",
    "                               activation_fn=tf.nn.relu)\n",
    "  net = slim.fully_connected(net, num_actions, activation_fn=None,\n",
    "                             weights_initializer=weights_initializer)\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "  \"\"\"A compact implementation of the multiplayer DQN agent.\"\"\"\n",
    "  def __init__(self,\n",
    "               num_actions=None,\n",
    "               observation_size=None,\n",
    "               num_players=None,\n",
    "               gamma=0.99,\n",
    "               update_horizon=1,\n",
    "               min_replay_history=500,\n",
    "               update_period=4,\n",
    "               stack_size=1,\n",
    "               target_update_period=500,\n",
    "               epsilon_fn=linearly_decaying_epsilon,\n",
    "               epsilon_train=0.02,\n",
    "               epsilon_eval=0.001,\n",
    "               epsilon_decay_period=1000,\n",
    "               graph_template=dqn_template,\n",
    "               tf_device='/cpu:*',\n",
    "               use_staging=True,\n",
    "               optimizer=tf.train.RMSPropOptimizer(\n",
    "                   learning_rate=.0025,\n",
    "                   decay=0.95,\n",
    "                   momentum=0.0,\n",
    "                   epsilon=1e-6,\n",
    "                   centered=True)):\n",
    "    \"\"\"Initializes the agent and constructs its graph.\n",
    "\n",
    "    Args:\n",
    "      num_actions: int, number of actions the agent can take at any state.\n",
    "      observation_size: int, size of observation vector.\n",
    "      num_players: int, number of players playing this game.\n",
    "      gamma: float, discount factor as commonly used in the RL literature.\n",
    "      update_horizon: int, horizon at which updates are performed, the 'n' in\n",
    "        n-step update.\n",
    "      min_replay_history: int, number of stored transitions before training.\n",
    "      update_period: int, period between DQN updates.\n",
    "      stack_size: int, number of observations to use as state.\n",
    "      target_update_period: Update period for the target network.\n",
    "      epsilon_fn: Function expecting 4 parameters: (decay_period, step,\n",
    "        warmup_steps, epsilon), and which returns the epsilon value used for\n",
    "        exploration during training.\n",
    "      epsilon_train: float, final epsilon for training.\n",
    "      epsilon_eval: float, epsilon during evaluation.\n",
    "      epsilon_decay_period: int, number of steps for epsilon to decay.\n",
    "      graph_template: function for building the neural network graph.\n",
    "      tf_device: str, Tensorflow device on which to run computations.\n",
    "      use_staging: bool, when True use a staging area to prefetch the next\n",
    "        sampling batch.\n",
    "      optimizer: Optimizer instance used for learning.\n",
    "    \"\"\"\n",
    "\n",
    "    tf.logging.info('Creating %s agent with the following parameters:',\n",
    "                    self.__class__.__name__)\n",
    "    tf.logging.info('\\t gamma: %f', gamma)\n",
    "    tf.logging.info('\\t update_horizon: %f', update_horizon)\n",
    "    tf.logging.info('\\t min_replay_history: %d', min_replay_history)\n",
    "    tf.logging.info('\\t update_period: %d', update_period)\n",
    "    tf.logging.info('\\t target_update_period: %d', target_update_period)\n",
    "    tf.logging.info('\\t epsilon_train: %f', epsilon_train)\n",
    "    tf.logging.info('\\t epsilon_eval: %f', epsilon_eval)\n",
    "    tf.logging.info('\\t epsilon_decay_period: %d', epsilon_decay_period)\n",
    "    tf.logging.info('\\t tf_device: %s', tf_device)\n",
    "    tf.logging.info('\\t use_staging: %s', use_staging)\n",
    "    tf.logging.info('\\t optimizer: %s', optimizer)\n",
    "\n",
    "    # Global variables.\n",
    "    self.num_actions = num_actions\n",
    "    self.observation_size = observation_size\n",
    "    self.num_players = num_players\n",
    "    self.gamma = gamma\n",
    "    self.update_horizon = update_horizon\n",
    "    self.cumulative_gamma = math.pow(gamma, update_horizon)\n",
    "    self.min_replay_history = min_replay_history\n",
    "    self.target_update_period = target_update_period\n",
    "    self.epsilon_fn = epsilon_fn\n",
    "    self.epsilon_train = epsilon_train\n",
    "    self.epsilon_eval = epsilon_eval\n",
    "    self.epsilon_decay_period = epsilon_decay_period\n",
    "    self.update_period = update_period\n",
    "    self.eval_mode = False\n",
    "    self.training_steps = 0\n",
    "    self.batch_staged = False\n",
    "    self.optimizer = optimizer\n",
    "\n",
    "    with tf.device(tf_device):\n",
    "      # Calling online_convnet will generate a new graph as defined in\n",
    "      # graph_template using whatever input is passed, but will always share\n",
    "      # the same weights.\n",
    "      online_convnet = tf.make_template('Online', graph_template)\n",
    "      target_convnet = tf.make_template('Target', graph_template)\n",
    "      # The state of the agent. The last axis is the number of past observations\n",
    "      # that make up the state.\n",
    "      states_shape = (1, observation_size, stack_size)\n",
    "      self.state = np.zeros(states_shape)\n",
    "      self.state_ph = tf.placeholder(tf.uint8, states_shape, name='state_ph')\n",
    "      self.legal_actions_ph = tf.placeholder(tf.float32,\n",
    "                                             [self.num_actions],\n",
    "                                             name='legal_actions_ph')\n",
    "      self._q = online_convnet(\n",
    "          state=self.state_ph, num_actions=self.num_actions)\n",
    "      self._replay = self._build_replay_memory(use_staging)\n",
    "      self._replay_qs = online_convnet(self._replay.states, self.num_actions)\n",
    "      self._replay_next_qt = target_convnet(self._replay.next_states,\n",
    "                                            self.num_actions)\n",
    "      self._train_op = self._build_train_op()\n",
    "      self._sync_qt_ops = self._build_sync_op()\n",
    "\n",
    "      self._q_argmax = tf.argmax(self._q + self.legal_actions_ph, axis=1)[0]\n",
    "\n",
    "    # Set up a session and initialize variables.\n",
    "    self._sess = tf.Session(\n",
    "        '', config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    self._init_op = tf.global_variables_initializer()\n",
    "    self._sess.run(self._init_op)\n",
    "\n",
    "    self._saver = tf.train.Saver(max_to_keep=0)\n",
    "\n",
    "    # This keeps tracks of the observed transitions during play, for each\n",
    "    # player.\n",
    "    self.transitions = [[] for _ in range(num_players)]\n",
    "  def unbundle(self, checkpoint_dir, iteration_number, bundle_dictionary):\n",
    "    \"\"\"Restores the agent from a checkpoint.\n",
    "\n",
    "    Restores the agent's Python objects to those specified in bundle_dictionary,\n",
    "    and restores the TensorFlow objects to those specified in the\n",
    "    checkpoint_dir. If the checkpoint_dir does not exist, will not reset the\n",
    "      agent's state.\n",
    "\n",
    "    Args:\n",
    "      checkpoint_dir: str, path to the checkpoint saved by `tf.Save`.\n",
    "      iteration_number: int, checkpoint version.\n",
    "      bundle_dictionary: Dictionary containing this class's Python objects.\n",
    "\n",
    "    Returns:\n",
    "      A boolean indicating whether unbundling was successful.\n",
    "    \"\"\"\n",
    "    try:\n",
    "      # replay.load() will throw a GOSError if it does not find all the\n",
    "      # necessary files, in which case we should abort the process.\n",
    "      self._replay.load(checkpoint_dir, iteration_number)\n",
    "    except tf.errors.NotFoundError:\n",
    "      return False\n",
    "    for key in self.__dict__:\n",
    "      if key in bundle_dictionary:\n",
    "        self.__dict__[key] = bundle_dictionary[key]\n",
    "    # print(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    # path = tf.train.latest_checkpoint(checkpoint_dir).split(\"-\")\n",
    "    # path[-1] = str(iteration_number)\n",
    "    # path = \"-\".join(path)\n",
    "    # print(path)\n",
    "    # self._saver.restore(self._sess, path)\n",
    "    self._saver.restore(self._sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating DQNAgent agent with the following parameters:\n",
      "INFO:tensorflow:\t gamma: 0.990000\n",
      "INFO:tensorflow:\t update_horizon: 1.000000\n",
      "INFO:tensorflow:\t min_replay_history: 500\n",
      "INFO:tensorflow:\t update_period: 4\n",
      "INFO:tensorflow:\t target_update_period: 500\n",
      "INFO:tensorflow:\t epsilon_train: 0.020000\n",
      "INFO:tensorflow:\t epsilon_eval: 0.001000\n",
      "INFO:tensorflow:\t epsilon_decay_period: 1000\n",
      "INFO:tensorflow:\t tf_device: /cpu:*\n",
      "INFO:tensorflow:\t use_staging: True\n",
      "INFO:tensorflow:\t optimizer: <tensorflow.python.training.rmsprop.RMSPropOptimizer object at 0x1a9e5425d0>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e4a6de90fd43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-3bf9752d9084>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_actions, observation_size, num_players, gamma, update_horizon, min_replay_history, update_period, stack_size, target_update_period, epsilon_fn, epsilon_train, epsilon_eval, epsilon_decay_period, graph_template, tf_device, use_staging, optimizer)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;31m# that make up the state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0mstates_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'state_ph'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       self.legal_actions_ph = tf.placeholder(tf.float32,\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.RMSPropOptimizer(\n",
    "                   learning_rate=.0025,\n",
    "                   decay=0.95,\n",
    "                   momentum=0.0,\n",
    "                   epsilon=1e-6,\n",
    "                   centered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No variables to save",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-049203a4305f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m    826\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m    827\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    863\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No variables to save"
     ]
    }
   ],
   "source": [
    "_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
