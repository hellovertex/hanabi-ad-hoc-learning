{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhanabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "#import checkpointer\n",
    "#import iteration_statistics\n",
    "#import dqn_agent\n",
    "#import gin.tf\n",
    "import rl_env\n",
    "import numpy as np\n",
    "#import rainbow_agent\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "import rl_env\n",
    "#import run_paired_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_encoded_observations(encoder, state, num_players):\n",
    "    print(\"--- EncodedObservations ---\")\n",
    "    print(\"Observation encoding shape: {}\".format(encoder.shape()))\n",
    "    print(\"Current actual player: {}\".format(state.cur_player()))\n",
    "    for i in range(num_players):\n",
    "      print(\"Encoded observation for player {}: {}\".format(\n",
    "          i, encoder.encode(state.observation(i))))\n",
    "    print(\"--- EndEncodedObservations ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_observations(encoder, state, player_num):\n",
    "    codes = encoder.encode(state.observation(player_num))\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_observation(observation):\n",
    "    \"\"\"Print some basic information about an agent observation.\"\"\"\n",
    "    print(\"--- Observation ---\")\n",
    "    print(observation)\n",
    "\n",
    "    print(\"### Information about the observation retrieved separately ###\")\n",
    "    print(\"### Current player, relative to self: {}\".format(\n",
    "        observation.cur_player_offset()))\n",
    "    print(\"### Observed hands: {}\".format(observation.observed_hands()))\n",
    "    print(\"### Card knowledge: {}\".format(observation.card_knowledge()))\n",
    "    print(\"### Discard pile: {}\".format(observation.discard_pile()))\n",
    "    print(\"### Fireworks: {}\".format(observation.fireworks()))\n",
    "    print(\"### Deck size: {}\".format(observation.deck_size()))\n",
    "    move_string = \"### Last moves:\"\n",
    "    for move_tuple in observation.last_moves():\n",
    "      move_string += \" {}\".format(move_tuple)\n",
    "    print(move_string)\n",
    "    print(\"### Information tokens: {}\".format(observation.information_tokens()))\n",
    "    print(\"### Life tokens: {}\".format(observation.life_tokens()))\n",
    "    print(\"### Legal moves: {}\".format(observation.legal_moves()))\n",
    "    print(\"--- EndObservation ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state(state):\n",
    "    \"\"\"Print some basic information about the state.\"\"\"\n",
    "    print(\"\")\n",
    "    print(\"Current player: {}\".format(state.cur_player()))\n",
    "    print(state)\n",
    "\n",
    "    # Example of more queries to provide more about this state. For\n",
    "    # example, bots could use these methods to to get information\n",
    "    # about the state in order to act accordingly.\n",
    "    print(\"### Information about the state retrieved separately ###\")\n",
    "    print(\"### Information tokens: {}\".format(state.information_tokens()))\n",
    "    print(\"### Life tokens: {}\".format(state.life_tokens()))\n",
    "    print(\"### Fireworks: {}\".format(state.fireworks()))\n",
    "    print(\"### Deck size: {}\".format(state.deck_size()))\n",
    "    print(\"### Discard pile: {}\".format(str(state.discard_pile())))\n",
    "    print(\"### Player hands: {}\".format(str(state.player_hands())))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from rl_env import Agent\n",
    "\n",
    "\n",
    "class RandomAgent():\n",
    "    def act(self, observation):\n",
    "        \"\"\"Act based on an observation.\"\"\"\n",
    "        return random.choice(observation.legal_moves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = RandomAgent()\n",
    "agent = RandomAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-1.8085e-02,  3.3283e-02, -9.3793e-03,  ...,  1.0604e-02,\n",
      "          1.2678e-02, -1.5251e-02],\n",
      "        [ 1.6680e-02, -1.4953e-03, -3.5092e-02,  ...,  2.9013e-02,\n",
      "          4.3534e-05, -2.2534e-02],\n",
      "        [-1.2419e-02, -7.7553e-03, -3.5022e-03,  ..., -2.1426e-02,\n",
      "          1.8194e-02, -2.5229e-02],\n",
      "        ...,\n",
      "        [ 2.7995e-03,  2.8872e-02,  1.1859e-02,  ...,  1.8105e-02,\n",
      "          4.6899e-03, -7.2390e-03],\n",
      "        [-9.1161e-03, -3.7539e-03,  3.6230e-02,  ..., -1.8333e-02,\n",
      "         -1.9359e-02,  6.0310e-03],\n",
      "        [ 3.4444e-02,  2.0447e-02,  1.2858e-02,  ..., -3.3766e-02,\n",
      "          1.5325e-02,  1.6319e-02]], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[ 0.0037,  0.0338,  0.0053,  ...,  0.0020, -0.0018, -0.0068],\n",
      "        [-0.0085, -0.0008, -0.0025,  ...,  0.0010,  0.0188,  0.0186],\n",
      "        [ 0.0090,  0.0057, -0.0025,  ...,  0.0091, -0.0042, -0.0102],\n",
      "        ...,\n",
      "        [-0.0046,  0.0005, -0.0014,  ..., -0.0092,  0.0046, -0.0050],\n",
      "        [ 0.0362, -0.0100, -0.0105,  ..., -0.0071, -0.0116, -0.0116],\n",
      "        [ 0.0013, -0.0108,  0.0026,  ...,  0.0047,  0.0158, -0.0126]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0144,  0.0671, -0.0041,  ...,  0.0126,  0.0108, -0.0221],\n",
      "        [ 0.0081, -0.0023, -0.0376,  ...,  0.0300,  0.0188, -0.0040],\n",
      "        [-0.0034, -0.0020, -0.0060,  ..., -0.0123,  0.0140, -0.0355],\n",
      "        ...,\n",
      "        [-0.0018,  0.0294,  0.0105,  ...,  0.0089,  0.0092, -0.0123],\n",
      "        [ 0.0271, -0.0137,  0.0257,  ..., -0.0255, -0.0309, -0.0055],\n",
      "        [ 0.0357,  0.0097,  0.0154,  ..., -0.0291,  0.0312,  0.0038]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 2.9635e-03,  1.4653e-02,  3.6442e-02,  6.6469e-03,  2.9572e-02,\n",
      "        -2.8889e-02,  2.4818e-02,  3.5093e-02,  1.4321e-02, -1.5744e-02,\n",
      "         2.6680e-02,  1.6126e-02,  1.6942e-02,  2.8654e-02,  1.5211e-02,\n",
      "        -2.5597e-02,  1.6400e-02, -2.7854e-03, -3.3636e-02,  3.5253e-02,\n",
      "        -1.7909e-02, -2.6552e-02,  1.6183e-02, -2.9163e-02,  2.7090e-02,\n",
      "         3.5299e-02,  3.6808e-02,  1.9562e-02,  2.5428e-02, -2.7256e-02,\n",
      "        -6.3864e-03, -5.9462e-04,  1.3267e-03,  2.1971e-02, -1.0383e-02,\n",
      "        -1.3785e-02, -3.1397e-02, -2.8509e-02, -1.8661e-02, -2.4698e-03,\n",
      "         3.7262e-02,  3.3366e-02, -3.2816e-02,  1.1135e-02, -2.8893e-02,\n",
      "        -2.9409e-02, -1.9025e-02,  1.3854e-04, -8.0462e-03, -2.0382e-02,\n",
      "         3.8620e-02, -3.5651e-02,  1.7868e-02,  2.8319e-02, -1.4665e-02,\n",
      "        -2.3059e-02, -1.8062e-02,  2.0823e-02,  2.9722e-02, -2.3068e-02,\n",
      "         7.1303e-03,  2.4943e-03, -1.0116e-03, -3.1778e-02, -2.1909e-02,\n",
      "        -3.8074e-02,  2.0646e-02, -3.2159e-02,  1.0797e-02, -3.5140e-02,\n",
      "         3.3568e-02, -3.4446e-02,  1.3508e-02, -1.6116e-02,  1.1536e-02,\n",
      "        -5.8840e-04,  1.2169e-02, -4.0023e-03,  3.8836e-02,  1.4905e-02,\n",
      "         3.8691e-02, -2.9168e-02,  3.1400e-02, -2.0945e-02,  1.3848e-02,\n",
      "         3.3694e-02, -1.1688e-02,  1.4290e-02, -4.4384e-03,  1.9911e-02,\n",
      "         1.2571e-02,  1.8135e-02, -2.9313e-02,  2.8904e-02, -1.7291e-02,\n",
      "        -2.1572e-02, -6.2361e-03, -2.4161e-02,  3.2806e-02, -3.3947e-02,\n",
      "        -1.5511e-04, -1.9533e-03, -3.8954e-02,  2.2524e-02, -3.3925e-02,\n",
      "         2.9512e-02, -2.2811e-02, -3.0871e-02, -5.4393e-03, -8.6236e-03,\n",
      "         3.5361e-03, -1.4191e-02,  3.6784e-02, -2.5246e-02,  3.0509e-02,\n",
      "        -3.5428e-02,  7.7443e-03,  2.7629e-02, -7.2685e-03,  3.2237e-02,\n",
      "        -9.3723e-03, -1.4564e-02,  1.0420e-02,  2.6379e-02, -1.4916e-02,\n",
      "        -3.1595e-02,  3.4143e-02,  3.6345e-03, -1.5630e-02, -1.3972e-04,\n",
      "        -1.7105e-02, -3.5044e-02,  3.0732e-02,  2.7839e-02, -2.9188e-03,\n",
      "        -6.3076e-03,  3.8172e-02,  8.1633e-03, -1.3543e-02,  3.4231e-02,\n",
      "        -2.1337e-02, -2.4276e-02,  1.2417e-02, -1.1725e-02, -3.1463e-02,\n",
      "         2.0518e-02,  1.0544e-02, -3.2538e-03, -1.9392e-02, -1.8089e-02,\n",
      "        -8.0081e-03, -1.2833e-02, -3.7463e-02,  3.0939e-02, -1.4497e-02,\n",
      "         1.3140e-02,  2.6531e-02,  1.3724e-02,  2.6146e-02,  2.0212e-02,\n",
      "        -2.9975e-02, -2.6930e-02,  3.8133e-02, -1.8719e-02, -2.1577e-02,\n",
      "        -2.8406e-02,  8.0731e-04,  3.8941e-02, -2.6237e-03, -2.3312e-02,\n",
      "         1.4567e-02, -1.6535e-02, -5.9290e-03, -2.4228e-02, -2.1257e-02,\n",
      "        -7.5976e-03, -2.1052e-02,  3.0802e-02,  2.6970e-02, -2.1085e-02,\n",
      "         5.4479e-03, -3.0027e-02, -3.3976e-02, -4.5849e-03,  1.8805e-02,\n",
      "        -1.9917e-02,  3.1336e-02,  2.0788e-02, -1.5147e-02, -1.3597e-02,\n",
      "        -8.2930e-03, -2.0157e-02,  3.8295e-02, -3.1231e-02,  5.1049e-03,\n",
      "        -9.3049e-03, -1.3335e-02, -2.2378e-02, -5.1875e-03,  2.2352e-02,\n",
      "        -5.8105e-03,  3.8101e-02, -2.6573e-02,  3.0711e-02,  3.0788e-02,\n",
      "        -1.8243e-02, -2.9967e-02, -2.3649e-02,  3.6290e-02, -1.5620e-02,\n",
      "        -3.7487e-02,  3.4034e-02, -3.4747e-02,  1.7735e-02,  6.9053e-03,\n",
      "        -1.5821e-02,  2.3573e-02,  3.3369e-02, -1.3493e-02, -3.0856e-02,\n",
      "        -2.7132e-02, -1.9780e-02,  1.2705e-03,  3.2808e-02, -3.1342e-03,\n",
      "        -3.8634e-02,  2.0420e-02,  1.6488e-02,  2.9530e-02, -2.2612e-02,\n",
      "         1.1712e-02,  8.7434e-03, -1.1648e-02,  3.2182e-02,  1.1413e-02,\n",
      "        -3.7897e-02,  3.7453e-02,  3.6140e-02, -1.9646e-02, -3.4984e-02,\n",
      "         3.6704e-02, -2.8606e-02, -1.3648e-03,  3.8185e-02,  1.9823e-02,\n",
      "        -5.1489e-03, -3.8540e-02, -2.7421e-02,  2.1303e-03,  8.8084e-05,\n",
      "        -1.3677e-02,  1.6797e-02, -1.9665e-02, -3.5492e-03,  2.2612e-02,\n",
      "         2.3272e-02,  3.2034e-02, -3.1062e-02,  8.3646e-03, -3.6119e-02,\n",
      "         1.4287e-02,  1.4969e-02, -3.6971e-02, -1.2092e-02, -1.9837e-02,\n",
      "        -2.6580e-03,  2.5110e-02, -1.1647e-02,  2.8401e-02, -3.5790e-02,\n",
      "         9.2449e-03, -1.7791e-02, -1.4120e-03,  1.0141e-02, -8.4649e-04,\n",
      "         8.5334e-03, -3.0333e-02,  3.8047e-02, -3.8745e-02,  3.8701e-02,\n",
      "        -1.2795e-02, -4.8158e-03, -1.2117e-02,  1.8149e-02,  1.4980e-02,\n",
      "         1.2365e-02,  2.3192e-02,  6.1854e-03,  1.6589e-03, -3.6935e-02,\n",
      "         2.8583e-02, -3.5995e-02,  1.8534e-03,  3.8024e-02, -3.7750e-02,\n",
      "         1.4153e-02,  1.4102e-02,  1.3855e-02, -3.0918e-02, -1.0597e-02,\n",
      "         1.9143e-02, -6.9472e-03,  1.5963e-02, -1.8085e-02,  3.4607e-02,\n",
      "        -2.9470e-02, -3.4803e-02, -2.4804e-02, -2.4690e-02, -8.2319e-03,\n",
      "         3.0598e-02,  2.6055e-02,  2.4517e-02, -2.3147e-02,  2.7218e-02,\n",
      "         2.8197e-02,  2.0606e-02, -2.7058e-02,  9.5661e-03,  3.6813e-02,\n",
      "        -1.7186e-02,  5.2928e-03,  1.6932e-02, -2.3201e-02,  8.5134e-05,\n",
      "         2.2838e-02, -5.8230e-03, -1.8117e-02,  4.3480e-03, -2.1150e-02,\n",
      "        -2.9445e-05,  8.5929e-03,  3.5260e-03,  1.4469e-02, -2.0095e-02,\n",
      "         2.2743e-02, -1.7634e-02, -2.9054e-02,  1.4230e-02, -4.7016e-03,\n",
      "         2.7738e-02,  1.7306e-02, -1.2785e-03,  3.7229e-02, -2.3630e-02,\n",
      "         3.0222e-02, -2.1805e-02,  1.5333e-02,  2.1544e-03, -3.8267e-02,\n",
      "         1.4856e-02,  1.1665e-02,  1.7282e-02, -4.1529e-04,  2.8345e-02,\n",
      "        -7.7544e-03,  2.8257e-02,  9.7619e-03, -7.0536e-03, -3.3596e-02,\n",
      "         1.7147e-02,  2.0086e-02, -4.6033e-03,  2.5442e-02,  1.6090e-02,\n",
      "         2.6674e-02,  1.7575e-02,  1.2372e-02,  2.0197e-02,  2.8670e-02,\n",
      "        -2.2650e-02,  3.8975e-02,  3.4829e-02,  1.2293e-02, -1.2536e-02,\n",
      "         9.4663e-03, -3.5159e-02, -1.2503e-02, -2.9384e-03, -5.0462e-03,\n",
      "         1.8273e-03, -2.8372e-02, -6.0662e-03,  2.5775e-02, -1.2473e-03,\n",
      "        -1.4613e-02,  2.7710e-02,  2.2813e-02,  1.5002e-03,  2.0346e-02,\n",
      "        -2.8940e-02, -2.9886e-02,  2.9044e-02, -2.6376e-02, -2.3130e-03,\n",
      "         2.4863e-03, -1.4399e-02,  2.7356e-02,  2.5135e-02, -2.7321e-02,\n",
      "        -1.8446e-02,  1.6796e-02, -2.2678e-02,  2.6350e-02, -7.0768e-03,\n",
      "         3.2635e-02, -2.3805e-02,  7.8865e-03, -3.2866e-02, -9.7642e-03,\n",
      "        -1.2912e-02, -2.1949e-03,  1.3587e-02,  3.8963e-02, -3.7363e-02,\n",
      "         1.7049e-02,  2.2369e-02, -1.6634e-02,  3.8861e-03, -2.2728e-02,\n",
      "        -2.4560e-02,  7.8295e-03,  2.3563e-02, -3.8515e-02,  2.8912e-02,\n",
      "        -1.0002e-02,  3.5323e-03,  1.2734e-02, -2.5320e-02, -2.8965e-03,\n",
      "         3.8268e-02, -2.7867e-02, -9.3053e-03,  1.2230e-02, -2.7258e-02,\n",
      "         1.5946e-02,  3.8734e-02,  4.1226e-03, -3.1839e-02,  9.3554e-03,\n",
      "        -2.5618e-02,  3.4907e-03, -3.7296e-02, -3.4564e-02,  2.3716e-02,\n",
      "         2.0954e-02, -3.7586e-02, -3.7391e-02, -1.3309e-02,  1.2149e-02,\n",
      "        -3.1076e-02,  6.3078e-03, -1.7014e-02, -1.5923e-02, -1.4117e-02,\n",
      "        -2.8650e-02, -3.8163e-03, -1.4690e-02,  8.7965e-03, -4.4636e-03,\n",
      "         2.9750e-02,  2.5403e-02, -3.0311e-03, -3.2178e-02,  3.7784e-02,\n",
      "        -8.7453e-03,  2.1000e-02, -1.8465e-02, -1.9710e-02,  1.1005e-02,\n",
      "        -2.1358e-02, -6.7365e-03, -2.9308e-02, -8.9999e-03, -2.4773e-02,\n",
      "         5.6130e-03, -9.2414e-03,  5.1732e-03, -1.7996e-02, -3.5375e-02,\n",
      "        -3.1379e-02, -3.6042e-02, -3.0679e-02,  2.1704e-02, -3.5633e-02,\n",
      "         2.4043e-02,  1.5803e-02, -3.5306e-02, -3.0985e-02, -3.2647e-02,\n",
      "         8.0861e-03, -2.7067e-02, -2.1245e-02, -1.6190e-03,  7.5937e-03,\n",
      "        -4.3800e-03, -1.0528e-02,  3.6225e-02,  1.4873e-02,  1.4946e-02,\n",
      "         2.5217e-02, -1.6591e-02, -3.5102e-02,  1.8292e-02, -1.0037e-02,\n",
      "         8.1909e-03, -3.3120e-02, -3.7805e-02,  2.3716e-02, -9.4848e-03,\n",
      "        -1.7954e-03, -8.0020e-03], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-3.2877e-02, -2.4876e-03, -5.3173e-03, -1.4696e-02, -1.1109e-02,\n",
      "        -7.9672e-03,  7.1170e-03, -1.4917e-02,  3.9464e-03,  6.0043e-03,\n",
      "         5.2198e-03, -2.7263e-03,  1.3003e-02, -1.5088e-02, -6.9056e-03,\n",
      "         8.2287e-03,  1.6656e-02,  1.7385e-02, -2.9257e-03, -4.5585e-03,\n",
      "         1.3461e-02,  1.8168e-03,  8.6949e-03, -1.1536e-02, -9.9767e-03,\n",
      "         7.1234e-03, -1.0601e-02,  1.3345e-02, -7.9809e-03, -8.5809e-03,\n",
      "         1.6374e-02,  9.9025e-04, -1.5518e-04, -2.4936e-02,  1.9980e-02,\n",
      "        -6.5364e-03, -2.8980e-03,  1.8415e-02, -1.0492e-02,  5.5149e-03,\n",
      "        -1.6035e-03, -8.4557e-03, -1.0577e-02,  2.1279e-03, -4.0008e-03,\n",
      "        -8.5507e-04, -6.7895e-03, -2.6336e-03,  1.0623e-02,  2.4843e-02,\n",
      "        -6.8776e-03, -7.6152e-03, -9.3843e-03, -1.2487e-02, -8.6449e-03,\n",
      "         1.2846e-02,  1.3158e-02, -9.6916e-03, -8.1880e-03,  8.4150e-03,\n",
      "         7.0346e-03, -4.8205e-03,  4.3171e-03,  7.3266e-03,  1.3503e-02,\n",
      "        -8.1350e-03, -2.4886e-02, -5.5153e-03, -2.5045e-03, -8.4519e-03,\n",
      "        -5.0224e-03, -8.5555e-03,  1.8339e-02, -1.0903e-02,  1.4546e-03,\n",
      "         1.1109e-02,  1.4051e-02, -1.1282e-02,  6.6994e-03, -7.8758e-03,\n",
      "         1.2070e-02, -9.6318e-04, -4.9424e-03,  5.4079e-03,  5.3572e-03,\n",
      "        -6.5429e-04, -4.9722e-03, -5.2240e-03, -2.0968e-03,  1.4210e-02,\n",
      "        -6.5444e-03,  3.3136e-03, -3.7753e-04, -1.6224e-02,  1.0222e-02,\n",
      "         5.6408e-03,  4.6206e-03, -8.7892e-03,  5.6745e-03,  5.1879e-03,\n",
      "        -1.7589e-02,  6.8678e-04, -1.7651e-02, -1.3122e-02,  1.0292e-02,\n",
      "        -1.3054e-02, -7.2003e-03,  9.1829e-03, -6.9234e-03, -1.2049e-02,\n",
      "         4.9965e-03, -3.3415e-03, -1.1101e-02,  6.2079e-03,  6.7153e-03,\n",
      "        -1.2520e-02, -1.6371e-03, -5.5218e-04,  8.5455e-03,  7.5174e-03,\n",
      "         5.6306e-03,  1.9718e-02, -1.3633e-03,  4.2444e-03, -5.2030e-03,\n",
      "        -9.5692e-03,  3.2330e-03,  1.3413e-02, -7.5289e-03,  1.2150e-03,\n",
      "        -1.3408e-02,  7.0175e-04, -9.3072e-03,  1.1539e-02,  7.3541e-03,\n",
      "         1.3075e-02, -3.1099e-03,  9.1061e-03, -2.1471e-03, -9.1346e-03,\n",
      "         3.0283e-03, -2.0801e-03, -1.5889e-02, -1.2595e-02, -1.2691e-02,\n",
      "         4.8654e-03, -1.2659e-02, -1.7314e-02,  8.3205e-03, -3.3005e-03,\n",
      "        -1.5135e-02,  1.8233e-04,  1.9222e-02, -1.3159e-02, -1.4571e-02,\n",
      "         4.7223e-03,  1.0136e-02,  1.5004e-02,  6.0034e-03, -9.7485e-03,\n",
      "         1.4039e-03,  1.7130e-02,  1.3551e-02, -1.0626e-02,  3.1205e-03,\n",
      "        -3.4546e-03,  1.8102e-02,  1.2273e-02, -5.3423e-03, -1.7413e-02,\n",
      "        -6.7759e-03,  4.0320e-03, -5.2986e-04, -1.4444e-02,  1.2652e-03,\n",
      "        -4.6194e-04, -2.0769e-02, -4.8355e-03, -4.6360e-03,  9.5385e-04,\n",
      "         2.8502e-03, -7.7942e-03,  1.4461e-03, -8.7690e-03,  3.4682e-03,\n",
      "         7.1879e-03,  1.0505e-03, -3.7391e-02, -6.9014e-03,  1.6894e-02,\n",
      "        -1.5845e-02, -1.0053e-02,  9.2367e-03, -8.8519e-03,  2.3262e-02,\n",
      "        -1.8289e-04, -4.0170e-03,  1.0037e-02, -5.7034e-03,  7.1946e-03,\n",
      "         3.3497e-03, -1.4550e-02,  5.5553e-03,  2.3244e-02,  1.2356e-02,\n",
      "        -5.6757e-03, -4.1096e-03, -2.4090e-03,  1.2431e-02, -1.3649e-02,\n",
      "        -3.0957e-03,  7.1697e-03, -1.4001e-03,  1.6385e-02,  1.0760e-02,\n",
      "         6.3801e-03, -1.6450e-02,  3.3982e-03, -5.6180e-03,  4.1690e-03,\n",
      "         6.7647e-03, -8.2364e-03,  2.7764e-03,  4.1689e-03, -1.6506e-02,\n",
      "        -4.4239e-03, -5.4855e-03,  2.0863e-03, -1.4834e-02,  3.2515e-04,\n",
      "         9.2575e-03, -8.5717e-03, -9.8578e-03, -3.6467e-03,  6.3841e-03,\n",
      "         1.2540e-02,  1.5478e-03,  6.8956e-03, -1.8647e-02, -2.1716e-02,\n",
      "         5.1152e-03, -1.0028e-02,  2.6794e-02,  8.0242e-03, -5.3111e-03,\n",
      "         3.5987e-03, -3.5694e-03,  2.1684e-02,  5.5819e-03, -9.5854e-03,\n",
      "         6.1787e-03,  4.2904e-03,  6.8971e-04,  4.7569e-03,  6.9915e-03,\n",
      "         1.3726e-02, -2.6594e-03, -5.1547e-03,  1.1799e-02,  4.5326e-04,\n",
      "         8.2169e-03,  5.1496e-03,  3.9775e-03, -6.8998e-04,  5.2677e-03,\n",
      "         5.7793e-03,  8.6975e-03,  4.8033e-03,  2.0219e-02, -1.6783e-02,\n",
      "        -2.0713e-02,  1.2794e-02, -7.4695e-03,  1.3289e-02, -1.0828e-02,\n",
      "         1.4621e-02,  4.3179e-03,  1.4862e-03,  1.1974e-02, -1.5821e-02,\n",
      "        -9.6411e-03, -9.5105e-03,  9.7927e-03,  2.1860e-02,  2.6396e-05,\n",
      "        -1.6529e-03, -1.1056e-02, -1.6546e-02,  4.6704e-03,  5.1676e-03,\n",
      "         5.5101e-03, -1.1069e-02,  4.0701e-03, -1.1115e-02,  7.4118e-03,\n",
      "        -1.3840e-02, -4.9173e-03,  2.1775e-02,  6.5851e-04,  9.3934e-04,\n",
      "        -7.5752e-03, -3.5407e-02,  2.0036e-03,  4.5194e-03, -5.2139e-03,\n",
      "        -2.1829e-03,  1.0714e-03, -2.1807e-02,  1.6608e-03, -1.3473e-02,\n",
      "        -2.5995e-03, -1.1184e-02, -7.5810e-03,  1.4504e-02,  9.7259e-03,\n",
      "        -1.5868e-02,  1.7612e-03, -5.6893e-03, -4.4608e-03, -2.4155e-03,\n",
      "        -9.8150e-03,  1.4786e-02,  8.0807e-03,  2.6953e-03,  8.4540e-03,\n",
      "         2.5876e-03, -4.3147e-03,  4.5800e-03,  6.1188e-03,  1.7226e-02,\n",
      "         2.4547e-03, -7.9803e-03, -1.4806e-03,  4.1896e-04,  7.1294e-04,\n",
      "         1.3921e-02,  5.4473e-03,  9.9063e-05,  1.5270e-02, -6.9814e-03,\n",
      "        -4.0282e-03,  3.0029e-03, -1.9394e-03, -1.0962e-02,  3.2893e-03,\n",
      "         1.3408e-03,  7.1710e-03, -1.4698e-02,  9.6706e-03,  8.1511e-03,\n",
      "         4.4331e-03,  1.0763e-02, -6.5358e-03,  1.1349e-02, -9.8276e-03,\n",
      "        -4.9412e-03, -4.0608e-03,  7.1021e-04, -1.4614e-02,  2.2638e-02,\n",
      "        -3.9664e-03, -2.3307e-02,  2.9687e-03,  5.3238e-03, -9.4346e-03,\n",
      "         4.6782e-03, -2.3913e-03, -1.3725e-02,  9.7377e-03, -7.8651e-03,\n",
      "         4.6133e-03,  6.0109e-03,  5.1832e-03, -9.0268e-03,  4.6565e-03,\n",
      "         7.4755e-03,  9.8564e-03, -1.3842e-02, -1.1256e-02,  2.1203e-02,\n",
      "         2.6506e-03,  1.9901e-03, -7.3997e-03,  4.8049e-03,  1.4247e-02,\n",
      "         2.9888e-03,  4.2123e-03,  6.2473e-03, -5.1362e-03, -1.0091e-02,\n",
      "         1.0567e-02, -1.1299e-02,  6.6255e-03,  8.9109e-03,  1.1321e-02,\n",
      "        -1.2362e-02, -1.3269e-02,  3.3108e-03, -3.4322e-03,  2.1260e-04,\n",
      "         3.5100e-04,  1.4623e-03, -1.9540e-02,  7.6505e-03,  5.6630e-03,\n",
      "        -5.1229e-03,  5.7296e-03, -4.5310e-03,  1.9598e-03, -8.2018e-04,\n",
      "        -2.0888e-03, -2.3980e-02, -3.2302e-03, -1.4247e-02, -2.4274e-03,\n",
      "         2.3256e-03,  1.5860e-02, -2.1929e-03,  4.3824e-04,  7.4089e-04,\n",
      "         4.2830e-03, -4.0824e-03,  6.9311e-03,  2.2359e-02, -1.7033e-02,\n",
      "         7.9096e-04, -4.2970e-03, -3.5650e-03, -1.5503e-03, -7.6442e-03,\n",
      "        -3.8927e-03,  2.4444e-02,  3.9077e-03, -9.8863e-03,  1.0270e-03,\n",
      "        -1.1188e-02, -5.1909e-03, -8.5443e-03, -1.1127e-02, -1.6208e-02,\n",
      "        -5.0151e-03, -1.6602e-02,  1.6034e-03, -1.2341e-02, -9.1954e-03,\n",
      "         9.4946e-03, -1.0510e-02, -3.1451e-03,  3.4588e-03, -6.5034e-03,\n",
      "         8.0906e-04, -5.6163e-03, -4.6285e-03, -1.0848e-02, -6.9351e-03,\n",
      "        -6.9840e-03,  2.0678e-02,  1.1677e-02, -4.5185e-03,  2.0279e-02,\n",
      "         5.8237e-03,  4.2044e-03,  3.8114e-03, -1.5297e-02, -6.3694e-03,\n",
      "        -5.3603e-03,  1.6751e-02,  1.8342e-03, -1.3581e-02,  2.3880e-03,\n",
      "         1.4186e-02,  1.1925e-02, -6.0127e-03,  5.1134e-03, -5.9205e-03,\n",
      "         2.7272e-03,  1.5875e-03, -1.3732e-03,  5.1129e-05,  6.6718e-03,\n",
      "        -1.0361e-02,  6.5484e-03, -7.5837e-04, -1.3093e-03, -1.3724e-03,\n",
      "         9.1483e-03, -3.8465e-03, -4.0942e-03, -5.0478e-03,  8.4431e-03,\n",
      "         6.0338e-03,  2.1592e-03,  9.0820e-03, -3.6356e-03,  2.6997e-03,\n",
      "        -1.0616e-03,  1.0699e-02, -9.7245e-03, -1.7654e-02,  1.1421e-02,\n",
      "         3.4910e-03, -2.7524e-03,  1.0042e-02, -9.9530e-03, -1.6294e-03,\n",
      "         5.7010e-03, -4.3761e-03,  8.1254e-03,  3.0549e-03, -1.9457e-03,\n",
      "        -5.0004e-03,  7.1033e-03])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0299,  0.0122,  0.0311, -0.0080,  0.0185, -0.0369,  0.0319,  0.0202,\n",
      "         0.0183, -0.0097,  0.0319,  0.0134,  0.0299,  0.0136,  0.0083, -0.0174,\n",
      "         0.0331,  0.0146, -0.0366,  0.0307, -0.0044, -0.0247,  0.0249, -0.0407,\n",
      "         0.0171,  0.0424,  0.0262,  0.0329,  0.0174, -0.0358,  0.0100,  0.0004,\n",
      "         0.0012, -0.0030,  0.0096, -0.0203, -0.0343, -0.0101, -0.0292,  0.0030,\n",
      "         0.0357,  0.0249, -0.0434,  0.0133, -0.0329, -0.0303, -0.0258, -0.0025,\n",
      "         0.0026,  0.0045,  0.0317, -0.0433,  0.0085,  0.0158, -0.0233, -0.0102,\n",
      "        -0.0049,  0.0111,  0.0215, -0.0147,  0.0142, -0.0023,  0.0033, -0.0245,\n",
      "        -0.0084, -0.0462, -0.0042, -0.0377,  0.0083, -0.0436,  0.0285, -0.0430,\n",
      "         0.0318, -0.0270,  0.0130,  0.0105,  0.0262, -0.0153,  0.0455,  0.0070,\n",
      "         0.0508, -0.0301,  0.0265, -0.0155,  0.0192,  0.0330, -0.0167,  0.0091,\n",
      "        -0.0065,  0.0341,  0.0060,  0.0214, -0.0297,  0.0127, -0.0071, -0.0159,\n",
      "        -0.0016, -0.0329,  0.0385, -0.0288, -0.0177, -0.0013, -0.0566,  0.0094,\n",
      "        -0.0236,  0.0165, -0.0300, -0.0217, -0.0124, -0.0207,  0.0085, -0.0175,\n",
      "         0.0257, -0.0190,  0.0372, -0.0479,  0.0061,  0.0271,  0.0013,  0.0398,\n",
      "        -0.0037,  0.0052,  0.0091,  0.0306, -0.0201, -0.0412,  0.0374,  0.0170,\n",
      "        -0.0232,  0.0011, -0.0305, -0.0343,  0.0214,  0.0394,  0.0044,  0.0068,\n",
      "         0.0351,  0.0173, -0.0157,  0.0251, -0.0183, -0.0264, -0.0035, -0.0243,\n",
      "        -0.0442,  0.0254, -0.0021, -0.0206, -0.0111, -0.0214, -0.0231, -0.0127,\n",
      "        -0.0182,  0.0178, -0.0291,  0.0179,  0.0367,  0.0287,  0.0321,  0.0105,\n",
      "        -0.0286, -0.0098,  0.0517, -0.0293, -0.0185, -0.0319,  0.0189,  0.0512,\n",
      "        -0.0080, -0.0407,  0.0078, -0.0125, -0.0065, -0.0387, -0.0200, -0.0081,\n",
      "        -0.0418,  0.0260,  0.0223, -0.0201,  0.0083, -0.0378, -0.0325, -0.0134,\n",
      "         0.0223, -0.0127,  0.0324, -0.0166, -0.0220,  0.0033, -0.0241, -0.0302,\n",
      "         0.0475, -0.0401,  0.0284, -0.0095, -0.0174, -0.0123, -0.0109,  0.0295,\n",
      "        -0.0025,  0.0236, -0.0210,  0.0540,  0.0431, -0.0239, -0.0341, -0.0261,\n",
      "         0.0487, -0.0293, -0.0406,  0.0412, -0.0361,  0.0341,  0.0177, -0.0094,\n",
      "         0.0071,  0.0368, -0.0191, -0.0267, -0.0204, -0.0280,  0.0040,  0.0370,\n",
      "        -0.0196, -0.0431,  0.0149,  0.0186,  0.0147, -0.0223,  0.0210,  0.0002,\n",
      "        -0.0215,  0.0285,  0.0178, -0.0254,  0.0390,  0.0430, -0.0383, -0.0567,\n",
      "         0.0418, -0.0386,  0.0254,  0.0462,  0.0145, -0.0016, -0.0421, -0.0057,\n",
      "         0.0077, -0.0095, -0.0075,  0.0211, -0.0190,  0.0012,  0.0296,  0.0370,\n",
      "         0.0294, -0.0362,  0.0202, -0.0357,  0.0225,  0.0201, -0.0330, -0.0128,\n",
      "        -0.0146,  0.0031,  0.0338, -0.0068,  0.0486, -0.0526, -0.0115, -0.0050,\n",
      "        -0.0089,  0.0234, -0.0117,  0.0232, -0.0260,  0.0395, -0.0268,  0.0229,\n",
      "        -0.0224, -0.0143, -0.0023,  0.0400,  0.0150,  0.0107,  0.0121, -0.0104,\n",
      "         0.0063, -0.0318,  0.0341, -0.0471,  0.0059,  0.0269, -0.0303,  0.0003,\n",
      "         0.0092,  0.0356, -0.0303, -0.0097,  0.0116, -0.0424,  0.0180, -0.0136,\n",
      "         0.0294, -0.0317, -0.0337, -0.0466, -0.0230, -0.0217,  0.0280,  0.0149,\n",
      "         0.0169, -0.0086,  0.0369,  0.0123,  0.0224, -0.0327,  0.0051,  0.0344,\n",
      "        -0.0270,  0.0201,  0.0250, -0.0205,  0.0085,  0.0254, -0.0101, -0.0135,\n",
      "         0.0105, -0.0039,  0.0024,  0.0006,  0.0020,  0.0149, -0.0194,  0.0367,\n",
      "        -0.0122, -0.0290,  0.0295, -0.0117,  0.0237,  0.0203, -0.0032,  0.0263,\n",
      "        -0.0203,  0.0316, -0.0146,  0.0006,  0.0118, -0.0301,  0.0193,  0.0224,\n",
      "         0.0107,  0.0109,  0.0185, -0.0127,  0.0242,  0.0105, -0.0217, -0.0110,\n",
      "         0.0132, -0.0032, -0.0016,  0.0308,  0.0067,  0.0314,  0.0152, -0.0014,\n",
      "         0.0299,  0.0208, -0.0180,  0.0450,  0.0400,  0.0033, -0.0079,  0.0169,\n",
      "        -0.0253, -0.0263, -0.0142,  0.0162,  0.0045, -0.0264, -0.0135,  0.0306,\n",
      "         0.0130, -0.0116,  0.0319,  0.0291, -0.0036,  0.0103, -0.0184, -0.0412,\n",
      "         0.0357, -0.0175,  0.0090, -0.0099, -0.0277,  0.0307,  0.0217, -0.0271,\n",
      "        -0.0181,  0.0183, -0.0422,  0.0340, -0.0014,  0.0275, -0.0181,  0.0034,\n",
      "        -0.0309, -0.0106, -0.0150, -0.0262,  0.0104,  0.0247, -0.0398,  0.0194,\n",
      "         0.0382, -0.0188,  0.0043, -0.0220, -0.0203,  0.0037,  0.0305, -0.0162,\n",
      "         0.0119, -0.0092, -0.0008,  0.0092, -0.0269, -0.0105,  0.0344, -0.0034,\n",
      "        -0.0054,  0.0023, -0.0262,  0.0048,  0.0335, -0.0044, -0.0430, -0.0069,\n",
      "        -0.0306, -0.0131, -0.0357, -0.0469,  0.0145,  0.0304, -0.0481, -0.0405,\n",
      "        -0.0099,  0.0056, -0.0303,  0.0007, -0.0216, -0.0268, -0.0211, -0.0356,\n",
      "         0.0169, -0.0030,  0.0043,  0.0158,  0.0356,  0.0296,  0.0008, -0.0475,\n",
      "         0.0314, -0.0141,  0.0378, -0.0166, -0.0333,  0.0134, -0.0072,  0.0052,\n",
      "        -0.0353, -0.0039, -0.0307,  0.0083, -0.0077,  0.0038, -0.0179, -0.0287,\n",
      "        -0.0417, -0.0295, -0.0314,  0.0204, -0.0370,  0.0332,  0.0120, -0.0394,\n",
      "        -0.0360, -0.0242,  0.0141, -0.0249, -0.0122, -0.0053,  0.0103, -0.0054,\n",
      "         0.0002,  0.0265, -0.0028,  0.0264,  0.0287, -0.0193, -0.0251,  0.0083,\n",
      "        -0.0117,  0.0139, -0.0375, -0.0297,  0.0268, -0.0114, -0.0068, -0.0009],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0107, -0.0197,  0.0128,  ...,  0.0389, -0.0258,  0.0399],\n",
      "        [ 0.0315,  0.0442, -0.0090,  ...,  0.0302,  0.0280, -0.0179],\n",
      "        [-0.0249, -0.0317, -0.0348,  ..., -0.0042, -0.0285,  0.0059],\n",
      "        ...,\n",
      "        [ 0.0201, -0.0373,  0.0174,  ..., -0.0217,  0.0289, -0.0053],\n",
      "        [-0.0015, -0.0299, -0.0224,  ..., -0.0167, -0.0095, -0.0086],\n",
      "        [ 0.0048, -0.0028, -0.0016,  ..., -0.0193,  0.0403, -0.0213]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-0.0042, -0.0147, -0.0009,  ...,  0.0118,  0.0015, -0.0113],\n",
      "        [ 0.0260, -0.0029,  0.0007,  ...,  0.0059, -0.0142,  0.0130],\n",
      "        [-0.0006,  0.0040,  0.0132,  ..., -0.0299, -0.0120,  0.0084],\n",
      "        ...,\n",
      "        [ 0.0014,  0.0069, -0.0066,  ..., -0.0052,  0.0086, -0.0093],\n",
      "        [ 0.0076,  0.0129, -0.0114,  ..., -0.0204, -0.0045,  0.0036],\n",
      "        [ 0.0108,  0.0068,  0.0004,  ...,  0.0041,  0.0178, -0.0008]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0149, -0.0344,  0.0119,  ...,  0.0507, -0.0243,  0.0286],\n",
      "        [ 0.0575,  0.0413, -0.0082,  ...,  0.0361,  0.0137, -0.0049],\n",
      "        [-0.0255, -0.0277, -0.0216,  ..., -0.0341, -0.0405,  0.0144],\n",
      "        ...,\n",
      "        [ 0.0215, -0.0304,  0.0109,  ..., -0.0269,  0.0376, -0.0146],\n",
      "        [ 0.0061, -0.0171, -0.0338,  ..., -0.0371, -0.0140, -0.0049],\n",
      "        [ 0.0156,  0.0040, -0.0012,  ..., -0.0151,  0.0580, -0.0220]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 4.0569e-02, -1.1220e-02, -2.0828e-02,  4.4106e-02, -3.1217e-02,\n",
      "         3.4562e-03, -3.9043e-02, -7.8600e-03, -2.4836e-02, -3.4038e-02,\n",
      "         3.7772e-02,  1.2961e-02,  3.1150e-02,  1.6970e-02, -2.7913e-04,\n",
      "        -2.9154e-02, -2.0909e-02, -2.2081e-02, -4.2780e-02,  3.5396e-02,\n",
      "         3.9437e-02, -3.2197e-02,  2.1902e-02,  2.1473e-02, -2.1992e-02,\n",
      "        -2.8517e-02,  1.1921e-02,  5.2284e-03, -7.0038e-03,  2.2038e-02,\n",
      "         1.2294e-02, -1.6192e-02, -3.5751e-03,  1.6848e-02, -4.4067e-02,\n",
      "        -1.0020e-02, -3.1603e-02, -2.9011e-02,  2.9103e-03, -3.6010e-02,\n",
      "        -2.3945e-02,  2.0411e-02,  1.7318e-02, -1.5613e-02, -3.5548e-02,\n",
      "        -8.3735e-03, -4.2297e-03,  3.3271e-02, -4.3698e-02, -1.4928e-02,\n",
      "         2.6151e-02, -1.8166e-02,  1.4388e-02, -3.0589e-02, -4.0160e-03,\n",
      "        -1.0296e-02,  2.7796e-02, -4.0072e-02, -1.7863e-02, -2.1197e-02,\n",
      "         4.0539e-02,  2.0808e-02,  3.7982e-02, -4.4030e-02, -2.4243e-02,\n",
      "         3.6549e-02, -4.2648e-02, -3.1099e-02, -3.2692e-02,  3.6733e-02,\n",
      "         4.1493e-02, -3.6883e-02,  8.3754e-03, -1.5243e-02,  3.3910e-02,\n",
      "        -2.6606e-02, -2.6460e-02,  3.3534e-02, -1.7226e-02, -3.3895e-02,\n",
      "        -3.6123e-02,  3.6286e-02, -4.1904e-02,  2.0443e-02,  2.6276e-02,\n",
      "         2.6383e-02,  2.7153e-02,  3.9457e-02,  1.2950e-02, -1.9974e-02,\n",
      "         1.4694e-02,  5.4881e-03,  1.6956e-02, -1.7817e-02, -3.6918e-02,\n",
      "         1.3285e-03,  2.8308e-04,  3.5265e-02, -2.1022e-02,  8.4650e-03,\n",
      "        -2.9471e-02, -4.9006e-03,  3.0519e-02,  4.8871e-03,  3.9734e-02,\n",
      "         2.7372e-02, -1.2877e-02, -4.2168e-02,  1.3447e-02, -3.5344e-02,\n",
      "         2.4887e-02, -4.1195e-02, -2.3313e-02,  3.7450e-02,  4.0511e-02,\n",
      "         2.2118e-02, -4.5034e-03, -4.2263e-02,  1.6144e-02,  4.3779e-02,\n",
      "         9.8333e-04,  2.7853e-02, -1.0476e-02,  4.2291e-02,  5.2002e-03,\n",
      "         2.5583e-02, -1.0081e-02, -1.7032e-02,  1.9846e-02,  2.9349e-02,\n",
      "         1.5733e-02,  2.6147e-02, -2.7502e-02,  9.2099e-03, -2.5402e-02,\n",
      "        -1.1574e-02, -3.0390e-02, -2.5798e-02, -1.1225e-02, -1.1799e-04,\n",
      "        -2.0919e-02,  8.0802e-03,  3.7510e-02, -1.7298e-02, -4.0030e-02,\n",
      "        -5.5662e-03,  4.3284e-02,  1.8392e-02,  2.4318e-02, -4.1880e-03,\n",
      "        -1.1761e-02, -3.7993e-02,  1.2858e-02,  2.4584e-03,  5.8703e-03,\n",
      "         3.0705e-02,  9.0764e-03,  3.1760e-02,  5.4588e-03,  3.6989e-03,\n",
      "         1.9930e-02,  4.3351e-02,  3.5232e-02, -1.7228e-02, -4.2794e-04,\n",
      "         1.0510e-02, -1.5142e-02,  1.8717e-02,  2.2493e-02, -8.4866e-03,\n",
      "         2.0528e-02, -1.9734e-02, -4.0540e-03,  1.2109e-02, -2.9106e-02,\n",
      "         1.8818e-02, -2.3405e-02, -1.5147e-02, -2.8515e-02, -4.1825e-02,\n",
      "         3.2645e-02, -1.3563e-02,  1.6770e-02,  3.9167e-02,  4.0967e-02,\n",
      "        -1.6206e-02,  3.3016e-02, -4.1799e-02, -3.5560e-02,  1.3933e-02,\n",
      "        -8.5020e-03,  2.0524e-02, -1.4459e-02, -2.5542e-03, -9.5300e-03,\n",
      "        -2.4224e-02, -3.9571e-03,  4.2698e-02, -4.1219e-02, -1.3584e-02,\n",
      "         2.8900e-02,  4.1809e-02,  1.2053e-02,  2.4911e-03,  3.9305e-02,\n",
      "        -3.5158e-02,  2.4249e-02, -2.2502e-02,  4.3959e-02, -1.4712e-03,\n",
      "        -4.0732e-02, -4.1579e-02,  1.0441e-02, -3.9522e-02, -4.1394e-02,\n",
      "        -4.1972e-03, -1.1492e-02, -1.7291e-02, -2.7804e-02, -3.8213e-02,\n",
      "        -2.7301e-02, -3.3299e-02, -1.0955e-02,  1.2984e-02,  1.9791e-02,\n",
      "        -3.5671e-02, -3.3441e-03, -4.1104e-02, -6.7121e-03,  2.8771e-02,\n",
      "        -6.8300e-03, -6.9738e-03,  2.5863e-03, -4.2348e-02,  3.7208e-02,\n",
      "         7.8595e-03,  3.4552e-02, -2.0223e-02, -8.0363e-03,  1.5712e-02,\n",
      "        -1.1611e-02, -1.2158e-02,  2.0221e-02, -2.0407e-02, -7.5669e-03,\n",
      "         2.1026e-02, -3.2301e-02, -4.1743e-02,  6.2808e-03, -3.7372e-02,\n",
      "        -2.7502e-02,  1.2675e-02,  3.8118e-04, -1.3602e-02, -2.2495e-02,\n",
      "         4.8946e-04,  4.2245e-02,  7.3531e-03, -1.4848e-02,  1.6818e-02,\n",
      "        -2.3648e-03, -1.5815e-02,  2.2220e-02,  1.9155e-02, -2.2682e-02,\n",
      "         4.3575e-02,  7.6072e-03,  1.6135e-02, -2.7505e-02, -7.6667e-03,\n",
      "        -3.6400e-02,  1.5957e-02, -7.5711e-03,  1.8796e-02, -1.3082e-02,\n",
      "        -2.1513e-02,  3.8313e-02,  3.0118e-03,  4.4045e-02, -2.6272e-02,\n",
      "         2.9445e-02, -1.6873e-04, -3.0747e-02,  4.1812e-02,  1.6933e-02,\n",
      "        -2.2101e-02, -1.0728e-02,  3.5973e-02,  4.0178e-03, -1.1072e-02,\n",
      "        -1.3101e-02,  3.9201e-02, -3.0506e-03,  1.6148e-02, -3.6182e-02,\n",
      "         4.2372e-02, -3.3636e-02,  9.5157e-03,  3.0341e-02,  1.7867e-03,\n",
      "        -3.7427e-02, -4.4178e-02, -3.1233e-02, -3.9064e-02,  1.8147e-02,\n",
      "        -2.1429e-02, -2.1313e-02, -2.6927e-02,  1.6950e-02, -1.6775e-02,\n",
      "        -1.1242e-02,  1.4158e-02, -1.1386e-02, -8.5997e-03,  1.3291e-02,\n",
      "         5.5365e-03, -3.1720e-02, -3.4571e-02,  3.0901e-02,  4.3044e-02,\n",
      "         1.3639e-02,  3.5704e-02,  3.6719e-02, -2.1433e-02, -2.0422e-02,\n",
      "        -4.0625e-02, -3.7334e-02, -5.3688e-03, -3.3748e-02,  1.1338e-02,\n",
      "         4.1663e-02, -1.9515e-02, -4.1984e-02, -3.7707e-02, -3.3414e-02,\n",
      "         1.1877e-02,  3.0091e-02, -3.5589e-03, -2.2880e-02, -4.0563e-02,\n",
      "         3.6068e-02,  3.0297e-02, -2.0036e-02,  9.6452e-03,  4.2194e-02,\n",
      "         1.3453e-02,  3.9732e-02, -1.2011e-02,  3.4085e-02,  3.4001e-02,\n",
      "         4.0599e-03, -3.0405e-02, -1.7024e-02,  3.2599e-02, -3.5331e-02,\n",
      "         2.7394e-02, -3.6145e-03, -3.3458e-02,  1.5158e-02,  7.9807e-04,\n",
      "         2.7619e-02, -2.3160e-02, -2.7785e-02,  2.0412e-02,  3.0934e-02,\n",
      "         3.6948e-02, -1.6368e-02, -1.7631e-02, -8.1121e-04,  3.2998e-02,\n",
      "        -1.9141e-02, -4.2358e-03, -2.8914e-04,  3.7891e-04, -1.2618e-02,\n",
      "         3.5902e-02, -2.0286e-02, -1.5366e-02,  3.5044e-03,  2.0902e-02,\n",
      "         2.3727e-03,  3.7041e-02, -1.1718e-02, -4.1531e-02, -3.2721e-02,\n",
      "         3.6320e-02,  2.8388e-02,  1.0984e-03, -3.3830e-02, -1.3469e-02,\n",
      "        -7.4095e-03, -1.9727e-02,  4.2995e-02,  3.8994e-02,  2.1821e-02,\n",
      "        -1.4645e-02, -1.7947e-02, -1.3752e-02, -1.9384e-03,  2.4618e-02,\n",
      "         3.0534e-02, -3.6819e-02, -2.1773e-02,  3.4206e-02,  2.7264e-02,\n",
      "        -6.0797e-04, -9.1395e-03, -3.8098e-02, -3.1320e-03, -3.0790e-03,\n",
      "         1.2214e-02, -3.5958e-02,  2.5881e-02,  3.3856e-02, -4.4159e-02,\n",
      "        -2.8371e-02,  2.3638e-02,  1.2031e-02,  6.7208e-03, -3.4047e-02,\n",
      "        -1.0172e-03, -2.0091e-02,  2.6270e-02, -6.3750e-03, -3.3973e-02,\n",
      "        -2.3947e-02, -1.0264e-02, -1.8845e-02,  3.4076e-02, -1.5264e-02,\n",
      "         1.1734e-02, -1.6177e-02,  8.6595e-03,  4.2399e-02, -3.9901e-02,\n",
      "        -6.5831e-03,  4.1485e-02,  2.5928e-02,  4.0154e-02,  1.1019e-02,\n",
      "         4.1320e-02,  2.9298e-02,  1.8136e-02, -8.8578e-03, -8.8639e-03,\n",
      "         2.2218e-02, -2.2875e-03, -2.0662e-02,  3.8763e-02, -1.9588e-02,\n",
      "        -2.5413e-02,  3.6050e-02,  3.4914e-02, -2.7878e-02,  4.1050e-02,\n",
      "         3.7379e-02, -3.2879e-02, -2.8755e-02, -3.9161e-02, -3.4658e-02,\n",
      "        -3.2807e-02, -1.2432e-02, -4.4102e-02,  1.8662e-02, -4.3988e-02,\n",
      "        -1.3828e-02,  3.1739e-03, -3.9993e-02,  4.2557e-02,  3.4191e-02,\n",
      "         3.4405e-02,  1.9451e-02, -3.7564e-02,  4.0423e-02, -3.9643e-02,\n",
      "         4.3669e-02,  1.3263e-02, -2.8835e-02,  2.5852e-02,  2.6940e-02,\n",
      "        -1.9742e-02,  3.0611e-02,  4.2867e-02, -3.4828e-02, -1.9445e-02,\n",
      "         2.7087e-02, -2.3084e-02, -1.0392e-02,  1.0379e-02,  3.7835e-02,\n",
      "        -2.0593e-03,  2.2465e-02, -2.2783e-02, -2.2319e-03,  2.5581e-03,\n",
      "         7.5098e-03,  4.4087e-02, -1.6333e-02, -1.9184e-02,  1.8453e-02,\n",
      "        -1.0672e-02,  1.3346e-02,  8.2699e-03, -5.2766e-03, -1.9391e-03,\n",
      "        -8.5335e-05, -2.1564e-02, -1.3659e-02, -2.2033e-02,  3.1841e-02,\n",
      "         3.1831e-03, -2.4521e-02], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-2.0221e-02, -1.5443e-02, -1.1067e-02, -6.7299e-03, -3.2290e-03,\n",
      "        -9.4285e-03,  3.9024e-03,  5.3253e-03, -1.3418e-02,  3.8734e-03,\n",
      "        -2.1955e-03, -3.2806e-03,  4.2366e-03, -1.0011e-02, -1.5382e-02,\n",
      "         3.7390e-03,  2.4903e-03,  9.0422e-03, -1.0241e-02, -7.2130e-03,\n",
      "        -1.8413e-03, -5.1551e-04,  2.5944e-02,  5.9690e-03,  1.4962e-02,\n",
      "         5.5665e-03, -5.2322e-03, -4.2160e-03,  9.2485e-03, -7.0505e-03,\n",
      "        -1.6168e-02, -9.2055e-03, -4.8018e-03,  9.3106e-03, -3.3410e-03,\n",
      "        -4.6219e-03,  1.3442e-03,  6.4855e-03, -2.4887e-03, -8.2634e-03,\n",
      "         7.8709e-03,  6.1825e-03,  2.2986e-04,  1.4439e-02, -9.2132e-03,\n",
      "        -1.2920e-02, -2.0720e-02,  1.8619e-02, -2.7609e-04, -6.7497e-03,\n",
      "        -5.9725e-03, -1.5119e-02,  4.3725e-03,  4.8486e-03, -9.5309e-03,\n",
      "         1.1551e-02,  4.6005e-03,  1.8820e-02,  5.4998e-03,  2.8964e-03,\n",
      "         1.1075e-02,  1.3595e-02,  1.7993e-03,  4.8108e-04,  9.3334e-03,\n",
      "         8.8052e-03,  2.2988e-02, -4.0737e-03,  1.0414e-02,  4.7549e-03,\n",
      "        -1.6472e-02,  1.0100e-02,  2.1699e-02,  7.9911e-03,  1.8350e-02,\n",
      "        -1.0951e-02, -2.3698e-02,  7.9257e-03, -6.3371e-03,  7.8067e-03,\n",
      "        -5.2970e-03, -4.6286e-03,  2.0501e-03, -9.3617e-03, -1.0154e-03,\n",
      "        -7.4586e-04, -3.5410e-03,  2.0995e-04, -3.2812e-03,  1.2175e-02,\n",
      "        -9.9026e-03,  1.3485e-02, -1.1446e-02, -2.8854e-03, -1.7701e-02,\n",
      "         1.5719e-02,  3.2990e-03, -1.3348e-02, -6.0143e-04,  2.0470e-02,\n",
      "        -1.0323e-03, -6.0400e-04, -3.2258e-03, -8.5372e-03,  1.0699e-02,\n",
      "        -8.1038e-03, -1.9155e-02,  9.0245e-03, -7.1804e-03, -1.4071e-03,\n",
      "        -1.3753e-03, -5.2235e-03, -6.4499e-03, -1.2459e-02,  9.0927e-03,\n",
      "         1.1947e-02, -1.5587e-02, -9.3146e-03, -1.1944e-02, -1.9947e-03,\n",
      "         3.2928e-03,  6.1263e-03, -1.4101e-03,  9.2641e-03, -1.3759e-02,\n",
      "         8.7493e-03, -8.2511e-04, -1.1240e-02, -2.4067e-03, -9.8921e-04,\n",
      "        -1.3305e-02,  7.6470e-03, -1.8946e-02, -8.9732e-03,  2.0617e-03,\n",
      "        -1.2858e-02,  1.4309e-02, -7.4456e-04,  7.4312e-03, -9.3409e-03,\n",
      "         2.1954e-03,  1.1764e-02, -7.3566e-03, -2.1165e-02,  3.4042e-03,\n",
      "         1.8524e-02,  1.9201e-03, -3.4472e-03,  2.2878e-02,  1.0818e-02,\n",
      "        -2.0213e-02, -2.1524e-02,  5.5829e-03, -6.8657e-03, -2.9948e-03,\n",
      "         1.6219e-03,  9.2741e-03,  3.4935e-03,  1.9596e-02, -1.4735e-02,\n",
      "         1.2037e-02, -4.6203e-03, -9.1577e-04,  7.3585e-03, -4.7593e-03,\n",
      "        -1.0570e-03, -1.6571e-02, -5.4946e-03,  9.7867e-03,  6.3103e-05,\n",
      "        -1.7459e-02,  4.5035e-03,  1.6804e-03,  5.1181e-03,  2.3115e-02,\n",
      "        -1.2688e-02, -1.3796e-02,  1.3154e-02, -8.4817e-03, -1.3985e-02,\n",
      "         2.2562e-03,  3.3158e-03,  3.5766e-04,  8.5731e-03,  1.0255e-02,\n",
      "         1.2514e-03,  1.3798e-02,  7.1681e-03,  6.0160e-03,  3.4973e-03,\n",
      "        -6.2628e-03,  3.9698e-03, -4.6273e-03, -2.4213e-02, -2.2074e-02,\n",
      "         4.1371e-06, -9.3965e-03,  1.1453e-02, -3.3832e-03,  1.1468e-02,\n",
      "         7.2668e-04, -1.0374e-02,  7.8611e-03,  1.7425e-02, -3.8939e-03,\n",
      "        -9.4257e-03,  4.1101e-03,  6.5313e-03,  3.5426e-04,  5.0698e-03,\n",
      "        -1.0087e-03,  1.2717e-02, -1.8313e-02, -2.1952e-03,  3.4673e-03,\n",
      "        -3.9797e-03,  6.2009e-03, -4.1070e-03,  1.2204e-02, -4.6161e-03,\n",
      "         2.3399e-03, -1.3493e-02,  8.0261e-03, -9.9825e-04, -8.7082e-03,\n",
      "        -8.0937e-03, -8.0595e-03, -2.0786e-03, -1.0251e-02, -2.0793e-03,\n",
      "        -4.1338e-03, -1.3216e-02,  1.8807e-03,  3.7371e-03,  8.6834e-03,\n",
      "        -2.1340e-04, -8.3454e-03,  1.1595e-02,  2.8941e-03, -3.6828e-03,\n",
      "         4.3745e-03, -1.2025e-02, -3.3034e-03,  7.4361e-03, -4.6586e-03,\n",
      "         3.9165e-03, -1.5069e-02,  1.4285e-02,  1.3552e-02,  3.7158e-03,\n",
      "        -3.6225e-03, -4.2954e-03, -7.2036e-03, -4.7793e-03,  1.5958e-02,\n",
      "         1.0904e-02,  8.5473e-03,  2.4597e-05,  1.2385e-02,  3.0296e-03,\n",
      "        -9.1639e-03,  6.5088e-04,  7.5493e-03, -2.6197e-03,  1.7874e-02,\n",
      "         5.1108e-03, -7.4278e-03,  1.2475e-02, -2.7138e-03, -4.9963e-03,\n",
      "         9.2043e-04, -8.5525e-04, -6.2255e-04,  1.0764e-02, -1.2756e-02,\n",
      "        -3.8296e-03, -5.9802e-03,  6.8644e-03, -1.3275e-02, -6.9276e-03,\n",
      "         5.0140e-03,  7.1875e-03,  2.9646e-03,  9.6351e-03,  1.0048e-02,\n",
      "        -1.7387e-02,  1.0645e-02,  2.3233e-02, -1.5072e-03,  2.1866e-02,\n",
      "         3.0020e-03, -7.5262e-04, -2.6875e-03,  6.4317e-03,  5.2326e-03,\n",
      "        -1.5010e-02,  8.7420e-03, -9.9060e-03,  9.8042e-04, -1.4349e-02,\n",
      "         2.3889e-03,  7.2196e-03, -1.3012e-03, -8.4323e-03, -1.6121e-02,\n",
      "         2.7289e-03,  6.7309e-03, -6.7909e-03,  5.9634e-03, -1.0744e-03,\n",
      "         2.1648e-02, -1.3090e-02, -7.0152e-03,  8.3501e-03, -1.3402e-03,\n",
      "         4.9120e-03,  1.0837e-02,  3.8591e-03,  6.1830e-03,  9.3419e-03,\n",
      "         6.5256e-03, -1.1851e-02,  1.3084e-02, -4.7999e-03,  4.9178e-03,\n",
      "         3.5266e-03, -1.1406e-03, -4.6511e-03,  1.8914e-03, -1.1400e-02,\n",
      "        -9.3676e-03, -8.3322e-03, -3.1802e-03,  1.5577e-02,  3.7018e-03,\n",
      "        -1.0191e-02, -1.0111e-03,  7.2360e-03, -2.3810e-02,  1.8941e-03,\n",
      "        -6.6251e-03, -3.2443e-03,  1.9202e-03,  2.5286e-03, -2.7463e-03,\n",
      "        -5.0486e-03,  9.2984e-03,  1.7131e-02,  4.5021e-04,  1.5278e-02,\n",
      "        -5.0368e-03,  1.7010e-02, -5.0649e-03,  8.6363e-03, -2.7966e-03,\n",
      "         1.8346e-03,  1.0142e-02,  4.2552e-04, -6.7250e-03, -2.3005e-03,\n",
      "         1.0835e-02,  9.6930e-03,  4.8537e-03, -1.9275e-02,  4.7633e-03,\n",
      "        -5.0506e-03, -3.2068e-03, -4.0447e-03,  3.8290e-03, -1.7114e-02,\n",
      "         3.1861e-03,  1.0433e-02, -9.6331e-04, -2.0976e-03, -3.3417e-03,\n",
      "        -1.4736e-02,  5.4741e-03, -1.0656e-02, -4.4029e-03,  1.6500e-02,\n",
      "        -8.9848e-03,  7.2989e-03, -6.1650e-03,  3.7004e-03, -1.7930e-02,\n",
      "         6.8771e-03, -1.0739e-02, -1.2426e-02, -5.9488e-03, -1.2390e-02,\n",
      "         7.3798e-03, -1.9557e-02, -9.2788e-03, -1.5514e-02, -1.7329e-02,\n",
      "        -4.8589e-03,  9.5565e-03, -7.3317e-03,  3.5970e-03,  1.6400e-02,\n",
      "        -1.6438e-02, -1.4666e-02, -1.7038e-02, -7.2478e-03,  3.6787e-03,\n",
      "         2.4389e-03, -9.1780e-03, -7.6621e-03, -1.2731e-02,  1.5895e-02,\n",
      "         2.6759e-03, -5.7818e-03,  3.6672e-03, -2.0472e-02, -2.5387e-03,\n",
      "        -3.4188e-02, -1.5732e-03, -8.0483e-03, -1.3434e-02,  2.6899e-03,\n",
      "        -9.9945e-03, -1.7331e-02,  3.2122e-03, -1.0112e-03,  3.8498e-03,\n",
      "        -5.1704e-03, -2.4921e-02, -4.0812e-03,  2.7792e-02,  3.8101e-03,\n",
      "         1.3377e-03,  1.2218e-02, -2.9482e-03, -6.1499e-03, -4.1026e-03,\n",
      "         7.8687e-03,  5.5799e-03, -3.1346e-03, -7.5734e-03,  6.2617e-04,\n",
      "         1.2032e-02, -9.0185e-03, -1.5938e-02,  1.8569e-02,  5.6682e-03,\n",
      "         1.7109e-02, -1.3620e-02, -1.5186e-02,  1.6599e-02,  1.1195e-02,\n",
      "         6.0911e-03, -1.8380e-02,  1.0888e-02,  3.1081e-04, -1.0002e-03,\n",
      "         5.9494e-03, -3.5180e-03, -3.2480e-04,  4.2840e-03,  1.9040e-02,\n",
      "        -3.7251e-03, -3.1611e-03,  1.2340e-03, -1.5819e-03,  1.1294e-02,\n",
      "         4.7810e-03, -1.9438e-02, -8.0156e-03, -5.7000e-05,  7.6238e-04,\n",
      "        -6.8110e-03,  1.9277e-03,  4.2956e-03,  1.3087e-02,  6.5811e-03,\n",
      "         1.2668e-02, -3.9501e-03, -1.0472e-02,  7.1707e-03,  2.7544e-04,\n",
      "        -3.9023e-03, -4.6462e-03,  9.6177e-03,  1.0167e-02,  1.7787e-02,\n",
      "        -1.6450e-02, -1.8754e-02,  2.9733e-03,  6.9522e-03,  1.9290e-03,\n",
      "        -1.7551e-02,  4.4997e-03, -1.4541e-02, -1.2748e-02, -8.3229e-03,\n",
      "         1.2076e-02, -3.1203e-03,  2.1195e-02,  9.3740e-04, -3.2410e-03,\n",
      "         6.0572e-03,  2.7351e-02,  2.5156e-03,  2.6827e-02,  5.4804e-03,\n",
      "        -3.1236e-04, -1.0360e-02,  2.1279e-03,  2.2526e-03,  3.6234e-03,\n",
      "        -5.8492e-03,  2.1543e-02])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([ 2.0348e-02, -2.6663e-02, -3.1895e-02,  3.7376e-02, -3.4446e-02,\n",
      "        -5.9723e-03, -3.5141e-02, -2.5347e-03, -3.8255e-02, -3.0165e-02,\n",
      "         3.5576e-02,  9.6801e-03,  3.5386e-02,  6.9590e-03, -1.5661e-02,\n",
      "        -2.5415e-02, -1.8419e-02, -1.3039e-02, -5.3021e-02,  2.8183e-02,\n",
      "         3.7596e-02, -3.2713e-02,  4.7846e-02,  2.7442e-02, -7.0301e-03,\n",
      "        -2.2950e-02,  6.6884e-03,  1.0124e-03,  2.2447e-03,  1.4987e-02,\n",
      "        -3.8746e-03, -2.5397e-02, -8.3769e-03,  2.6158e-02, -4.7408e-02,\n",
      "        -1.4642e-02, -3.0259e-02, -2.2526e-02,  4.2165e-04, -4.4274e-02,\n",
      "        -1.6075e-02,  2.6593e-02,  1.7548e-02, -1.1736e-03, -4.4761e-02,\n",
      "        -2.1294e-02, -2.4950e-02,  5.1891e-02, -4.3974e-02, -2.1677e-02,\n",
      "         2.0178e-02, -3.3285e-02,  1.8760e-02, -2.5740e-02, -1.3547e-02,\n",
      "         1.2552e-03,  3.2396e-02, -2.1252e-02, -1.2363e-02, -1.8300e-02,\n",
      "         5.1614e-02,  3.4403e-02,  3.9781e-02, -4.3549e-02, -1.4909e-02,\n",
      "         4.5354e-02, -1.9660e-02, -3.5173e-02, -2.2278e-02,  4.1488e-02,\n",
      "         2.5021e-02, -2.6783e-02,  3.0074e-02, -7.2523e-03,  5.2261e-02,\n",
      "        -3.7557e-02, -5.0158e-02,  4.1460e-02, -2.3563e-02, -2.6088e-02,\n",
      "        -4.1420e-02,  3.1657e-02, -3.9854e-02,  1.1082e-02,  2.5261e-02,\n",
      "         2.5637e-02,  2.3612e-02,  3.9667e-02,  9.6689e-03, -7.7987e-03,\n",
      "         4.7912e-03,  1.8973e-02,  5.5099e-03, -2.0703e-02, -5.4619e-02,\n",
      "         1.7047e-02,  3.5820e-03,  2.1917e-02, -2.1623e-02,  2.8935e-02,\n",
      "        -3.0503e-02, -5.5046e-03,  2.7293e-02, -3.6502e-03,  5.0433e-02,\n",
      "         1.9268e-02, -3.2032e-02, -3.3143e-02,  6.2668e-03, -3.6751e-02,\n",
      "         2.3512e-02, -4.6419e-02, -2.9763e-02,  2.4991e-02,  4.9604e-02,\n",
      "         3.4065e-02, -2.0090e-02, -5.1577e-02,  4.1995e-03,  4.1785e-02,\n",
      "         4.2762e-03,  3.3979e-02, -1.1886e-02,  5.1555e-02, -8.5587e-03,\n",
      "         3.4332e-02, -1.0906e-02, -2.8272e-02,  1.7439e-02,  2.8360e-02,\n",
      "         2.4275e-03,  3.3794e-02, -4.6448e-02,  2.3662e-04, -2.3340e-02,\n",
      "        -2.4433e-02, -1.6082e-02, -2.6543e-02, -3.7940e-03, -9.4589e-03,\n",
      "        -1.8724e-02,  1.9845e-02,  3.0154e-02, -3.8463e-02, -3.6626e-02,\n",
      "         1.2958e-02,  4.5205e-02,  1.4945e-02,  4.7196e-02,  6.6299e-03,\n",
      "        -3.1975e-02, -5.9518e-02,  1.8441e-02, -4.4073e-03,  2.8755e-03,\n",
      "         3.2327e-02,  1.8351e-02,  3.5253e-02,  2.5054e-02, -1.1036e-02,\n",
      "         3.1967e-02,  3.8730e-02,  3.4316e-02, -9.8696e-03, -5.1872e-03,\n",
      "         9.4531e-03, -3.1713e-02,  1.3222e-02,  3.2280e-02, -8.4235e-03,\n",
      "         3.0690e-03, -1.5230e-02, -2.3737e-03,  1.7227e-02, -5.9911e-03,\n",
      "         6.1293e-03, -3.7200e-02, -1.9936e-03, -3.6997e-02, -5.5810e-02,\n",
      "         3.4901e-02, -1.0248e-02,  1.7128e-02,  4.7741e-02,  5.1222e-02,\n",
      "        -1.4954e-02,  4.6814e-02, -3.4631e-02, -2.9544e-02,  1.7431e-02,\n",
      "        -1.4765e-02,  2.4494e-02, -1.9086e-02, -2.6767e-02, -3.1604e-02,\n",
      "        -2.4219e-02, -1.3354e-02,  5.4151e-02, -4.4603e-02, -2.1152e-03,\n",
      "         2.9627e-02,  3.1435e-02,  1.9914e-02,  1.9916e-02,  3.5411e-02,\n",
      "        -4.4583e-02,  2.8359e-02, -1.5971e-02,  4.4313e-02,  3.5986e-03,\n",
      "        -4.1740e-02, -2.8862e-02, -7.8721e-03, -4.1718e-02, -3.7926e-02,\n",
      "        -8.1768e-03, -5.2913e-03, -2.1398e-02, -1.5600e-02, -4.2829e-02,\n",
      "        -2.4961e-02, -4.6792e-02, -2.9285e-03,  1.1986e-02,  1.1083e-02,\n",
      "        -4.3765e-02, -1.1404e-02, -4.3183e-02, -1.6963e-02,  2.6692e-02,\n",
      "        -1.0964e-02, -2.0189e-02,  4.4670e-03, -3.8611e-02,  4.5891e-02,\n",
      "         7.6461e-03,  2.6207e-02, -8.6275e-03, -5.1422e-03,  1.2030e-02,\n",
      "        -7.2366e-03, -2.4184e-02,  1.6918e-02, -1.2971e-02, -1.2225e-02,\n",
      "         2.4943e-02, -4.7370e-02, -2.7458e-02,  1.9832e-02, -3.3656e-02,\n",
      "        -3.1124e-02,  8.3799e-03, -6.8225e-03, -1.8381e-02, -6.5375e-03,\n",
      "         1.1394e-02,  5.0792e-02,  7.3777e-03, -2.4633e-03,  1.9847e-02,\n",
      "        -1.1529e-02, -1.5164e-02,  2.9769e-02,  1.6535e-02, -4.8081e-03,\n",
      "         4.8685e-02,  1.7938e-04,  2.8611e-02, -3.0219e-02, -1.2663e-02,\n",
      "        -3.5479e-02,  1.5101e-02, -8.1936e-03,  2.9560e-02, -2.5838e-02,\n",
      "        -2.5342e-02,  3.2332e-02,  9.8762e-03,  3.0770e-02, -3.3200e-02,\n",
      "         3.4459e-02,  7.0187e-03, -2.7782e-02,  5.1447e-02,  2.6982e-02,\n",
      "        -3.9487e-02, -8.3303e-05,  5.9206e-02,  2.5106e-03,  1.0794e-02,\n",
      "        -1.0099e-02,  3.8449e-02, -5.7381e-03,  2.2579e-02, -3.0949e-02,\n",
      "         2.7362e-02, -2.4894e-02, -3.9029e-04,  3.1321e-02, -1.2562e-02,\n",
      "        -3.5038e-02, -3.6958e-02, -3.2534e-02, -4.7496e-02,  2.0259e-03,\n",
      "        -1.8700e-02, -1.4582e-02, -3.3718e-02,  2.2913e-02, -1.7850e-02,\n",
      "         1.0407e-02,  1.0680e-03, -1.8401e-02, -2.4961e-04,  1.1951e-02,\n",
      "         1.0448e-02, -2.0883e-02, -3.0712e-02,  3.7084e-02,  5.2386e-02,\n",
      "         2.0165e-02,  2.3854e-02,  4.9803e-02, -2.6233e-02, -1.5505e-02,\n",
      "        -3.7098e-02, -3.8474e-02, -1.0020e-02, -3.1857e-02, -6.2217e-05,\n",
      "         3.2296e-02, -2.7847e-02, -4.5164e-02, -2.2130e-02, -2.9712e-02,\n",
      "         1.6858e-03,  2.9080e-02,  3.6771e-03, -4.6690e-02, -3.8668e-02,\n",
      "         2.9443e-02,  2.7053e-02, -1.8116e-02,  1.2174e-02,  3.9448e-02,\n",
      "         8.4040e-03,  4.9031e-02,  5.1198e-03,  3.4535e-02,  4.9279e-02,\n",
      "        -9.7689e-04, -1.3395e-02, -2.2088e-02,  4.1235e-02, -3.8128e-02,\n",
      "         2.9229e-02,  6.5279e-03, -3.3033e-02,  8.4334e-03, -1.5025e-03,\n",
      "         3.8454e-02, -1.3467e-02, -2.2931e-02,  1.1378e-03,  3.5697e-02,\n",
      "         3.1897e-02, -1.9575e-02, -2.1676e-02,  3.0178e-03,  1.5884e-02,\n",
      "        -1.5955e-02,  6.1972e-03, -1.2524e-03, -1.7187e-03, -1.5960e-02,\n",
      "         2.1166e-02, -1.4812e-02, -2.6022e-02, -8.9849e-04,  3.7402e-02,\n",
      "        -6.6121e-03,  4.4340e-02, -1.7883e-02, -3.7830e-02, -5.0651e-02,\n",
      "         4.3197e-02,  1.7649e-02, -1.1328e-02, -3.9779e-02, -2.5859e-02,\n",
      "        -2.9710e-05, -3.9285e-02,  3.3716e-02,  2.3479e-02,  4.4924e-03,\n",
      "        -1.9504e-02, -8.3902e-03, -2.1083e-02,  1.6586e-03,  4.1018e-02,\n",
      "         1.4096e-02, -5.1485e-02, -3.8811e-02,  2.6958e-02,  3.0942e-02,\n",
      "         1.8309e-03, -1.8318e-02, -4.5760e-02, -1.5863e-02,  1.2816e-02,\n",
      "         1.4890e-02, -4.1739e-02,  2.9548e-02,  1.3384e-02, -4.6698e-02,\n",
      "        -6.2560e-02,  2.2064e-02,  3.9830e-03, -6.7132e-03, -3.1357e-02,\n",
      "        -1.1012e-02, -3.7421e-02,  2.9482e-02, -7.3862e-03, -3.0123e-02,\n",
      "        -2.9117e-02, -3.5185e-02, -2.2926e-02,  6.1868e-02, -1.1454e-02,\n",
      "         1.3072e-02, -3.9587e-03,  5.7113e-03,  3.6249e-02, -4.4004e-02,\n",
      "         1.2857e-03,  4.7065e-02,  2.2793e-02,  3.2580e-02,  1.1645e-02,\n",
      "         5.3351e-02,  2.0280e-02,  2.1984e-03,  9.7114e-03, -3.1957e-03,\n",
      "         3.9327e-02, -1.5907e-02, -3.5848e-02,  5.5362e-02, -8.3930e-03,\n",
      "        -1.9321e-02,  1.7670e-02,  4.5802e-02, -2.7567e-02,  4.0050e-02,\n",
      "         4.3328e-02, -3.6397e-02, -2.9080e-02, -3.4877e-02, -1.5618e-02,\n",
      "        -3.6532e-02, -1.5593e-02, -4.2868e-02,  1.7080e-02, -3.2694e-02,\n",
      "        -9.0473e-03, -1.6264e-02, -4.8009e-02,  4.2500e-02,  3.4953e-02,\n",
      "         2.7594e-02,  2.1379e-02, -3.3268e-02,  5.3511e-02, -3.3062e-02,\n",
      "         5.6337e-02,  9.3126e-03, -3.9307e-02,  3.3023e-02,  2.7216e-02,\n",
      "        -2.3645e-02,  2.5964e-02,  5.2485e-02, -2.4661e-02, -1.6577e-03,\n",
      "         1.0637e-02, -4.1838e-02, -7.4187e-03,  1.7331e-02,  3.9764e-02,\n",
      "        -1.9610e-02,  2.6965e-02, -3.7324e-02, -1.4980e-02, -5.7648e-03,\n",
      "         1.9586e-02,  4.0967e-02,  4.8622e-03, -1.8247e-02,  1.5212e-02,\n",
      "        -4.6147e-03,  4.0697e-02,  1.0786e-02,  2.1550e-02,  3.5413e-03,\n",
      "        -3.9770e-04, -3.1923e-02, -1.1531e-02, -1.9780e-02,  3.5465e-02,\n",
      "        -2.6661e-03, -2.9778e-03], requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0066,  0.0343,  0.0023,  ..., -0.0387, -0.0211,  0.0349],\n",
      "        [ 0.0313, -0.0062,  0.0260,  ..., -0.0382, -0.0137,  0.0266],\n",
      "        [ 0.0282, -0.0288,  0.0303,  ...,  0.0103, -0.0296,  0.0266],\n",
      "        ...,\n",
      "        [ 0.0102, -0.0191,  0.0155,  ..., -0.0352, -0.0069,  0.0004],\n",
      "        [-0.0414,  0.0403, -0.0143,  ...,  0.0365,  0.0312,  0.0433],\n",
      "        [-0.0288,  0.0223,  0.0407,  ...,  0.0149,  0.0331, -0.0120]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-0.0034,  0.0020,  0.0106,  ...,  0.0112, -0.0031,  0.0087],\n",
      "        [ 0.0054,  0.0041,  0.0039,  ...,  0.0057, -0.0140,  0.0149],\n",
      "        [-0.0127, -0.0127, -0.0140,  ...,  0.0054,  0.0031, -0.0216],\n",
      "        ...,\n",
      "        [ 0.0178, -0.0041,  0.0050,  ...,  0.0100,  0.0024, -0.0344],\n",
      "        [-0.0076,  0.0121, -0.0014,  ...,  0.0179,  0.0042, -0.0100],\n",
      "        [ 0.0210,  0.0056, -0.0072,  ...,  0.0076, -0.0025, -0.0033]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0100,  0.0363,  0.0129,  ..., -0.0276, -0.0242,  0.0436],\n",
      "        [ 0.0366, -0.0021,  0.0299,  ..., -0.0325, -0.0277,  0.0415],\n",
      "        [ 0.0155, -0.0415,  0.0163,  ...,  0.0157, -0.0265,  0.0050],\n",
      "        ...,\n",
      "        [ 0.0279, -0.0232,  0.0204,  ..., -0.0251, -0.0045, -0.0340],\n",
      "        [-0.0490,  0.0524, -0.0157,  ...,  0.0544,  0.0354,  0.0334],\n",
      "        [-0.0078,  0.0279,  0.0335,  ...,  0.0225,  0.0306, -0.0153]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0194,  0.0368,  0.0170, -0.0277,  0.0255, -0.0027, -0.0358, -0.0239,\n",
      "         0.0087, -0.0286, -0.0199,  0.0378,  0.0304, -0.0052,  0.0094,  0.0021,\n",
      "        -0.0252,  0.0212,  0.0337,  0.0280], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-0.0207, -0.0034,  0.0102, -0.0154,  0.0081,  0.0051,  0.0036, -0.0078,\n",
      "        -0.0100,  0.0108, -0.0109,  0.0037, -0.0083, -0.0080, -0.0051, -0.0160,\n",
      "         0.0048,  0.0173, -0.0060, -0.0037])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0401,  0.0335,  0.0272, -0.0431,  0.0337,  0.0024, -0.0322, -0.0318,\n",
      "        -0.0013, -0.0178, -0.0308,  0.0415,  0.0221, -0.0133,  0.0043, -0.0139,\n",
      "        -0.0204,  0.0386,  0.0277,  0.0243], requires_grad=True)\n",
      "\n",
      "-=-=--=-=--=-=-=-=\n",
      "\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0144,  0.0671, -0.0041,  ...,  0.0126,  0.0108, -0.0221],\n",
      "        [ 0.0081, -0.0023, -0.0376,  ...,  0.0300,  0.0188, -0.0040],\n",
      "        [-0.0034, -0.0020, -0.0060,  ..., -0.0123,  0.0140, -0.0355],\n",
      "        ...,\n",
      "        [-0.0018,  0.0294,  0.0105,  ...,  0.0089,  0.0092, -0.0123],\n",
      "        [ 0.0271, -0.0137,  0.0257,  ..., -0.0255, -0.0309, -0.0055],\n",
      "        [ 0.0357,  0.0097,  0.0154,  ..., -0.0291,  0.0312,  0.0038]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[ 0.0037,  0.0338,  0.0053,  ...,  0.0020, -0.0018, -0.0068],\n",
      "        [-0.0085, -0.0008, -0.0025,  ...,  0.0010,  0.0188,  0.0186],\n",
      "        [ 0.0090,  0.0057, -0.0025,  ...,  0.0091, -0.0042, -0.0102],\n",
      "        ...,\n",
      "        [-0.0046,  0.0005, -0.0014,  ..., -0.0092,  0.0046, -0.0050],\n",
      "        [ 0.0362, -0.0100, -0.0105,  ..., -0.0071, -0.0116, -0.0116],\n",
      "        [ 0.0013, -0.0108,  0.0026,  ...,  0.0047,  0.0158, -0.0126]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0107,  0.1009,  0.0013,  ...,  0.0145,  0.0090, -0.0289],\n",
      "        [-0.0004, -0.0031, -0.0402,  ...,  0.0310,  0.0376,  0.0146],\n",
      "        [ 0.0055,  0.0037, -0.0086,  ..., -0.0033,  0.0098, -0.0457],\n",
      "        ...,\n",
      "        [-0.0063,  0.0299,  0.0091,  ..., -0.0003,  0.0138, -0.0173],\n",
      "        [ 0.0633, -0.0237,  0.0151,  ..., -0.0326, -0.0425, -0.0171],\n",
      "        [ 0.0371, -0.0011,  0.0180,  ..., -0.0243,  0.0470, -0.0088]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0299,  0.0122,  0.0311, -0.0080,  0.0185, -0.0369,  0.0319,  0.0202,\n",
      "         0.0183, -0.0097,  0.0319,  0.0134,  0.0299,  0.0136,  0.0083, -0.0174,\n",
      "         0.0331,  0.0146, -0.0366,  0.0307, -0.0044, -0.0247,  0.0249, -0.0407,\n",
      "         0.0171,  0.0424,  0.0262,  0.0329,  0.0174, -0.0358,  0.0100,  0.0004,\n",
      "         0.0012, -0.0030,  0.0096, -0.0203, -0.0343, -0.0101, -0.0292,  0.0030,\n",
      "         0.0357,  0.0249, -0.0434,  0.0133, -0.0329, -0.0303, -0.0258, -0.0025,\n",
      "         0.0026,  0.0045,  0.0317, -0.0433,  0.0085,  0.0158, -0.0233, -0.0102,\n",
      "        -0.0049,  0.0111,  0.0215, -0.0147,  0.0142, -0.0023,  0.0033, -0.0245,\n",
      "        -0.0084, -0.0462, -0.0042, -0.0377,  0.0083, -0.0436,  0.0285, -0.0430,\n",
      "         0.0318, -0.0270,  0.0130,  0.0105,  0.0262, -0.0153,  0.0455,  0.0070,\n",
      "         0.0508, -0.0301,  0.0265, -0.0155,  0.0192,  0.0330, -0.0167,  0.0091,\n",
      "        -0.0065,  0.0341,  0.0060,  0.0214, -0.0297,  0.0127, -0.0071, -0.0159,\n",
      "        -0.0016, -0.0329,  0.0385, -0.0288, -0.0177, -0.0013, -0.0566,  0.0094,\n",
      "        -0.0236,  0.0165, -0.0300, -0.0217, -0.0124, -0.0207,  0.0085, -0.0175,\n",
      "         0.0257, -0.0190,  0.0372, -0.0479,  0.0061,  0.0271,  0.0013,  0.0398,\n",
      "        -0.0037,  0.0052,  0.0091,  0.0306, -0.0201, -0.0412,  0.0374,  0.0170,\n",
      "        -0.0232,  0.0011, -0.0305, -0.0343,  0.0214,  0.0394,  0.0044,  0.0068,\n",
      "         0.0351,  0.0173, -0.0157,  0.0251, -0.0183, -0.0264, -0.0035, -0.0243,\n",
      "        -0.0442,  0.0254, -0.0021, -0.0206, -0.0111, -0.0214, -0.0231, -0.0127,\n",
      "        -0.0182,  0.0178, -0.0291,  0.0179,  0.0367,  0.0287,  0.0321,  0.0105,\n",
      "        -0.0286, -0.0098,  0.0517, -0.0293, -0.0185, -0.0319,  0.0189,  0.0512,\n",
      "        -0.0080, -0.0407,  0.0078, -0.0125, -0.0065, -0.0387, -0.0200, -0.0081,\n",
      "        -0.0418,  0.0260,  0.0223, -0.0201,  0.0083, -0.0378, -0.0325, -0.0134,\n",
      "         0.0223, -0.0127,  0.0324, -0.0166, -0.0220,  0.0033, -0.0241, -0.0302,\n",
      "         0.0475, -0.0401,  0.0284, -0.0095, -0.0174, -0.0123, -0.0109,  0.0295,\n",
      "        -0.0025,  0.0236, -0.0210,  0.0540,  0.0431, -0.0239, -0.0341, -0.0261,\n",
      "         0.0487, -0.0293, -0.0406,  0.0412, -0.0361,  0.0341,  0.0177, -0.0094,\n",
      "         0.0071,  0.0368, -0.0191, -0.0267, -0.0204, -0.0280,  0.0040,  0.0370,\n",
      "        -0.0196, -0.0431,  0.0149,  0.0186,  0.0147, -0.0223,  0.0210,  0.0002,\n",
      "        -0.0215,  0.0285,  0.0178, -0.0254,  0.0390,  0.0430, -0.0383, -0.0567,\n",
      "         0.0418, -0.0386,  0.0254,  0.0462,  0.0145, -0.0016, -0.0421, -0.0057,\n",
      "         0.0077, -0.0095, -0.0075,  0.0211, -0.0190,  0.0012,  0.0296,  0.0370,\n",
      "         0.0294, -0.0362,  0.0202, -0.0357,  0.0225,  0.0201, -0.0330, -0.0128,\n",
      "        -0.0146,  0.0031,  0.0338, -0.0068,  0.0486, -0.0526, -0.0115, -0.0050,\n",
      "        -0.0089,  0.0234, -0.0117,  0.0232, -0.0260,  0.0395, -0.0268,  0.0229,\n",
      "        -0.0224, -0.0143, -0.0023,  0.0400,  0.0150,  0.0107,  0.0121, -0.0104,\n",
      "         0.0063, -0.0318,  0.0341, -0.0471,  0.0059,  0.0269, -0.0303,  0.0003,\n",
      "         0.0092,  0.0356, -0.0303, -0.0097,  0.0116, -0.0424,  0.0180, -0.0136,\n",
      "         0.0294, -0.0317, -0.0337, -0.0466, -0.0230, -0.0217,  0.0280,  0.0149,\n",
      "         0.0169, -0.0086,  0.0369,  0.0123,  0.0224, -0.0327,  0.0051,  0.0344,\n",
      "        -0.0270,  0.0201,  0.0250, -0.0205,  0.0085,  0.0254, -0.0101, -0.0135,\n",
      "         0.0105, -0.0039,  0.0024,  0.0006,  0.0020,  0.0149, -0.0194,  0.0367,\n",
      "        -0.0122, -0.0290,  0.0295, -0.0117,  0.0237,  0.0203, -0.0032,  0.0263,\n",
      "        -0.0203,  0.0316, -0.0146,  0.0006,  0.0118, -0.0301,  0.0193,  0.0224,\n",
      "         0.0107,  0.0109,  0.0185, -0.0127,  0.0242,  0.0105, -0.0217, -0.0110,\n",
      "         0.0132, -0.0032, -0.0016,  0.0308,  0.0067,  0.0314,  0.0152, -0.0014,\n",
      "         0.0299,  0.0208, -0.0180,  0.0450,  0.0400,  0.0033, -0.0079,  0.0169,\n",
      "        -0.0253, -0.0263, -0.0142,  0.0162,  0.0045, -0.0264, -0.0135,  0.0306,\n",
      "         0.0130, -0.0116,  0.0319,  0.0291, -0.0036,  0.0103, -0.0184, -0.0412,\n",
      "         0.0357, -0.0175,  0.0090, -0.0099, -0.0277,  0.0307,  0.0217, -0.0271,\n",
      "        -0.0181,  0.0183, -0.0422,  0.0340, -0.0014,  0.0275, -0.0181,  0.0034,\n",
      "        -0.0309, -0.0106, -0.0150, -0.0262,  0.0104,  0.0247, -0.0398,  0.0194,\n",
      "         0.0382, -0.0188,  0.0043, -0.0220, -0.0203,  0.0037,  0.0305, -0.0162,\n",
      "         0.0119, -0.0092, -0.0008,  0.0092, -0.0269, -0.0105,  0.0344, -0.0034,\n",
      "        -0.0054,  0.0023, -0.0262,  0.0048,  0.0335, -0.0044, -0.0430, -0.0069,\n",
      "        -0.0306, -0.0131, -0.0357, -0.0469,  0.0145,  0.0304, -0.0481, -0.0405,\n",
      "        -0.0099,  0.0056, -0.0303,  0.0007, -0.0216, -0.0268, -0.0211, -0.0356,\n",
      "         0.0169, -0.0030,  0.0043,  0.0158,  0.0356,  0.0296,  0.0008, -0.0475,\n",
      "         0.0314, -0.0141,  0.0378, -0.0166, -0.0333,  0.0134, -0.0072,  0.0052,\n",
      "        -0.0353, -0.0039, -0.0307,  0.0083, -0.0077,  0.0038, -0.0179, -0.0287,\n",
      "        -0.0417, -0.0295, -0.0314,  0.0204, -0.0370,  0.0332,  0.0120, -0.0394,\n",
      "        -0.0360, -0.0242,  0.0141, -0.0249, -0.0122, -0.0053,  0.0103, -0.0054,\n",
      "         0.0002,  0.0265, -0.0028,  0.0264,  0.0287, -0.0193, -0.0251,  0.0083,\n",
      "        -0.0117,  0.0139, -0.0375, -0.0297,  0.0268, -0.0114, -0.0068, -0.0009],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-3.2877e-02, -2.4876e-03, -5.3173e-03, -1.4696e-02, -1.1109e-02,\n",
      "        -7.9672e-03,  7.1170e-03, -1.4917e-02,  3.9464e-03,  6.0043e-03,\n",
      "         5.2198e-03, -2.7263e-03,  1.3003e-02, -1.5088e-02, -6.9056e-03,\n",
      "         8.2287e-03,  1.6656e-02,  1.7385e-02, -2.9257e-03, -4.5585e-03,\n",
      "         1.3461e-02,  1.8168e-03,  8.6949e-03, -1.1536e-02, -9.9767e-03,\n",
      "         7.1234e-03, -1.0601e-02,  1.3345e-02, -7.9809e-03, -8.5809e-03,\n",
      "         1.6374e-02,  9.9025e-04, -1.5518e-04, -2.4936e-02,  1.9980e-02,\n",
      "        -6.5364e-03, -2.8980e-03,  1.8415e-02, -1.0492e-02,  5.5149e-03,\n",
      "        -1.6035e-03, -8.4557e-03, -1.0577e-02,  2.1279e-03, -4.0008e-03,\n",
      "        -8.5507e-04, -6.7895e-03, -2.6336e-03,  1.0623e-02,  2.4843e-02,\n",
      "        -6.8776e-03, -7.6152e-03, -9.3843e-03, -1.2487e-02, -8.6449e-03,\n",
      "         1.2846e-02,  1.3158e-02, -9.6916e-03, -8.1880e-03,  8.4150e-03,\n",
      "         7.0346e-03, -4.8205e-03,  4.3171e-03,  7.3266e-03,  1.3503e-02,\n",
      "        -8.1350e-03, -2.4886e-02, -5.5153e-03, -2.5045e-03, -8.4519e-03,\n",
      "        -5.0224e-03, -8.5555e-03,  1.8339e-02, -1.0903e-02,  1.4546e-03,\n",
      "         1.1109e-02,  1.4051e-02, -1.1282e-02,  6.6994e-03, -7.8758e-03,\n",
      "         1.2070e-02, -9.6318e-04, -4.9424e-03,  5.4079e-03,  5.3572e-03,\n",
      "        -6.5429e-04, -4.9722e-03, -5.2240e-03, -2.0968e-03,  1.4210e-02,\n",
      "        -6.5444e-03,  3.3136e-03, -3.7753e-04, -1.6224e-02,  1.0222e-02,\n",
      "         5.6408e-03,  4.6206e-03, -8.7892e-03,  5.6745e-03,  5.1879e-03,\n",
      "        -1.7589e-02,  6.8678e-04, -1.7651e-02, -1.3122e-02,  1.0292e-02,\n",
      "        -1.3054e-02, -7.2003e-03,  9.1829e-03, -6.9234e-03, -1.2049e-02,\n",
      "         4.9965e-03, -3.3415e-03, -1.1101e-02,  6.2079e-03,  6.7153e-03,\n",
      "        -1.2520e-02, -1.6371e-03, -5.5218e-04,  8.5455e-03,  7.5174e-03,\n",
      "         5.6306e-03,  1.9718e-02, -1.3633e-03,  4.2444e-03, -5.2030e-03,\n",
      "        -9.5692e-03,  3.2330e-03,  1.3413e-02, -7.5289e-03,  1.2150e-03,\n",
      "        -1.3408e-02,  7.0175e-04, -9.3072e-03,  1.1539e-02,  7.3541e-03,\n",
      "         1.3075e-02, -3.1099e-03,  9.1061e-03, -2.1471e-03, -9.1346e-03,\n",
      "         3.0283e-03, -2.0801e-03, -1.5889e-02, -1.2595e-02, -1.2691e-02,\n",
      "         4.8654e-03, -1.2659e-02, -1.7314e-02,  8.3205e-03, -3.3005e-03,\n",
      "        -1.5135e-02,  1.8233e-04,  1.9222e-02, -1.3159e-02, -1.4571e-02,\n",
      "         4.7223e-03,  1.0136e-02,  1.5004e-02,  6.0034e-03, -9.7485e-03,\n",
      "         1.4039e-03,  1.7130e-02,  1.3551e-02, -1.0626e-02,  3.1205e-03,\n",
      "        -3.4546e-03,  1.8102e-02,  1.2273e-02, -5.3423e-03, -1.7413e-02,\n",
      "        -6.7759e-03,  4.0320e-03, -5.2986e-04, -1.4444e-02,  1.2652e-03,\n",
      "        -4.6194e-04, -2.0769e-02, -4.8355e-03, -4.6360e-03,  9.5385e-04,\n",
      "         2.8502e-03, -7.7942e-03,  1.4461e-03, -8.7690e-03,  3.4682e-03,\n",
      "         7.1879e-03,  1.0505e-03, -3.7391e-02, -6.9014e-03,  1.6894e-02,\n",
      "        -1.5845e-02, -1.0053e-02,  9.2367e-03, -8.8519e-03,  2.3262e-02,\n",
      "        -1.8289e-04, -4.0170e-03,  1.0037e-02, -5.7034e-03,  7.1946e-03,\n",
      "         3.3497e-03, -1.4550e-02,  5.5553e-03,  2.3244e-02,  1.2356e-02,\n",
      "        -5.6757e-03, -4.1096e-03, -2.4090e-03,  1.2431e-02, -1.3649e-02,\n",
      "        -3.0957e-03,  7.1697e-03, -1.4001e-03,  1.6385e-02,  1.0760e-02,\n",
      "         6.3801e-03, -1.6450e-02,  3.3982e-03, -5.6180e-03,  4.1690e-03,\n",
      "         6.7647e-03, -8.2364e-03,  2.7764e-03,  4.1689e-03, -1.6506e-02,\n",
      "        -4.4239e-03, -5.4855e-03,  2.0863e-03, -1.4834e-02,  3.2515e-04,\n",
      "         9.2575e-03, -8.5717e-03, -9.8578e-03, -3.6467e-03,  6.3841e-03,\n",
      "         1.2540e-02,  1.5478e-03,  6.8956e-03, -1.8647e-02, -2.1716e-02,\n",
      "         5.1152e-03, -1.0028e-02,  2.6794e-02,  8.0242e-03, -5.3111e-03,\n",
      "         3.5987e-03, -3.5694e-03,  2.1684e-02,  5.5819e-03, -9.5854e-03,\n",
      "         6.1787e-03,  4.2904e-03,  6.8971e-04,  4.7569e-03,  6.9915e-03,\n",
      "         1.3726e-02, -2.6594e-03, -5.1547e-03,  1.1799e-02,  4.5326e-04,\n",
      "         8.2169e-03,  5.1496e-03,  3.9775e-03, -6.8998e-04,  5.2677e-03,\n",
      "         5.7793e-03,  8.6975e-03,  4.8033e-03,  2.0219e-02, -1.6783e-02,\n",
      "        -2.0713e-02,  1.2794e-02, -7.4695e-03,  1.3289e-02, -1.0828e-02,\n",
      "         1.4621e-02,  4.3179e-03,  1.4862e-03,  1.1974e-02, -1.5821e-02,\n",
      "        -9.6411e-03, -9.5105e-03,  9.7927e-03,  2.1860e-02,  2.6396e-05,\n",
      "        -1.6529e-03, -1.1056e-02, -1.6546e-02,  4.6704e-03,  5.1676e-03,\n",
      "         5.5101e-03, -1.1069e-02,  4.0701e-03, -1.1115e-02,  7.4118e-03,\n",
      "        -1.3840e-02, -4.9173e-03,  2.1775e-02,  6.5851e-04,  9.3934e-04,\n",
      "        -7.5752e-03, -3.5407e-02,  2.0036e-03,  4.5194e-03, -5.2139e-03,\n",
      "        -2.1829e-03,  1.0714e-03, -2.1807e-02,  1.6608e-03, -1.3473e-02,\n",
      "        -2.5995e-03, -1.1184e-02, -7.5810e-03,  1.4504e-02,  9.7259e-03,\n",
      "        -1.5868e-02,  1.7612e-03, -5.6893e-03, -4.4608e-03, -2.4155e-03,\n",
      "        -9.8150e-03,  1.4786e-02,  8.0807e-03,  2.6953e-03,  8.4540e-03,\n",
      "         2.5876e-03, -4.3147e-03,  4.5800e-03,  6.1188e-03,  1.7226e-02,\n",
      "         2.4547e-03, -7.9803e-03, -1.4806e-03,  4.1896e-04,  7.1294e-04,\n",
      "         1.3921e-02,  5.4473e-03,  9.9063e-05,  1.5270e-02, -6.9814e-03,\n",
      "        -4.0282e-03,  3.0029e-03, -1.9394e-03, -1.0962e-02,  3.2893e-03,\n",
      "         1.3408e-03,  7.1710e-03, -1.4698e-02,  9.6706e-03,  8.1511e-03,\n",
      "         4.4331e-03,  1.0763e-02, -6.5358e-03,  1.1349e-02, -9.8276e-03,\n",
      "        -4.9412e-03, -4.0608e-03,  7.1021e-04, -1.4614e-02,  2.2638e-02,\n",
      "        -3.9664e-03, -2.3307e-02,  2.9687e-03,  5.3238e-03, -9.4346e-03,\n",
      "         4.6782e-03, -2.3913e-03, -1.3725e-02,  9.7377e-03, -7.8651e-03,\n",
      "         4.6133e-03,  6.0109e-03,  5.1832e-03, -9.0268e-03,  4.6565e-03,\n",
      "         7.4755e-03,  9.8564e-03, -1.3842e-02, -1.1256e-02,  2.1203e-02,\n",
      "         2.6506e-03,  1.9901e-03, -7.3997e-03,  4.8049e-03,  1.4247e-02,\n",
      "         2.9888e-03,  4.2123e-03,  6.2473e-03, -5.1362e-03, -1.0091e-02,\n",
      "         1.0567e-02, -1.1299e-02,  6.6255e-03,  8.9109e-03,  1.1321e-02,\n",
      "        -1.2362e-02, -1.3269e-02,  3.3108e-03, -3.4322e-03,  2.1260e-04,\n",
      "         3.5100e-04,  1.4623e-03, -1.9540e-02,  7.6505e-03,  5.6630e-03,\n",
      "        -5.1229e-03,  5.7296e-03, -4.5310e-03,  1.9598e-03, -8.2018e-04,\n",
      "        -2.0888e-03, -2.3980e-02, -3.2302e-03, -1.4247e-02, -2.4274e-03,\n",
      "         2.3256e-03,  1.5860e-02, -2.1929e-03,  4.3824e-04,  7.4089e-04,\n",
      "         4.2830e-03, -4.0824e-03,  6.9311e-03,  2.2359e-02, -1.7033e-02,\n",
      "         7.9096e-04, -4.2970e-03, -3.5650e-03, -1.5503e-03, -7.6442e-03,\n",
      "        -3.8927e-03,  2.4444e-02,  3.9077e-03, -9.8863e-03,  1.0270e-03,\n",
      "        -1.1188e-02, -5.1909e-03, -8.5443e-03, -1.1127e-02, -1.6208e-02,\n",
      "        -5.0151e-03, -1.6602e-02,  1.6034e-03, -1.2341e-02, -9.1954e-03,\n",
      "         9.4946e-03, -1.0510e-02, -3.1451e-03,  3.4588e-03, -6.5034e-03,\n",
      "         8.0906e-04, -5.6163e-03, -4.6285e-03, -1.0848e-02, -6.9351e-03,\n",
      "        -6.9840e-03,  2.0678e-02,  1.1677e-02, -4.5185e-03,  2.0279e-02,\n",
      "         5.8237e-03,  4.2044e-03,  3.8114e-03, -1.5297e-02, -6.3694e-03,\n",
      "        -5.3603e-03,  1.6751e-02,  1.8342e-03, -1.3581e-02,  2.3880e-03,\n",
      "         1.4186e-02,  1.1925e-02, -6.0127e-03,  5.1134e-03, -5.9205e-03,\n",
      "         2.7272e-03,  1.5875e-03, -1.3732e-03,  5.1129e-05,  6.6718e-03,\n",
      "        -1.0361e-02,  6.5484e-03, -7.5837e-04, -1.3093e-03, -1.3724e-03,\n",
      "         9.1483e-03, -3.8465e-03, -4.0942e-03, -5.0478e-03,  8.4431e-03,\n",
      "         6.0338e-03,  2.1592e-03,  9.0820e-03, -3.6356e-03,  2.6997e-03,\n",
      "        -1.0616e-03,  1.0699e-02, -9.7245e-03, -1.7654e-02,  1.1421e-02,\n",
      "         3.4910e-03, -2.7524e-03,  1.0042e-02, -9.9530e-03, -1.6294e-03,\n",
      "         5.7010e-03, -4.3761e-03,  8.1254e-03,  3.0549e-03, -1.9457e-03,\n",
      "        -5.0004e-03,  7.1033e-03])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0628,  0.0097,  0.0258, -0.0227,  0.0074, -0.0448,  0.0391,  0.0053,\n",
      "         0.0222, -0.0037,  0.0371,  0.0107,  0.0429, -0.0015,  0.0014, -0.0091,\n",
      "         0.0497,  0.0320, -0.0395,  0.0261,  0.0090, -0.0229,  0.0336, -0.0522,\n",
      "         0.0071,  0.0495,  0.0156,  0.0463,  0.0095, -0.0444,  0.0264,  0.0014,\n",
      "         0.0010, -0.0279,  0.0296, -0.0269, -0.0372,  0.0083, -0.0396,  0.0086,\n",
      "         0.0341,  0.0165, -0.0540,  0.0154, -0.0369, -0.0311, -0.0326, -0.0051,\n",
      "         0.0132,  0.0293,  0.0249, -0.0509, -0.0009,  0.0033, -0.0320,  0.0026,\n",
      "         0.0083,  0.0014,  0.0133, -0.0062,  0.0212, -0.0071,  0.0076, -0.0171,\n",
      "         0.0051, -0.0543, -0.0291, -0.0432,  0.0058, -0.0520,  0.0235, -0.0516,\n",
      "         0.0502, -0.0379,  0.0144,  0.0216,  0.0403, -0.0266,  0.0522, -0.0008,\n",
      "         0.0628, -0.0311,  0.0215, -0.0101,  0.0246,  0.0324, -0.0216,  0.0038,\n",
      "        -0.0086,  0.0483, -0.0005,  0.0248, -0.0301, -0.0035,  0.0032, -0.0103,\n",
      "         0.0030, -0.0417,  0.0442, -0.0236, -0.0353, -0.0006, -0.0743, -0.0037,\n",
      "        -0.0133,  0.0034, -0.0372, -0.0125, -0.0193, -0.0327,  0.0135, -0.0209,\n",
      "         0.0146, -0.0128,  0.0439, -0.0605,  0.0045,  0.0265,  0.0098,  0.0473,\n",
      "         0.0019,  0.0249,  0.0077,  0.0349, -0.0253, -0.0507,  0.0406,  0.0305,\n",
      "        -0.0307,  0.0023, -0.0439, -0.0336,  0.0121,  0.0509,  0.0118,  0.0198,\n",
      "         0.0320,  0.0264, -0.0178,  0.0160, -0.0153, -0.0284, -0.0194, -0.0369,\n",
      "        -0.0568,  0.0302, -0.0148, -0.0379, -0.0028, -0.0247, -0.0383, -0.0125,\n",
      "         0.0010,  0.0046, -0.0436,  0.0226,  0.0468,  0.0437,  0.0382,  0.0007,\n",
      "        -0.0272,  0.0073,  0.0652, -0.0400, -0.0153, -0.0353,  0.0370,  0.0635,\n",
      "        -0.0133, -0.0581,  0.0010, -0.0085, -0.0070, -0.0531, -0.0187, -0.0085,\n",
      "        -0.0626,  0.0211,  0.0177, -0.0192,  0.0111, -0.0456, -0.0311, -0.0221,\n",
      "         0.0257, -0.0055,  0.0334, -0.0540, -0.0289,  0.0202, -0.0400, -0.0403,\n",
      "         0.0568, -0.0489,  0.0516, -0.0097, -0.0214, -0.0023, -0.0166,  0.0367,\n",
      "         0.0009,  0.0090, -0.0155,  0.0772,  0.0555, -0.0296, -0.0382, -0.0285,\n",
      "         0.0612, -0.0429, -0.0437,  0.0484, -0.0375,  0.0505,  0.0284, -0.0031,\n",
      "        -0.0093,  0.0402, -0.0247, -0.0225, -0.0136, -0.0363,  0.0068,  0.0411,\n",
      "        -0.0361, -0.0475,  0.0094,  0.0207, -0.0001, -0.0220,  0.0302, -0.0084,\n",
      "        -0.0314,  0.0249,  0.0242, -0.0128,  0.0405,  0.0499, -0.0569, -0.0784,\n",
      "         0.0469, -0.0487,  0.0522,  0.0542,  0.0092,  0.0020, -0.0457,  0.0159,\n",
      "         0.0133, -0.0191, -0.0013,  0.0254, -0.0183,  0.0060,  0.0366,  0.0507,\n",
      "         0.0267, -0.0414,  0.0320, -0.0352,  0.0307,  0.0253, -0.0290, -0.0135,\n",
      "        -0.0093,  0.0089,  0.0425, -0.0020,  0.0688, -0.0694, -0.0322,  0.0078,\n",
      "        -0.0164,  0.0367, -0.0225,  0.0378, -0.0217,  0.0410, -0.0148,  0.0071,\n",
      "        -0.0321, -0.0238,  0.0075,  0.0619,  0.0150,  0.0091,  0.0011, -0.0269,\n",
      "         0.0110, -0.0266,  0.0396, -0.0581,  0.0100,  0.0158, -0.0229, -0.0135,\n",
      "         0.0043,  0.0574, -0.0296, -0.0087,  0.0040, -0.0778,  0.0200, -0.0090,\n",
      "         0.0242, -0.0338, -0.0327, -0.0684, -0.0214, -0.0352,  0.0254,  0.0037,\n",
      "         0.0094,  0.0059,  0.0467, -0.0035,  0.0241, -0.0384,  0.0006,  0.0320,\n",
      "        -0.0368,  0.0349,  0.0331, -0.0178,  0.0170,  0.0280, -0.0145, -0.0090,\n",
      "         0.0166,  0.0133,  0.0049, -0.0074,  0.0006,  0.0153, -0.0187,  0.0506,\n",
      "        -0.0067, -0.0289,  0.0448, -0.0187,  0.0197,  0.0233, -0.0052,  0.0153,\n",
      "        -0.0171,  0.0329, -0.0075, -0.0141,  0.0215, -0.0220,  0.0237,  0.0332,\n",
      "         0.0042,  0.0223,  0.0087, -0.0176,  0.0201,  0.0112, -0.0363,  0.0117,\n",
      "         0.0092, -0.0265,  0.0013,  0.0361, -0.0028,  0.0360,  0.0128, -0.0151,\n",
      "         0.0397,  0.0129, -0.0134,  0.0510,  0.0452, -0.0058, -0.0032,  0.0244,\n",
      "        -0.0154, -0.0402, -0.0255,  0.0374,  0.0071, -0.0244, -0.0209,  0.0354,\n",
      "         0.0272, -0.0086,  0.0361,  0.0353, -0.0088,  0.0002, -0.0078, -0.0525,\n",
      "         0.0423, -0.0086,  0.0203, -0.0222, -0.0409,  0.0340,  0.0183, -0.0269,\n",
      "        -0.0177,  0.0197, -0.0618,  0.0417,  0.0042,  0.0224, -0.0123, -0.0012,\n",
      "        -0.0289, -0.0114, -0.0171, -0.0502,  0.0071,  0.0105, -0.0422,  0.0217,\n",
      "         0.0541, -0.0210,  0.0048, -0.0212, -0.0160, -0.0003,  0.0374,  0.0062,\n",
      "        -0.0052, -0.0084, -0.0051,  0.0056, -0.0284, -0.0182,  0.0305,  0.0210,\n",
      "        -0.0015, -0.0075, -0.0252, -0.0064,  0.0284, -0.0130, -0.0541, -0.0231,\n",
      "        -0.0356, -0.0297, -0.0341, -0.0592,  0.0053,  0.0399, -0.0586, -0.0437,\n",
      "        -0.0064, -0.0009, -0.0295, -0.0049, -0.0263, -0.0376, -0.0280, -0.0426,\n",
      "         0.0375,  0.0087, -0.0002,  0.0361,  0.0414,  0.0338,  0.0046, -0.0628,\n",
      "         0.0250, -0.0195,  0.0545, -0.0148, -0.0469,  0.0158,  0.0070,  0.0171,\n",
      "        -0.0413,  0.0012, -0.0366,  0.0111, -0.0061,  0.0024, -0.0179, -0.0220,\n",
      "        -0.0521, -0.0229, -0.0322,  0.0191, -0.0384,  0.0423,  0.0081, -0.0435,\n",
      "        -0.0411, -0.0158,  0.0202, -0.0227, -0.0031, -0.0089,  0.0130, -0.0065,\n",
      "         0.0109,  0.0168, -0.0204,  0.0378,  0.0322, -0.0221, -0.0150, -0.0016,\n",
      "        -0.0133,  0.0196, -0.0419, -0.0216,  0.0298, -0.0134, -0.0118,  0.0062],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0149, -0.0344,  0.0119,  ...,  0.0507, -0.0243,  0.0286],\n",
      "        [ 0.0575,  0.0413, -0.0082,  ...,  0.0361,  0.0137, -0.0049],\n",
      "        [-0.0255, -0.0277, -0.0216,  ..., -0.0341, -0.0405,  0.0144],\n",
      "        ...,\n",
      "        [ 0.0215, -0.0304,  0.0109,  ..., -0.0269,  0.0376, -0.0146],\n",
      "        [ 0.0061, -0.0171, -0.0338,  ..., -0.0371, -0.0140, -0.0049],\n",
      "        [ 0.0156,  0.0040, -0.0012,  ..., -0.0151,  0.0580, -0.0220]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-0.0042, -0.0147, -0.0009,  ...,  0.0118,  0.0015, -0.0113],\n",
      "        [ 0.0260, -0.0029,  0.0007,  ...,  0.0059, -0.0142,  0.0130],\n",
      "        [-0.0006,  0.0040,  0.0132,  ..., -0.0299, -0.0120,  0.0084],\n",
      "        ...,\n",
      "        [ 0.0014,  0.0069, -0.0066,  ..., -0.0052,  0.0086, -0.0093],\n",
      "        [ 0.0076,  0.0129, -0.0114,  ..., -0.0204, -0.0045,  0.0036],\n",
      "        [ 0.0108,  0.0068,  0.0004,  ...,  0.0041,  0.0178, -0.0008]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0192, -0.0491,  0.0110,  ...,  0.0625, -0.0228,  0.0174],\n",
      "        [ 0.0836,  0.0384, -0.0075,  ...,  0.0419, -0.0005,  0.0082],\n",
      "        [-0.0260, -0.0237, -0.0084,  ..., -0.0640, -0.0525,  0.0228],\n",
      "        ...,\n",
      "        [ 0.0228, -0.0235,  0.0043,  ..., -0.0322,  0.0462, -0.0239],\n",
      "        [ 0.0137, -0.0042, -0.0451,  ..., -0.0575, -0.0186, -0.0013],\n",
      "        [ 0.0264,  0.0108, -0.0009,  ..., -0.0110,  0.0758, -0.0228]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([ 2.0348e-02, -2.6663e-02, -3.1895e-02,  3.7376e-02, -3.4446e-02,\n",
      "        -5.9723e-03, -3.5141e-02, -2.5347e-03, -3.8255e-02, -3.0165e-02,\n",
      "         3.5576e-02,  9.6801e-03,  3.5386e-02,  6.9590e-03, -1.5661e-02,\n",
      "        -2.5415e-02, -1.8419e-02, -1.3039e-02, -5.3021e-02,  2.8183e-02,\n",
      "         3.7596e-02, -3.2713e-02,  4.7846e-02,  2.7442e-02, -7.0301e-03,\n",
      "        -2.2950e-02,  6.6884e-03,  1.0124e-03,  2.2447e-03,  1.4987e-02,\n",
      "        -3.8746e-03, -2.5397e-02, -8.3769e-03,  2.6158e-02, -4.7408e-02,\n",
      "        -1.4642e-02, -3.0259e-02, -2.2526e-02,  4.2165e-04, -4.4274e-02,\n",
      "        -1.6075e-02,  2.6593e-02,  1.7548e-02, -1.1736e-03, -4.4761e-02,\n",
      "        -2.1294e-02, -2.4950e-02,  5.1891e-02, -4.3974e-02, -2.1677e-02,\n",
      "         2.0178e-02, -3.3285e-02,  1.8760e-02, -2.5740e-02, -1.3547e-02,\n",
      "         1.2552e-03,  3.2396e-02, -2.1252e-02, -1.2363e-02, -1.8300e-02,\n",
      "         5.1614e-02,  3.4403e-02,  3.9781e-02, -4.3549e-02, -1.4909e-02,\n",
      "         4.5354e-02, -1.9660e-02, -3.5173e-02, -2.2278e-02,  4.1488e-02,\n",
      "         2.5021e-02, -2.6783e-02,  3.0074e-02, -7.2523e-03,  5.2261e-02,\n",
      "        -3.7557e-02, -5.0158e-02,  4.1460e-02, -2.3563e-02, -2.6088e-02,\n",
      "        -4.1420e-02,  3.1657e-02, -3.9854e-02,  1.1082e-02,  2.5261e-02,\n",
      "         2.5637e-02,  2.3612e-02,  3.9667e-02,  9.6689e-03, -7.7987e-03,\n",
      "         4.7912e-03,  1.8973e-02,  5.5099e-03, -2.0703e-02, -5.4619e-02,\n",
      "         1.7047e-02,  3.5820e-03,  2.1917e-02, -2.1623e-02,  2.8935e-02,\n",
      "        -3.0503e-02, -5.5046e-03,  2.7293e-02, -3.6502e-03,  5.0433e-02,\n",
      "         1.9268e-02, -3.2032e-02, -3.3143e-02,  6.2668e-03, -3.6751e-02,\n",
      "         2.3512e-02, -4.6419e-02, -2.9763e-02,  2.4991e-02,  4.9604e-02,\n",
      "         3.4065e-02, -2.0090e-02, -5.1577e-02,  4.1995e-03,  4.1785e-02,\n",
      "         4.2762e-03,  3.3979e-02, -1.1886e-02,  5.1555e-02, -8.5587e-03,\n",
      "         3.4332e-02, -1.0906e-02, -2.8272e-02,  1.7439e-02,  2.8360e-02,\n",
      "         2.4275e-03,  3.3794e-02, -4.6448e-02,  2.3662e-04, -2.3340e-02,\n",
      "        -2.4433e-02, -1.6082e-02, -2.6543e-02, -3.7940e-03, -9.4589e-03,\n",
      "        -1.8724e-02,  1.9845e-02,  3.0154e-02, -3.8463e-02, -3.6626e-02,\n",
      "         1.2958e-02,  4.5205e-02,  1.4945e-02,  4.7196e-02,  6.6299e-03,\n",
      "        -3.1975e-02, -5.9518e-02,  1.8441e-02, -4.4073e-03,  2.8755e-03,\n",
      "         3.2327e-02,  1.8351e-02,  3.5253e-02,  2.5054e-02, -1.1036e-02,\n",
      "         3.1967e-02,  3.8730e-02,  3.4316e-02, -9.8696e-03, -5.1872e-03,\n",
      "         9.4531e-03, -3.1713e-02,  1.3222e-02,  3.2280e-02, -8.4235e-03,\n",
      "         3.0690e-03, -1.5230e-02, -2.3737e-03,  1.7227e-02, -5.9911e-03,\n",
      "         6.1293e-03, -3.7200e-02, -1.9936e-03, -3.6997e-02, -5.5810e-02,\n",
      "         3.4901e-02, -1.0248e-02,  1.7128e-02,  4.7741e-02,  5.1222e-02,\n",
      "        -1.4954e-02,  4.6814e-02, -3.4631e-02, -2.9544e-02,  1.7431e-02,\n",
      "        -1.4765e-02,  2.4494e-02, -1.9086e-02, -2.6767e-02, -3.1604e-02,\n",
      "        -2.4219e-02, -1.3354e-02,  5.4151e-02, -4.4603e-02, -2.1152e-03,\n",
      "         2.9627e-02,  3.1435e-02,  1.9914e-02,  1.9916e-02,  3.5411e-02,\n",
      "        -4.4583e-02,  2.8359e-02, -1.5971e-02,  4.4313e-02,  3.5986e-03,\n",
      "        -4.1740e-02, -2.8862e-02, -7.8721e-03, -4.1718e-02, -3.7926e-02,\n",
      "        -8.1768e-03, -5.2913e-03, -2.1398e-02, -1.5600e-02, -4.2829e-02,\n",
      "        -2.4961e-02, -4.6792e-02, -2.9285e-03,  1.1986e-02,  1.1083e-02,\n",
      "        -4.3765e-02, -1.1404e-02, -4.3183e-02, -1.6963e-02,  2.6692e-02,\n",
      "        -1.0964e-02, -2.0189e-02,  4.4670e-03, -3.8611e-02,  4.5891e-02,\n",
      "         7.6461e-03,  2.6207e-02, -8.6275e-03, -5.1422e-03,  1.2030e-02,\n",
      "        -7.2366e-03, -2.4184e-02,  1.6918e-02, -1.2971e-02, -1.2225e-02,\n",
      "         2.4943e-02, -4.7370e-02, -2.7458e-02,  1.9832e-02, -3.3656e-02,\n",
      "        -3.1124e-02,  8.3799e-03, -6.8225e-03, -1.8381e-02, -6.5375e-03,\n",
      "         1.1394e-02,  5.0792e-02,  7.3777e-03, -2.4633e-03,  1.9847e-02,\n",
      "        -1.1529e-02, -1.5164e-02,  2.9769e-02,  1.6535e-02, -4.8081e-03,\n",
      "         4.8685e-02,  1.7938e-04,  2.8611e-02, -3.0219e-02, -1.2663e-02,\n",
      "        -3.5479e-02,  1.5101e-02, -8.1936e-03,  2.9560e-02, -2.5838e-02,\n",
      "        -2.5342e-02,  3.2332e-02,  9.8762e-03,  3.0770e-02, -3.3200e-02,\n",
      "         3.4459e-02,  7.0187e-03, -2.7782e-02,  5.1447e-02,  2.6982e-02,\n",
      "        -3.9487e-02, -8.3303e-05,  5.9206e-02,  2.5106e-03,  1.0794e-02,\n",
      "        -1.0099e-02,  3.8449e-02, -5.7381e-03,  2.2579e-02, -3.0949e-02,\n",
      "         2.7362e-02, -2.4894e-02, -3.9029e-04,  3.1321e-02, -1.2562e-02,\n",
      "        -3.5038e-02, -3.6958e-02, -3.2534e-02, -4.7496e-02,  2.0259e-03,\n",
      "        -1.8700e-02, -1.4582e-02, -3.3718e-02,  2.2913e-02, -1.7850e-02,\n",
      "         1.0407e-02,  1.0680e-03, -1.8401e-02, -2.4961e-04,  1.1951e-02,\n",
      "         1.0448e-02, -2.0883e-02, -3.0712e-02,  3.7084e-02,  5.2386e-02,\n",
      "         2.0165e-02,  2.3854e-02,  4.9803e-02, -2.6233e-02, -1.5505e-02,\n",
      "        -3.7098e-02, -3.8474e-02, -1.0020e-02, -3.1857e-02, -6.2217e-05,\n",
      "         3.2296e-02, -2.7847e-02, -4.5164e-02, -2.2130e-02, -2.9712e-02,\n",
      "         1.6858e-03,  2.9080e-02,  3.6771e-03, -4.6690e-02, -3.8668e-02,\n",
      "         2.9443e-02,  2.7053e-02, -1.8116e-02,  1.2174e-02,  3.9448e-02,\n",
      "         8.4040e-03,  4.9031e-02,  5.1198e-03,  3.4535e-02,  4.9279e-02,\n",
      "        -9.7689e-04, -1.3395e-02, -2.2088e-02,  4.1235e-02, -3.8128e-02,\n",
      "         2.9229e-02,  6.5279e-03, -3.3033e-02,  8.4334e-03, -1.5025e-03,\n",
      "         3.8454e-02, -1.3467e-02, -2.2931e-02,  1.1378e-03,  3.5697e-02,\n",
      "         3.1897e-02, -1.9575e-02, -2.1676e-02,  3.0178e-03,  1.5884e-02,\n",
      "        -1.5955e-02,  6.1972e-03, -1.2524e-03, -1.7187e-03, -1.5960e-02,\n",
      "         2.1166e-02, -1.4812e-02, -2.6022e-02, -8.9849e-04,  3.7402e-02,\n",
      "        -6.6121e-03,  4.4340e-02, -1.7883e-02, -3.7830e-02, -5.0651e-02,\n",
      "         4.3197e-02,  1.7649e-02, -1.1328e-02, -3.9779e-02, -2.5859e-02,\n",
      "        -2.9710e-05, -3.9285e-02,  3.3716e-02,  2.3479e-02,  4.4924e-03,\n",
      "        -1.9504e-02, -8.3902e-03, -2.1083e-02,  1.6586e-03,  4.1018e-02,\n",
      "         1.4096e-02, -5.1485e-02, -3.8811e-02,  2.6958e-02,  3.0942e-02,\n",
      "         1.8309e-03, -1.8318e-02, -4.5760e-02, -1.5863e-02,  1.2816e-02,\n",
      "         1.4890e-02, -4.1739e-02,  2.9548e-02,  1.3384e-02, -4.6698e-02,\n",
      "        -6.2560e-02,  2.2064e-02,  3.9830e-03, -6.7132e-03, -3.1357e-02,\n",
      "        -1.1012e-02, -3.7421e-02,  2.9482e-02, -7.3862e-03, -3.0123e-02,\n",
      "        -2.9117e-02, -3.5185e-02, -2.2926e-02,  6.1868e-02, -1.1454e-02,\n",
      "         1.3072e-02, -3.9587e-03,  5.7113e-03,  3.6249e-02, -4.4004e-02,\n",
      "         1.2857e-03,  4.7065e-02,  2.2793e-02,  3.2580e-02,  1.1645e-02,\n",
      "         5.3351e-02,  2.0280e-02,  2.1984e-03,  9.7114e-03, -3.1957e-03,\n",
      "         3.9327e-02, -1.5907e-02, -3.5848e-02,  5.5362e-02, -8.3930e-03,\n",
      "        -1.9321e-02,  1.7670e-02,  4.5802e-02, -2.7567e-02,  4.0050e-02,\n",
      "         4.3328e-02, -3.6397e-02, -2.9080e-02, -3.4877e-02, -1.5618e-02,\n",
      "        -3.6532e-02, -1.5593e-02, -4.2868e-02,  1.7080e-02, -3.2694e-02,\n",
      "        -9.0473e-03, -1.6264e-02, -4.8009e-02,  4.2500e-02,  3.4953e-02,\n",
      "         2.7594e-02,  2.1379e-02, -3.3268e-02,  5.3511e-02, -3.3062e-02,\n",
      "         5.6337e-02,  9.3126e-03, -3.9307e-02,  3.3023e-02,  2.7216e-02,\n",
      "        -2.3645e-02,  2.5964e-02,  5.2485e-02, -2.4661e-02, -1.6577e-03,\n",
      "         1.0637e-02, -4.1838e-02, -7.4187e-03,  1.7331e-02,  3.9764e-02,\n",
      "        -1.9610e-02,  2.6965e-02, -3.7324e-02, -1.4980e-02, -5.7648e-03,\n",
      "         1.9586e-02,  4.0967e-02,  4.8622e-03, -1.8247e-02,  1.5212e-02,\n",
      "        -4.6147e-03,  4.0697e-02,  1.0786e-02,  2.1550e-02,  3.5413e-03,\n",
      "        -3.9770e-04, -3.1923e-02, -1.1531e-02, -1.9780e-02,  3.5465e-02,\n",
      "        -2.6661e-03, -2.9778e-03], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-2.0221e-02, -1.5443e-02, -1.1067e-02, -6.7299e-03, -3.2290e-03,\n",
      "        -9.4285e-03,  3.9024e-03,  5.3253e-03, -1.3418e-02,  3.8734e-03,\n",
      "        -2.1955e-03, -3.2806e-03,  4.2366e-03, -1.0011e-02, -1.5382e-02,\n",
      "         3.7390e-03,  2.4903e-03,  9.0422e-03, -1.0241e-02, -7.2130e-03,\n",
      "        -1.8413e-03, -5.1551e-04,  2.5944e-02,  5.9690e-03,  1.4962e-02,\n",
      "         5.5665e-03, -5.2322e-03, -4.2160e-03,  9.2485e-03, -7.0505e-03,\n",
      "        -1.6168e-02, -9.2055e-03, -4.8018e-03,  9.3106e-03, -3.3410e-03,\n",
      "        -4.6219e-03,  1.3442e-03,  6.4855e-03, -2.4887e-03, -8.2634e-03,\n",
      "         7.8709e-03,  6.1825e-03,  2.2986e-04,  1.4439e-02, -9.2132e-03,\n",
      "        -1.2920e-02, -2.0720e-02,  1.8619e-02, -2.7609e-04, -6.7497e-03,\n",
      "        -5.9725e-03, -1.5119e-02,  4.3725e-03,  4.8486e-03, -9.5309e-03,\n",
      "         1.1551e-02,  4.6005e-03,  1.8820e-02,  5.4998e-03,  2.8964e-03,\n",
      "         1.1075e-02,  1.3595e-02,  1.7993e-03,  4.8108e-04,  9.3334e-03,\n",
      "         8.8052e-03,  2.2988e-02, -4.0737e-03,  1.0414e-02,  4.7549e-03,\n",
      "        -1.6472e-02,  1.0100e-02,  2.1699e-02,  7.9911e-03,  1.8350e-02,\n",
      "        -1.0951e-02, -2.3698e-02,  7.9257e-03, -6.3371e-03,  7.8067e-03,\n",
      "        -5.2970e-03, -4.6286e-03,  2.0501e-03, -9.3617e-03, -1.0154e-03,\n",
      "        -7.4586e-04, -3.5410e-03,  2.0995e-04, -3.2812e-03,  1.2175e-02,\n",
      "        -9.9026e-03,  1.3485e-02, -1.1446e-02, -2.8854e-03, -1.7701e-02,\n",
      "         1.5719e-02,  3.2990e-03, -1.3348e-02, -6.0143e-04,  2.0470e-02,\n",
      "        -1.0323e-03, -6.0400e-04, -3.2258e-03, -8.5372e-03,  1.0699e-02,\n",
      "        -8.1038e-03, -1.9155e-02,  9.0245e-03, -7.1804e-03, -1.4071e-03,\n",
      "        -1.3753e-03, -5.2235e-03, -6.4499e-03, -1.2459e-02,  9.0927e-03,\n",
      "         1.1947e-02, -1.5587e-02, -9.3146e-03, -1.1944e-02, -1.9947e-03,\n",
      "         3.2928e-03,  6.1263e-03, -1.4101e-03,  9.2641e-03, -1.3759e-02,\n",
      "         8.7493e-03, -8.2511e-04, -1.1240e-02, -2.4067e-03, -9.8921e-04,\n",
      "        -1.3305e-02,  7.6470e-03, -1.8946e-02, -8.9732e-03,  2.0617e-03,\n",
      "        -1.2858e-02,  1.4309e-02, -7.4456e-04,  7.4312e-03, -9.3409e-03,\n",
      "         2.1954e-03,  1.1764e-02, -7.3566e-03, -2.1165e-02,  3.4042e-03,\n",
      "         1.8524e-02,  1.9201e-03, -3.4472e-03,  2.2878e-02,  1.0818e-02,\n",
      "        -2.0213e-02, -2.1524e-02,  5.5829e-03, -6.8657e-03, -2.9948e-03,\n",
      "         1.6219e-03,  9.2741e-03,  3.4935e-03,  1.9596e-02, -1.4735e-02,\n",
      "         1.2037e-02, -4.6203e-03, -9.1577e-04,  7.3585e-03, -4.7593e-03,\n",
      "        -1.0570e-03, -1.6571e-02, -5.4946e-03,  9.7867e-03,  6.3103e-05,\n",
      "        -1.7459e-02,  4.5035e-03,  1.6804e-03,  5.1181e-03,  2.3115e-02,\n",
      "        -1.2688e-02, -1.3796e-02,  1.3154e-02, -8.4817e-03, -1.3985e-02,\n",
      "         2.2562e-03,  3.3158e-03,  3.5766e-04,  8.5731e-03,  1.0255e-02,\n",
      "         1.2514e-03,  1.3798e-02,  7.1681e-03,  6.0160e-03,  3.4973e-03,\n",
      "        -6.2628e-03,  3.9698e-03, -4.6273e-03, -2.4213e-02, -2.2074e-02,\n",
      "         4.1371e-06, -9.3965e-03,  1.1453e-02, -3.3832e-03,  1.1468e-02,\n",
      "         7.2668e-04, -1.0374e-02,  7.8611e-03,  1.7425e-02, -3.8939e-03,\n",
      "        -9.4257e-03,  4.1101e-03,  6.5313e-03,  3.5426e-04,  5.0698e-03,\n",
      "        -1.0087e-03,  1.2717e-02, -1.8313e-02, -2.1952e-03,  3.4673e-03,\n",
      "        -3.9797e-03,  6.2009e-03, -4.1070e-03,  1.2204e-02, -4.6161e-03,\n",
      "         2.3399e-03, -1.3493e-02,  8.0261e-03, -9.9825e-04, -8.7082e-03,\n",
      "        -8.0937e-03, -8.0595e-03, -2.0786e-03, -1.0251e-02, -2.0793e-03,\n",
      "        -4.1338e-03, -1.3216e-02,  1.8807e-03,  3.7371e-03,  8.6834e-03,\n",
      "        -2.1340e-04, -8.3454e-03,  1.1595e-02,  2.8941e-03, -3.6828e-03,\n",
      "         4.3745e-03, -1.2025e-02, -3.3034e-03,  7.4361e-03, -4.6586e-03,\n",
      "         3.9165e-03, -1.5069e-02,  1.4285e-02,  1.3552e-02,  3.7158e-03,\n",
      "        -3.6225e-03, -4.2954e-03, -7.2036e-03, -4.7793e-03,  1.5958e-02,\n",
      "         1.0904e-02,  8.5473e-03,  2.4597e-05,  1.2385e-02,  3.0296e-03,\n",
      "        -9.1639e-03,  6.5088e-04,  7.5493e-03, -2.6197e-03,  1.7874e-02,\n",
      "         5.1108e-03, -7.4278e-03,  1.2475e-02, -2.7138e-03, -4.9963e-03,\n",
      "         9.2043e-04, -8.5525e-04, -6.2255e-04,  1.0764e-02, -1.2756e-02,\n",
      "        -3.8296e-03, -5.9802e-03,  6.8644e-03, -1.3275e-02, -6.9276e-03,\n",
      "         5.0140e-03,  7.1875e-03,  2.9646e-03,  9.6351e-03,  1.0048e-02,\n",
      "        -1.7387e-02,  1.0645e-02,  2.3233e-02, -1.5072e-03,  2.1866e-02,\n",
      "         3.0020e-03, -7.5262e-04, -2.6875e-03,  6.4317e-03,  5.2326e-03,\n",
      "        -1.5010e-02,  8.7420e-03, -9.9060e-03,  9.8042e-04, -1.4349e-02,\n",
      "         2.3889e-03,  7.2196e-03, -1.3012e-03, -8.4323e-03, -1.6121e-02,\n",
      "         2.7289e-03,  6.7309e-03, -6.7909e-03,  5.9634e-03, -1.0744e-03,\n",
      "         2.1648e-02, -1.3090e-02, -7.0152e-03,  8.3501e-03, -1.3402e-03,\n",
      "         4.9120e-03,  1.0837e-02,  3.8591e-03,  6.1830e-03,  9.3419e-03,\n",
      "         6.5256e-03, -1.1851e-02,  1.3084e-02, -4.7999e-03,  4.9178e-03,\n",
      "         3.5266e-03, -1.1406e-03, -4.6511e-03,  1.8914e-03, -1.1400e-02,\n",
      "        -9.3676e-03, -8.3322e-03, -3.1802e-03,  1.5577e-02,  3.7018e-03,\n",
      "        -1.0191e-02, -1.0111e-03,  7.2360e-03, -2.3810e-02,  1.8941e-03,\n",
      "        -6.6251e-03, -3.2443e-03,  1.9202e-03,  2.5286e-03, -2.7463e-03,\n",
      "        -5.0486e-03,  9.2984e-03,  1.7131e-02,  4.5021e-04,  1.5278e-02,\n",
      "        -5.0368e-03,  1.7010e-02, -5.0649e-03,  8.6363e-03, -2.7966e-03,\n",
      "         1.8346e-03,  1.0142e-02,  4.2552e-04, -6.7250e-03, -2.3005e-03,\n",
      "         1.0835e-02,  9.6930e-03,  4.8537e-03, -1.9275e-02,  4.7633e-03,\n",
      "        -5.0506e-03, -3.2068e-03, -4.0447e-03,  3.8290e-03, -1.7114e-02,\n",
      "         3.1861e-03,  1.0433e-02, -9.6331e-04, -2.0976e-03, -3.3417e-03,\n",
      "        -1.4736e-02,  5.4741e-03, -1.0656e-02, -4.4029e-03,  1.6500e-02,\n",
      "        -8.9848e-03,  7.2989e-03, -6.1650e-03,  3.7004e-03, -1.7930e-02,\n",
      "         6.8771e-03, -1.0739e-02, -1.2426e-02, -5.9488e-03, -1.2390e-02,\n",
      "         7.3798e-03, -1.9557e-02, -9.2788e-03, -1.5514e-02, -1.7329e-02,\n",
      "        -4.8589e-03,  9.5565e-03, -7.3317e-03,  3.5970e-03,  1.6400e-02,\n",
      "        -1.6438e-02, -1.4666e-02, -1.7038e-02, -7.2478e-03,  3.6787e-03,\n",
      "         2.4389e-03, -9.1780e-03, -7.6621e-03, -1.2731e-02,  1.5895e-02,\n",
      "         2.6759e-03, -5.7818e-03,  3.6672e-03, -2.0472e-02, -2.5387e-03,\n",
      "        -3.4188e-02, -1.5732e-03, -8.0483e-03, -1.3434e-02,  2.6899e-03,\n",
      "        -9.9945e-03, -1.7331e-02,  3.2122e-03, -1.0112e-03,  3.8498e-03,\n",
      "        -5.1704e-03, -2.4921e-02, -4.0812e-03,  2.7792e-02,  3.8101e-03,\n",
      "         1.3377e-03,  1.2218e-02, -2.9482e-03, -6.1499e-03, -4.1026e-03,\n",
      "         7.8687e-03,  5.5799e-03, -3.1346e-03, -7.5734e-03,  6.2617e-04,\n",
      "         1.2032e-02, -9.0185e-03, -1.5938e-02,  1.8569e-02,  5.6682e-03,\n",
      "         1.7109e-02, -1.3620e-02, -1.5186e-02,  1.6599e-02,  1.1195e-02,\n",
      "         6.0911e-03, -1.8380e-02,  1.0888e-02,  3.1081e-04, -1.0002e-03,\n",
      "         5.9494e-03, -3.5180e-03, -3.2480e-04,  4.2840e-03,  1.9040e-02,\n",
      "        -3.7251e-03, -3.1611e-03,  1.2340e-03, -1.5819e-03,  1.1294e-02,\n",
      "         4.7810e-03, -1.9438e-02, -8.0156e-03, -5.7000e-05,  7.6238e-04,\n",
      "        -6.8110e-03,  1.9277e-03,  4.2956e-03,  1.3087e-02,  6.5811e-03,\n",
      "         1.2668e-02, -3.9501e-03, -1.0472e-02,  7.1707e-03,  2.7544e-04,\n",
      "        -3.9023e-03, -4.6462e-03,  9.6177e-03,  1.0167e-02,  1.7787e-02,\n",
      "        -1.6450e-02, -1.8754e-02,  2.9733e-03,  6.9522e-03,  1.9290e-03,\n",
      "        -1.7551e-02,  4.4997e-03, -1.4541e-02, -1.2748e-02, -8.3229e-03,\n",
      "         1.2076e-02, -3.1203e-03,  2.1195e-02,  9.3740e-04, -3.2410e-03,\n",
      "         6.0572e-03,  2.7351e-02,  2.5156e-03,  2.6827e-02,  5.4804e-03,\n",
      "        -3.1236e-04, -1.0360e-02,  2.1279e-03,  2.2526e-03,  3.6234e-03,\n",
      "        -5.8492e-03,  2.1543e-02])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([ 0.0001, -0.0421, -0.0430,  0.0306, -0.0377, -0.0154, -0.0312,  0.0028,\n",
      "        -0.0517, -0.0263,  0.0334,  0.0064,  0.0396, -0.0031, -0.0310, -0.0217,\n",
      "        -0.0159, -0.0040, -0.0633,  0.0210,  0.0358, -0.0332,  0.0738,  0.0334,\n",
      "         0.0079, -0.0174,  0.0015, -0.0032,  0.0115,  0.0079, -0.0200, -0.0346,\n",
      "        -0.0132,  0.0355, -0.0507, -0.0193, -0.0289, -0.0160, -0.0021, -0.0525,\n",
      "        -0.0082,  0.0328,  0.0178,  0.0133, -0.0540, -0.0342, -0.0457,  0.0705,\n",
      "        -0.0443, -0.0284,  0.0142, -0.0484,  0.0231, -0.0209, -0.0231,  0.0128,\n",
      "         0.0370, -0.0024, -0.0069, -0.0154,  0.0627,  0.0480,  0.0416, -0.0431,\n",
      "        -0.0056,  0.0542,  0.0033, -0.0392, -0.0119,  0.0462,  0.0085, -0.0167,\n",
      "         0.0518,  0.0007,  0.0706, -0.0485, -0.0739,  0.0494, -0.0299, -0.0183,\n",
      "        -0.0467,  0.0270, -0.0378,  0.0017,  0.0242,  0.0249,  0.0201,  0.0399,\n",
      "         0.0064,  0.0044, -0.0051,  0.0325, -0.0059, -0.0236, -0.0723,  0.0328,\n",
      "         0.0069,  0.0086, -0.0222,  0.0494, -0.0315, -0.0061,  0.0241, -0.0122,\n",
      "         0.0611,  0.0112, -0.0512, -0.0241, -0.0009, -0.0382,  0.0221, -0.0516,\n",
      "        -0.0362,  0.0125,  0.0587,  0.0460, -0.0357, -0.0609, -0.0077,  0.0398,\n",
      "         0.0076,  0.0401, -0.0133,  0.0608, -0.0223,  0.0431, -0.0117, -0.0395,\n",
      "         0.0150,  0.0274, -0.0109,  0.0414, -0.0654, -0.0087, -0.0213, -0.0373,\n",
      "        -0.0018, -0.0273,  0.0036, -0.0188, -0.0165,  0.0316,  0.0228, -0.0596,\n",
      "        -0.0332,  0.0315,  0.0471,  0.0115,  0.0701,  0.0174, -0.0522, -0.0810,\n",
      "         0.0240, -0.0113, -0.0001,  0.0339,  0.0276,  0.0387,  0.0447, -0.0258,\n",
      "         0.0440,  0.0341,  0.0334, -0.0025, -0.0099,  0.0084, -0.0483,  0.0077,\n",
      "         0.0421, -0.0084, -0.0144, -0.0107, -0.0007,  0.0223,  0.0171, -0.0066,\n",
      "        -0.0510,  0.0112, -0.0455, -0.0698,  0.0372, -0.0069,  0.0175,  0.0563,\n",
      "         0.0615, -0.0137,  0.0606, -0.0275, -0.0235,  0.0209, -0.0210,  0.0285,\n",
      "        -0.0237, -0.0510, -0.0537, -0.0242, -0.0228,  0.0656, -0.0480,  0.0094,\n",
      "         0.0304,  0.0211,  0.0278,  0.0373,  0.0315, -0.0540,  0.0325, -0.0094,\n",
      "         0.0447,  0.0087, -0.0427, -0.0161, -0.0262, -0.0439, -0.0345, -0.0122,\n",
      "         0.0009, -0.0255, -0.0034, -0.0474, -0.0226, -0.0603,  0.0051,  0.0110,\n",
      "         0.0024, -0.0519, -0.0195, -0.0453, -0.0272,  0.0246, -0.0151, -0.0334,\n",
      "         0.0063, -0.0349,  0.0546,  0.0074,  0.0179,  0.0030, -0.0022,  0.0083,\n",
      "        -0.0029, -0.0362,  0.0136, -0.0055, -0.0169,  0.0289, -0.0624, -0.0132,\n",
      "         0.0334, -0.0299, -0.0347,  0.0041, -0.0140, -0.0232,  0.0094,  0.0223,\n",
      "         0.0593,  0.0074,  0.0099,  0.0229, -0.0207, -0.0145,  0.0373,  0.0139,\n",
      "         0.0131,  0.0538, -0.0072,  0.0411, -0.0329, -0.0177, -0.0346,  0.0142,\n",
      "        -0.0088,  0.0403, -0.0386, -0.0292,  0.0264,  0.0167,  0.0175, -0.0401,\n",
      "         0.0395,  0.0142, -0.0248,  0.0611,  0.0370, -0.0569,  0.0106,  0.0824,\n",
      "         0.0010,  0.0327, -0.0071,  0.0377, -0.0084,  0.0290, -0.0257,  0.0124,\n",
      "        -0.0162, -0.0103,  0.0323, -0.0269, -0.0326, -0.0297, -0.0338, -0.0559,\n",
      "        -0.0141, -0.0160, -0.0079, -0.0405,  0.0289, -0.0189,  0.0321, -0.0120,\n",
      "        -0.0254,  0.0081,  0.0106,  0.0154, -0.0100, -0.0269,  0.0433,  0.0617,\n",
      "         0.0267,  0.0120,  0.0629, -0.0310, -0.0106, -0.0336, -0.0396, -0.0147,\n",
      "        -0.0300, -0.0115,  0.0229, -0.0362, -0.0483, -0.0066, -0.0260, -0.0085,\n",
      "         0.0281,  0.0109, -0.0705, -0.0368,  0.0228,  0.0238, -0.0162,  0.0147,\n",
      "         0.0367,  0.0034,  0.0583,  0.0223,  0.0350,  0.0646, -0.0060,  0.0036,\n",
      "        -0.0272,  0.0499, -0.0409,  0.0311,  0.0167, -0.0326,  0.0017, -0.0038,\n",
      "         0.0493, -0.0038, -0.0181, -0.0181,  0.0405,  0.0268, -0.0228, -0.0257,\n",
      "         0.0068, -0.0012, -0.0128,  0.0166, -0.0022, -0.0038, -0.0193,  0.0064,\n",
      "        -0.0093, -0.0367, -0.0053,  0.0539, -0.0156,  0.0516, -0.0240, -0.0341,\n",
      "        -0.0686,  0.0501,  0.0069, -0.0238, -0.0457, -0.0382,  0.0074, -0.0588,\n",
      "         0.0244,  0.0080, -0.0128, -0.0244,  0.0012, -0.0284,  0.0053,  0.0574,\n",
      "        -0.0023, -0.0662, -0.0558,  0.0197,  0.0346,  0.0043, -0.0275, -0.0534,\n",
      "        -0.0286,  0.0287,  0.0176, -0.0475,  0.0332, -0.0071, -0.0492, -0.0967,\n",
      "         0.0205, -0.0041, -0.0201, -0.0287, -0.0210, -0.0548,  0.0327, -0.0084,\n",
      "        -0.0263, -0.0343, -0.0601, -0.0270,  0.0897, -0.0076,  0.0144,  0.0083,\n",
      "         0.0028,  0.0301, -0.0481,  0.0092,  0.0526,  0.0197,  0.0250,  0.0123,\n",
      "         0.0654,  0.0113, -0.0137,  0.0283,  0.0025,  0.0564, -0.0295, -0.0510,\n",
      "         0.0720,  0.0028, -0.0132, -0.0007,  0.0567, -0.0273,  0.0390,  0.0493,\n",
      "        -0.0399, -0.0294, -0.0306,  0.0034, -0.0403, -0.0188, -0.0416,  0.0155,\n",
      "        -0.0214, -0.0043, -0.0357, -0.0560,  0.0424,  0.0357,  0.0208,  0.0233,\n",
      "        -0.0290,  0.0666, -0.0265,  0.0690,  0.0054, -0.0498,  0.0402,  0.0275,\n",
      "        -0.0275,  0.0213,  0.0621, -0.0145,  0.0161, -0.0058, -0.0606, -0.0044,\n",
      "         0.0243,  0.0417, -0.0372,  0.0315, -0.0519, -0.0277, -0.0141,  0.0317,\n",
      "         0.0378,  0.0261, -0.0173,  0.0120,  0.0014,  0.0680,  0.0133,  0.0484,\n",
      "         0.0090, -0.0007, -0.0423, -0.0094, -0.0175,  0.0391, -0.0085,  0.0186],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0100,  0.0363,  0.0129,  ..., -0.0276, -0.0242,  0.0436],\n",
      "        [ 0.0366, -0.0021,  0.0299,  ..., -0.0325, -0.0277,  0.0415],\n",
      "        [ 0.0155, -0.0415,  0.0163,  ...,  0.0157, -0.0265,  0.0050],\n",
      "        ...,\n",
      "        [ 0.0279, -0.0232,  0.0204,  ..., -0.0251, -0.0045, -0.0340],\n",
      "        [-0.0490,  0.0524, -0.0157,  ...,  0.0544,  0.0354,  0.0334],\n",
      "        [-0.0078,  0.0279,  0.0335,  ...,  0.0225,  0.0306, -0.0153]],\n",
      "       requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([[-0.0034,  0.0020,  0.0106,  ...,  0.0112, -0.0031,  0.0087],\n",
      "        [ 0.0054,  0.0041,  0.0039,  ...,  0.0057, -0.0140,  0.0149],\n",
      "        [-0.0127, -0.0127, -0.0140,  ...,  0.0054,  0.0031, -0.0216],\n",
      "        ...,\n",
      "        [ 0.0178, -0.0041,  0.0050,  ...,  0.0100,  0.0024, -0.0344],\n",
      "        [-0.0076,  0.0121, -0.0014,  ...,  0.0179,  0.0042, -0.0100],\n",
      "        [ 0.0210,  0.0056, -0.0072,  ...,  0.0076, -0.0025, -0.0033]])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([[-0.0133,  0.0383,  0.0234,  ..., -0.0164, -0.0273,  0.0522],\n",
      "        [ 0.0420,  0.0021,  0.0338,  ..., -0.0268, -0.0417,  0.0564],\n",
      "        [ 0.0028, -0.0542,  0.0023,  ...,  0.0211, -0.0234, -0.0166],\n",
      "        ...,\n",
      "        [ 0.0457, -0.0273,  0.0254,  ..., -0.0151, -0.0021, -0.0684],\n",
      "        [-0.0566,  0.0646, -0.0171,  ...,  0.0722,  0.0396,  0.0234],\n",
      "        [ 0.0132,  0.0334,  0.0263,  ...,  0.0302,  0.0281, -0.0187]],\n",
      "       requires_grad=True)\n",
      "Starting weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0401,  0.0335,  0.0272, -0.0431,  0.0337,  0.0024, -0.0322, -0.0318,\n",
      "        -0.0013, -0.0178, -0.0308,  0.0415,  0.0221, -0.0133,  0.0043, -0.0139,\n",
      "        -0.0204,  0.0386,  0.0277,  0.0243], requires_grad=True)\n",
      "Noise vector:\n",
      "tensor([-0.0207, -0.0034,  0.0102, -0.0154,  0.0081,  0.0051,  0.0036, -0.0078,\n",
      "        -0.0100,  0.0108, -0.0109,  0.0037, -0.0083, -0.0080, -0.0051, -0.0160,\n",
      "         0.0048,  0.0173, -0.0060, -0.0037])\n",
      "New weights:\n",
      "Parameter containing:\n",
      "tensor([-0.0608,  0.0301,  0.0375, -0.0585,  0.0418,  0.0075, -0.0286, -0.0396,\n",
      "        -0.0112, -0.0071, -0.0417,  0.0453,  0.0138, -0.0213, -0.0008, -0.0300,\n",
      "        -0.0157,  0.0559,  0.0217,  0.0206], requires_grad=True)\n",
      "\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "aaa\n",
      "Parameter containing:\n",
      "tensor([[-0.0144,  0.0671, -0.0041,  ...,  0.0126,  0.0108, -0.0221],\n",
      "        [ 0.0081, -0.0023, -0.0376,  ...,  0.0300,  0.0188, -0.0040],\n",
      "        [-0.0034, -0.0020, -0.0060,  ..., -0.0123,  0.0140, -0.0355],\n",
      "        ...,\n",
      "        [-0.0018,  0.0294,  0.0105,  ...,  0.0089,  0.0092, -0.0123],\n",
      "        [ 0.0271, -0.0137,  0.0257,  ..., -0.0255, -0.0309, -0.0055],\n",
      "        [ 0.0357,  0.0097,  0.0154,  ..., -0.0291,  0.0312,  0.0038]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0299,  0.0122,  0.0311, -0.0080,  0.0185, -0.0369,  0.0319,  0.0202,\n",
      "         0.0183, -0.0097,  0.0319,  0.0134,  0.0299,  0.0136,  0.0083, -0.0174,\n",
      "         0.0331,  0.0146, -0.0366,  0.0307, -0.0044, -0.0247,  0.0249, -0.0407,\n",
      "         0.0171,  0.0424,  0.0262,  0.0329,  0.0174, -0.0358,  0.0100,  0.0004,\n",
      "         0.0012, -0.0030,  0.0096, -0.0203, -0.0343, -0.0101, -0.0292,  0.0030,\n",
      "         0.0357,  0.0249, -0.0434,  0.0133, -0.0329, -0.0303, -0.0258, -0.0025,\n",
      "         0.0026,  0.0045,  0.0317, -0.0433,  0.0085,  0.0158, -0.0233, -0.0102,\n",
      "        -0.0049,  0.0111,  0.0215, -0.0147,  0.0142, -0.0023,  0.0033, -0.0245,\n",
      "        -0.0084, -0.0462, -0.0042, -0.0377,  0.0083, -0.0436,  0.0285, -0.0430,\n",
      "         0.0318, -0.0270,  0.0130,  0.0105,  0.0262, -0.0153,  0.0455,  0.0070,\n",
      "         0.0508, -0.0301,  0.0265, -0.0155,  0.0192,  0.0330, -0.0167,  0.0091,\n",
      "        -0.0065,  0.0341,  0.0060,  0.0214, -0.0297,  0.0127, -0.0071, -0.0159,\n",
      "        -0.0016, -0.0329,  0.0385, -0.0288, -0.0177, -0.0013, -0.0566,  0.0094,\n",
      "        -0.0236,  0.0165, -0.0300, -0.0217, -0.0124, -0.0207,  0.0085, -0.0175,\n",
      "         0.0257, -0.0190,  0.0372, -0.0479,  0.0061,  0.0271,  0.0013,  0.0398,\n",
      "        -0.0037,  0.0052,  0.0091,  0.0306, -0.0201, -0.0412,  0.0374,  0.0170,\n",
      "        -0.0232,  0.0011, -0.0305, -0.0343,  0.0214,  0.0394,  0.0044,  0.0068,\n",
      "         0.0351,  0.0173, -0.0157,  0.0251, -0.0183, -0.0264, -0.0035, -0.0243,\n",
      "        -0.0442,  0.0254, -0.0021, -0.0206, -0.0111, -0.0214, -0.0231, -0.0127,\n",
      "        -0.0182,  0.0178, -0.0291,  0.0179,  0.0367,  0.0287,  0.0321,  0.0105,\n",
      "        -0.0286, -0.0098,  0.0517, -0.0293, -0.0185, -0.0319,  0.0189,  0.0512,\n",
      "        -0.0080, -0.0407,  0.0078, -0.0125, -0.0065, -0.0387, -0.0200, -0.0081,\n",
      "        -0.0418,  0.0260,  0.0223, -0.0201,  0.0083, -0.0378, -0.0325, -0.0134,\n",
      "         0.0223, -0.0127,  0.0324, -0.0166, -0.0220,  0.0033, -0.0241, -0.0302,\n",
      "         0.0475, -0.0401,  0.0284, -0.0095, -0.0174, -0.0123, -0.0109,  0.0295,\n",
      "        -0.0025,  0.0236, -0.0210,  0.0540,  0.0431, -0.0239, -0.0341, -0.0261,\n",
      "         0.0487, -0.0293, -0.0406,  0.0412, -0.0361,  0.0341,  0.0177, -0.0094,\n",
      "         0.0071,  0.0368, -0.0191, -0.0267, -0.0204, -0.0280,  0.0040,  0.0370,\n",
      "        -0.0196, -0.0431,  0.0149,  0.0186,  0.0147, -0.0223,  0.0210,  0.0002,\n",
      "        -0.0215,  0.0285,  0.0178, -0.0254,  0.0390,  0.0430, -0.0383, -0.0567,\n",
      "         0.0418, -0.0386,  0.0254,  0.0462,  0.0145, -0.0016, -0.0421, -0.0057,\n",
      "         0.0077, -0.0095, -0.0075,  0.0211, -0.0190,  0.0012,  0.0296,  0.0370,\n",
      "         0.0294, -0.0362,  0.0202, -0.0357,  0.0225,  0.0201, -0.0330, -0.0128,\n",
      "        -0.0146,  0.0031,  0.0338, -0.0068,  0.0486, -0.0526, -0.0115, -0.0050,\n",
      "        -0.0089,  0.0234, -0.0117,  0.0232, -0.0260,  0.0395, -0.0268,  0.0229,\n",
      "        -0.0224, -0.0143, -0.0023,  0.0400,  0.0150,  0.0107,  0.0121, -0.0104,\n",
      "         0.0063, -0.0318,  0.0341, -0.0471,  0.0059,  0.0269, -0.0303,  0.0003,\n",
      "         0.0092,  0.0356, -0.0303, -0.0097,  0.0116, -0.0424,  0.0180, -0.0136,\n",
      "         0.0294, -0.0317, -0.0337, -0.0466, -0.0230, -0.0217,  0.0280,  0.0149,\n",
      "         0.0169, -0.0086,  0.0369,  0.0123,  0.0224, -0.0327,  0.0051,  0.0344,\n",
      "        -0.0270,  0.0201,  0.0250, -0.0205,  0.0085,  0.0254, -0.0101, -0.0135,\n",
      "         0.0105, -0.0039,  0.0024,  0.0006,  0.0020,  0.0149, -0.0194,  0.0367,\n",
      "        -0.0122, -0.0290,  0.0295, -0.0117,  0.0237,  0.0203, -0.0032,  0.0263,\n",
      "        -0.0203,  0.0316, -0.0146,  0.0006,  0.0118, -0.0301,  0.0193,  0.0224,\n",
      "         0.0107,  0.0109,  0.0185, -0.0127,  0.0242,  0.0105, -0.0217, -0.0110,\n",
      "         0.0132, -0.0032, -0.0016,  0.0308,  0.0067,  0.0314,  0.0152, -0.0014,\n",
      "         0.0299,  0.0208, -0.0180,  0.0450,  0.0400,  0.0033, -0.0079,  0.0169,\n",
      "        -0.0253, -0.0263, -0.0142,  0.0162,  0.0045, -0.0264, -0.0135,  0.0306,\n",
      "         0.0130, -0.0116,  0.0319,  0.0291, -0.0036,  0.0103, -0.0184, -0.0412,\n",
      "         0.0357, -0.0175,  0.0090, -0.0099, -0.0277,  0.0307,  0.0217, -0.0271,\n",
      "        -0.0181,  0.0183, -0.0422,  0.0340, -0.0014,  0.0275, -0.0181,  0.0034,\n",
      "        -0.0309, -0.0106, -0.0150, -0.0262,  0.0104,  0.0247, -0.0398,  0.0194,\n",
      "         0.0382, -0.0188,  0.0043, -0.0220, -0.0203,  0.0037,  0.0305, -0.0162,\n",
      "         0.0119, -0.0092, -0.0008,  0.0092, -0.0269, -0.0105,  0.0344, -0.0034,\n",
      "        -0.0054,  0.0023, -0.0262,  0.0048,  0.0335, -0.0044, -0.0430, -0.0069,\n",
      "        -0.0306, -0.0131, -0.0357, -0.0469,  0.0145,  0.0304, -0.0481, -0.0405,\n",
      "        -0.0099,  0.0056, -0.0303,  0.0007, -0.0216, -0.0268, -0.0211, -0.0356,\n",
      "         0.0169, -0.0030,  0.0043,  0.0158,  0.0356,  0.0296,  0.0008, -0.0475,\n",
      "         0.0314, -0.0141,  0.0378, -0.0166, -0.0333,  0.0134, -0.0072,  0.0052,\n",
      "        -0.0353, -0.0039, -0.0307,  0.0083, -0.0077,  0.0038, -0.0179, -0.0287,\n",
      "        -0.0417, -0.0295, -0.0314,  0.0204, -0.0370,  0.0332,  0.0120, -0.0394,\n",
      "        -0.0360, -0.0242,  0.0141, -0.0249, -0.0122, -0.0053,  0.0103, -0.0054,\n",
      "         0.0002,  0.0265, -0.0028,  0.0264,  0.0287, -0.0193, -0.0251,  0.0083,\n",
      "        -0.0117,  0.0139, -0.0375, -0.0297,  0.0268, -0.0114, -0.0068, -0.0009],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0149, -0.0344,  0.0119,  ...,  0.0507, -0.0243,  0.0286],\n",
      "        [ 0.0575,  0.0413, -0.0082,  ...,  0.0361,  0.0137, -0.0049],\n",
      "        [-0.0255, -0.0277, -0.0216,  ..., -0.0341, -0.0405,  0.0144],\n",
      "        ...,\n",
      "        [ 0.0215, -0.0304,  0.0109,  ..., -0.0269,  0.0376, -0.0146],\n",
      "        [ 0.0061, -0.0171, -0.0338,  ..., -0.0371, -0.0140, -0.0049],\n",
      "        [ 0.0156,  0.0040, -0.0012,  ..., -0.0151,  0.0580, -0.0220]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.0348e-02, -2.6663e-02, -3.1895e-02,  3.7376e-02, -3.4446e-02,\n",
      "        -5.9723e-03, -3.5141e-02, -2.5347e-03, -3.8255e-02, -3.0165e-02,\n",
      "         3.5576e-02,  9.6801e-03,  3.5386e-02,  6.9590e-03, -1.5661e-02,\n",
      "        -2.5415e-02, -1.8419e-02, -1.3039e-02, -5.3021e-02,  2.8183e-02,\n",
      "         3.7596e-02, -3.2713e-02,  4.7846e-02,  2.7442e-02, -7.0301e-03,\n",
      "        -2.2950e-02,  6.6884e-03,  1.0124e-03,  2.2447e-03,  1.4987e-02,\n",
      "        -3.8746e-03, -2.5397e-02, -8.3769e-03,  2.6158e-02, -4.7408e-02,\n",
      "        -1.4642e-02, -3.0259e-02, -2.2526e-02,  4.2165e-04, -4.4274e-02,\n",
      "        -1.6075e-02,  2.6593e-02,  1.7548e-02, -1.1736e-03, -4.4761e-02,\n",
      "        -2.1294e-02, -2.4950e-02,  5.1891e-02, -4.3974e-02, -2.1677e-02,\n",
      "         2.0178e-02, -3.3285e-02,  1.8760e-02, -2.5740e-02, -1.3547e-02,\n",
      "         1.2552e-03,  3.2396e-02, -2.1252e-02, -1.2363e-02, -1.8300e-02,\n",
      "         5.1614e-02,  3.4403e-02,  3.9781e-02, -4.3549e-02, -1.4909e-02,\n",
      "         4.5354e-02, -1.9660e-02, -3.5173e-02, -2.2278e-02,  4.1488e-02,\n",
      "         2.5021e-02, -2.6783e-02,  3.0074e-02, -7.2523e-03,  5.2261e-02,\n",
      "        -3.7557e-02, -5.0158e-02,  4.1460e-02, -2.3563e-02, -2.6088e-02,\n",
      "        -4.1420e-02,  3.1657e-02, -3.9854e-02,  1.1082e-02,  2.5261e-02,\n",
      "         2.5637e-02,  2.3612e-02,  3.9667e-02,  9.6689e-03, -7.7987e-03,\n",
      "         4.7912e-03,  1.8973e-02,  5.5099e-03, -2.0703e-02, -5.4619e-02,\n",
      "         1.7047e-02,  3.5820e-03,  2.1917e-02, -2.1623e-02,  2.8935e-02,\n",
      "        -3.0503e-02, -5.5046e-03,  2.7293e-02, -3.6502e-03,  5.0433e-02,\n",
      "         1.9268e-02, -3.2032e-02, -3.3143e-02,  6.2668e-03, -3.6751e-02,\n",
      "         2.3512e-02, -4.6419e-02, -2.9763e-02,  2.4991e-02,  4.9604e-02,\n",
      "         3.4065e-02, -2.0090e-02, -5.1577e-02,  4.1995e-03,  4.1785e-02,\n",
      "         4.2762e-03,  3.3979e-02, -1.1886e-02,  5.1555e-02, -8.5587e-03,\n",
      "         3.4332e-02, -1.0906e-02, -2.8272e-02,  1.7439e-02,  2.8360e-02,\n",
      "         2.4275e-03,  3.3794e-02, -4.6448e-02,  2.3662e-04, -2.3340e-02,\n",
      "        -2.4433e-02, -1.6082e-02, -2.6543e-02, -3.7940e-03, -9.4589e-03,\n",
      "        -1.8724e-02,  1.9845e-02,  3.0154e-02, -3.8463e-02, -3.6626e-02,\n",
      "         1.2958e-02,  4.5205e-02,  1.4945e-02,  4.7196e-02,  6.6299e-03,\n",
      "        -3.1975e-02, -5.9518e-02,  1.8441e-02, -4.4073e-03,  2.8755e-03,\n",
      "         3.2327e-02,  1.8351e-02,  3.5253e-02,  2.5054e-02, -1.1036e-02,\n",
      "         3.1967e-02,  3.8730e-02,  3.4316e-02, -9.8696e-03, -5.1872e-03,\n",
      "         9.4531e-03, -3.1713e-02,  1.3222e-02,  3.2280e-02, -8.4235e-03,\n",
      "         3.0690e-03, -1.5230e-02, -2.3737e-03,  1.7227e-02, -5.9911e-03,\n",
      "         6.1293e-03, -3.7200e-02, -1.9936e-03, -3.6997e-02, -5.5810e-02,\n",
      "         3.4901e-02, -1.0248e-02,  1.7128e-02,  4.7741e-02,  5.1222e-02,\n",
      "        -1.4954e-02,  4.6814e-02, -3.4631e-02, -2.9544e-02,  1.7431e-02,\n",
      "        -1.4765e-02,  2.4494e-02, -1.9086e-02, -2.6767e-02, -3.1604e-02,\n",
      "        -2.4219e-02, -1.3354e-02,  5.4151e-02, -4.4603e-02, -2.1152e-03,\n",
      "         2.9627e-02,  3.1435e-02,  1.9914e-02,  1.9916e-02,  3.5411e-02,\n",
      "        -4.4583e-02,  2.8359e-02, -1.5971e-02,  4.4313e-02,  3.5986e-03,\n",
      "        -4.1740e-02, -2.8862e-02, -7.8721e-03, -4.1718e-02, -3.7926e-02,\n",
      "        -8.1768e-03, -5.2913e-03, -2.1398e-02, -1.5600e-02, -4.2829e-02,\n",
      "        -2.4961e-02, -4.6792e-02, -2.9285e-03,  1.1986e-02,  1.1083e-02,\n",
      "        -4.3765e-02, -1.1404e-02, -4.3183e-02, -1.6963e-02,  2.6692e-02,\n",
      "        -1.0964e-02, -2.0189e-02,  4.4670e-03, -3.8611e-02,  4.5891e-02,\n",
      "         7.6461e-03,  2.6207e-02, -8.6275e-03, -5.1422e-03,  1.2030e-02,\n",
      "        -7.2366e-03, -2.4184e-02,  1.6918e-02, -1.2971e-02, -1.2225e-02,\n",
      "         2.4943e-02, -4.7370e-02, -2.7458e-02,  1.9832e-02, -3.3656e-02,\n",
      "        -3.1124e-02,  8.3799e-03, -6.8225e-03, -1.8381e-02, -6.5375e-03,\n",
      "         1.1394e-02,  5.0792e-02,  7.3777e-03, -2.4633e-03,  1.9847e-02,\n",
      "        -1.1529e-02, -1.5164e-02,  2.9769e-02,  1.6535e-02, -4.8081e-03,\n",
      "         4.8685e-02,  1.7938e-04,  2.8611e-02, -3.0219e-02, -1.2663e-02,\n",
      "        -3.5479e-02,  1.5101e-02, -8.1936e-03,  2.9560e-02, -2.5838e-02,\n",
      "        -2.5342e-02,  3.2332e-02,  9.8762e-03,  3.0770e-02, -3.3200e-02,\n",
      "         3.4459e-02,  7.0187e-03, -2.7782e-02,  5.1447e-02,  2.6982e-02,\n",
      "        -3.9487e-02, -8.3303e-05,  5.9206e-02,  2.5106e-03,  1.0794e-02,\n",
      "        -1.0099e-02,  3.8449e-02, -5.7381e-03,  2.2579e-02, -3.0949e-02,\n",
      "         2.7362e-02, -2.4894e-02, -3.9029e-04,  3.1321e-02, -1.2562e-02,\n",
      "        -3.5038e-02, -3.6958e-02, -3.2534e-02, -4.7496e-02,  2.0259e-03,\n",
      "        -1.8700e-02, -1.4582e-02, -3.3718e-02,  2.2913e-02, -1.7850e-02,\n",
      "         1.0407e-02,  1.0680e-03, -1.8401e-02, -2.4961e-04,  1.1951e-02,\n",
      "         1.0448e-02, -2.0883e-02, -3.0712e-02,  3.7084e-02,  5.2386e-02,\n",
      "         2.0165e-02,  2.3854e-02,  4.9803e-02, -2.6233e-02, -1.5505e-02,\n",
      "        -3.7098e-02, -3.8474e-02, -1.0020e-02, -3.1857e-02, -6.2217e-05,\n",
      "         3.2296e-02, -2.7847e-02, -4.5164e-02, -2.2130e-02, -2.9712e-02,\n",
      "         1.6858e-03,  2.9080e-02,  3.6771e-03, -4.6690e-02, -3.8668e-02,\n",
      "         2.9443e-02,  2.7053e-02, -1.8116e-02,  1.2174e-02,  3.9448e-02,\n",
      "         8.4040e-03,  4.9031e-02,  5.1198e-03,  3.4535e-02,  4.9279e-02,\n",
      "        -9.7689e-04, -1.3395e-02, -2.2088e-02,  4.1235e-02, -3.8128e-02,\n",
      "         2.9229e-02,  6.5279e-03, -3.3033e-02,  8.4334e-03, -1.5025e-03,\n",
      "         3.8454e-02, -1.3467e-02, -2.2931e-02,  1.1378e-03,  3.5697e-02,\n",
      "         3.1897e-02, -1.9575e-02, -2.1676e-02,  3.0178e-03,  1.5884e-02,\n",
      "        -1.5955e-02,  6.1972e-03, -1.2524e-03, -1.7187e-03, -1.5960e-02,\n",
      "         2.1166e-02, -1.4812e-02, -2.6022e-02, -8.9849e-04,  3.7402e-02,\n",
      "        -6.6121e-03,  4.4340e-02, -1.7883e-02, -3.7830e-02, -5.0651e-02,\n",
      "         4.3197e-02,  1.7649e-02, -1.1328e-02, -3.9779e-02, -2.5859e-02,\n",
      "        -2.9710e-05, -3.9285e-02,  3.3716e-02,  2.3479e-02,  4.4924e-03,\n",
      "        -1.9504e-02, -8.3902e-03, -2.1083e-02,  1.6586e-03,  4.1018e-02,\n",
      "         1.4096e-02, -5.1485e-02, -3.8811e-02,  2.6958e-02,  3.0942e-02,\n",
      "         1.8309e-03, -1.8318e-02, -4.5760e-02, -1.5863e-02,  1.2816e-02,\n",
      "         1.4890e-02, -4.1739e-02,  2.9548e-02,  1.3384e-02, -4.6698e-02,\n",
      "        -6.2560e-02,  2.2064e-02,  3.9830e-03, -6.7132e-03, -3.1357e-02,\n",
      "        -1.1012e-02, -3.7421e-02,  2.9482e-02, -7.3862e-03, -3.0123e-02,\n",
      "        -2.9117e-02, -3.5185e-02, -2.2926e-02,  6.1868e-02, -1.1454e-02,\n",
      "         1.3072e-02, -3.9587e-03,  5.7113e-03,  3.6249e-02, -4.4004e-02,\n",
      "         1.2857e-03,  4.7065e-02,  2.2793e-02,  3.2580e-02,  1.1645e-02,\n",
      "         5.3351e-02,  2.0280e-02,  2.1984e-03,  9.7114e-03, -3.1957e-03,\n",
      "         3.9327e-02, -1.5907e-02, -3.5848e-02,  5.5362e-02, -8.3930e-03,\n",
      "        -1.9321e-02,  1.7670e-02,  4.5802e-02, -2.7567e-02,  4.0050e-02,\n",
      "         4.3328e-02, -3.6397e-02, -2.9080e-02, -3.4877e-02, -1.5618e-02,\n",
      "        -3.6532e-02, -1.5593e-02, -4.2868e-02,  1.7080e-02, -3.2694e-02,\n",
      "        -9.0473e-03, -1.6264e-02, -4.8009e-02,  4.2500e-02,  3.4953e-02,\n",
      "         2.7594e-02,  2.1379e-02, -3.3268e-02,  5.3511e-02, -3.3062e-02,\n",
      "         5.6337e-02,  9.3126e-03, -3.9307e-02,  3.3023e-02,  2.7216e-02,\n",
      "        -2.3645e-02,  2.5964e-02,  5.2485e-02, -2.4661e-02, -1.6577e-03,\n",
      "         1.0637e-02, -4.1838e-02, -7.4187e-03,  1.7331e-02,  3.9764e-02,\n",
      "        -1.9610e-02,  2.6965e-02, -3.7324e-02, -1.4980e-02, -5.7648e-03,\n",
      "         1.9586e-02,  4.0967e-02,  4.8622e-03, -1.8247e-02,  1.5212e-02,\n",
      "        -4.6147e-03,  4.0697e-02,  1.0786e-02,  2.1550e-02,  3.5413e-03,\n",
      "        -3.9770e-04, -3.1923e-02, -1.1531e-02, -1.9780e-02,  3.5465e-02,\n",
      "        -2.6661e-03, -2.9778e-03], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0100,  0.0363,  0.0129,  ..., -0.0276, -0.0242,  0.0436],\n",
      "        [ 0.0366, -0.0021,  0.0299,  ..., -0.0325, -0.0277,  0.0415],\n",
      "        [ 0.0155, -0.0415,  0.0163,  ...,  0.0157, -0.0265,  0.0050],\n",
      "        ...,\n",
      "        [ 0.0279, -0.0232,  0.0204,  ..., -0.0251, -0.0045, -0.0340],\n",
      "        [-0.0490,  0.0524, -0.0157,  ...,  0.0544,  0.0354,  0.0334],\n",
      "        [-0.0078,  0.0279,  0.0335,  ...,  0.0225,  0.0306, -0.0153]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0401,  0.0335,  0.0272, -0.0431,  0.0337,  0.0024, -0.0322, -0.0318,\n",
      "        -0.0013, -0.0178, -0.0308,  0.0415,  0.0221, -0.0133,  0.0043, -0.0139,\n",
      "        -0.0204,  0.0386,  0.0277,  0.0243], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def make_torch_seed():\n",
    "    while True:\n",
    "        seed = torch.random.seed()\n",
    "        if seed < 2**63:\n",
    "            return seed\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    #TODO: Try other network architectures (smaller layers)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        #self.conv1 = nn.Conv2d(2, 2, 13)\n",
    "        #self.conv2 = nn.Conv2d(2, 2, 1)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(658, 512)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 20)\n",
    "\n",
    "    \n",
    "    #TODO: Try other activation func\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (1, 1))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        #x = F.max_pool2d(F.relu(self.conv2(x)), 1)\n",
    "        #x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \"\"\"\n",
    "    def foward2(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \"\"\"\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "initial_seed = torch.random.seed()\n",
    "net = Net()\n",
    "# print(net)\n",
    "# print(net.parameters())\n",
    "# flattened = []\n",
    "# total = 0\n",
    "# for p in net.parameters():\n",
    "#     print(p)\n",
    "# #     print(p)\n",
    "# #     print(p.shape)\n",
    "#     f = torch.flatten(p)\n",
    "#     print(f.shape)\n",
    "#     length = len(f)\n",
    "#     print(length)\n",
    "#     total += length\n",
    "#     for i in range(length):\n",
    "#         flattened.append(f[i].item())\n",
    "# #     print(f)\n",
    "# #     flattened.append(list(f))\n",
    "# # print(net.parameters().shape)\n",
    "# # print(total)\n",
    "# # print(flattened[0])\n",
    "# # noise = torch.empty(total).normal_(mean=0,std=0.1)\n",
    "# print(noise[0])\n",
    "\n",
    "modification_seed = torch.random.seed()\n",
    "flattened = []\n",
    "with torch.no_grad():\n",
    "    for p in net.parameters():\n",
    "        print(\"Starting weights:\")\n",
    "        print(p)\n",
    "        s = p.shape\n",
    "        print(\"Noise vector:\")\n",
    "        noise = torch.empty(s).normal_(mean=0,std=0.01)\n",
    "        print(noise)\n",
    "        p += noise\n",
    "        print(\"New weights:\")\n",
    "        print(p)\n",
    "#     print(f)\n",
    "#     flattened.append(list(f))\n",
    "# print(net.parameters().shape)\n",
    "# print(total)\n",
    "# print(flattened[0])\n",
    "# noise = torch.empty(t\n",
    "\n",
    "print()\n",
    "print(\"-=-=--=-=--=-=-=-=\")\n",
    "print()\n",
    "\n",
    "\n",
    "net2 = copy.deepcopy(net)\n",
    "# net2.load_state_dict(net.state_dict())\n",
    "\n",
    "#Copy\n",
    "\n",
    "    \n",
    "    \n",
    "torch.random.manual_seed(modification_seed)\n",
    "with torch.no_grad():\n",
    "    for p in net.parameters():\n",
    "        print(\"Starting weights:\")\n",
    "        print(p)\n",
    "        s = p.shape\n",
    "        print(\"Noise vector:\")\n",
    "        noise = torch.empty(s).normal_(mean=0,std=0.01)\n",
    "        print(noise)\n",
    "        p += noise\n",
    "        print(\"New weights:\")\n",
    "        print(p)\n",
    "        \n",
    "    \n",
    "print(\"\")\n",
    "print(\"-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"aaa\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p2 in net2.parameters():\n",
    "        print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_tensor(mylist):\n",
    "    encoded_observations = np.array(mylist).reshape(1,658)\n",
    "    tensor_observations = torch.FloatTensor(encoded_observations)\n",
    "    return tensor_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_encoded_observations = get_encoded_observations(obs_encoder, state, 0)\n",
    "#encoded_observations = np.array(list_encoded_observations).reshape(1,658)\n",
    "#tensor_observations = torch.FloatTensor(encoded_observations)\n",
    "#net(tensor_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = tensor_observations\n",
    "#out = net(input)\n",
    "#print(out)\n",
    "#net.zero_grad()\n",
    "#out.backward(torch.randn(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def make_action(array):\\n        index = np.rgmax(array)\\n        return index\\n\\n\\n    def get_weights():\\n        #Pytorch code to get an array with all the weights of the network\\n        weights  = [] #np.zeros()\\n\\n    def set_wegiths(weights):\\n        #Pytorch code to set the weigths\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PytorchAgent:\n",
    "\n",
    "    def __init__(self,game,net=None,mutation_sd=0.01):\n",
    "        if net is None:\n",
    "            self.net = Net()\n",
    "        else:\n",
    "            self.net = copy.deepcopy(net)\n",
    "        self.game = game #TODO is there a way to factoor this out?\n",
    "        self.obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "        self.fitness=0.0\n",
    "\n",
    "    def act(self, state):\n",
    "        with torch.no_grad():\n",
    "            encoded_observations = get_encoded_observations(self.obs_encoder, state, state.cur_player())\n",
    "            input_tensor = list_to_tensor(encoded_observations)\n",
    "            output_tensor = self.net(input_tensor)\n",
    "            weight = output_tensor.tolist()[0]#weight of 20 possible moves\n",
    "            rank = sorted(range(len(weight)), key=lambda k: weight[k]) # rank of 20 possible moves in weight\n",
    "            index = sorted(range(len(rank)), key=lambda k: rank[k]) # index of sorted rank of 20 possible moves\n",
    "            observation = state.observation(state.cur_player())# need to make sure whether observation = state works\n",
    "            for i in index:\n",
    "#                 print(\"checking move:\" + str(self.game.get_move(i)))\n",
    "                if str(self.game.get_move(i)) in str(observation.legal_moves()):# Is there a way of not using str?\n",
    "#                     print(\"valid\")\n",
    "                    return self.game.get_move(i)\n",
    "#                 else:\n",
    "#                     print(\"invalid, checking next possible move in priority list\")\n",
    "        #here you probably need to check if it is a valid action\n",
    "        # There's a code in the HLE that gets the legal actions from a state (a \"mask\")\n",
    "        # you can do mask*model.forward()\n",
    "        # This will multiply all ILLEGAL actions by zero\n",
    "    \n",
    "    # If seed is none, create a new seed and append to self.seeds. Otherwise, just use the given seed, but not append\n",
    "    #TODO: Try other values for mutation rate\n",
    "    def mutate(self,sd=0.01,seed=None): #TODO: Posssibly try to ranomly change only a few of the parametes usign a mutation rate (low priorty)?\n",
    "        if seed is None:\n",
    "            seed = self.make_torch_seed()\n",
    "        with torch.no_grad():\n",
    "            torch.random.manual_seed(seed)\n",
    "            for p in net.parameters():\n",
    "                shape = p.shape\n",
    "                noise = torch.empty(shape).normal_(mean=0.0,std=sd)\n",
    "                p += noise\n",
    "    \n",
    "    def make_torch_seed(self):\n",
    "        while True:\n",
    "            seed = torch.random.seed()\n",
    "            if seed < 2**63:\n",
    "                return seed\n",
    "        \n",
    "\"\"\"\n",
    "    def make_action(array):\n",
    "        index = np.rgmax(array)\n",
    "        return index\n",
    "\n",
    "\n",
    "    def get_weights():\n",
    "        #Pytorch code to get an array with all the weights of the network\n",
    "        weights  = [] #np.zeros()\n",
    "\n",
    "    def set_wegiths(weights):\n",
    "        #Pytorch code to set the weigths\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_parameters = {\"players\": 2, \"random_start_player\": True}\n",
    "game = pyhanabi.HanabiGame(game_parameters)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "state = game.new_initial_state()\n",
    "\n",
    "pyagent = PytorchAgent(game)\n",
    "\n",
    "population_size = 5\n",
    "num_games = 5\n",
    "num_generations = 500\n",
    "# one run of game\n",
    "score=0\n",
    "\n",
    "# population = [PytorchAgent(game) for p in range(population_size)]\n",
    "\n",
    "    \n",
    "while not state.is_terminal():\n",
    "    if state.score() >=score:\n",
    "        score = state.score()\n",
    "    if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:\n",
    "        state.deal_random_card()\n",
    "        continue\n",
    "\n",
    "    #print_state(state)\n",
    "\n",
    "    #observation = state.observation(state.cur_player())\n",
    "    #print_observation(observation)\n",
    "    #print(observation.legal_moves())\n",
    "    #print_encoded_observations(obs_encoder, state, game.num_players())\n",
    "    #encoded_observations = get_encoded_observations(obs_encoder, state, state.cur_player())\n",
    "    #mytensor = list_to_tensor(encoded_observations)\n",
    "    #legal_moves = state.legal_moves()\n",
    "    # print(\"\")\n",
    "    # print(\"Number of legal moves: {}\".format(len(legal_moves)))\n",
    "    current_life_token = state.life_tokens()\n",
    "    current_fireworks = state.fireworks()\n",
    "    move  = pyagent.act(state)\n",
    "    # move = np.random.choice(legal_moves)\n",
    "    # print(\"Chose random legal move: {}\".format(move))\n",
    "\n",
    "    state.apply_move(move)\n",
    "print(\"game finished\")\n",
    "print(state.fireworks())\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_start_player=true\n",
      "seed=-456913086\n",
      "max_life_tokens=3\n",
      "hand_size=5\n",
      "observation_type=1\n",
      "max_information_tokens=8\n",
      "ranks=5\n",
      "colors=5\n",
      "players=2\n",
      "<__main__.PytorchAgent object at 0x7fc0dbc577d0>\n",
      "Time 15:38:33. Best of generation 0 has fitness 0.9\n",
      "0\n",
      "Time 15:40:29. Best of generation 1 has fitness 1.75\n",
      "0\n",
      "Time 15:41:16. Best of generation 2 has fitness 0.85\n",
      "0\n",
      "Time 15:43:00. Best of generation 3 has fitness 1.0\n",
      "0\n",
      "Time 15:43:39. Best of generation 4 has fitness 0.65\n",
      "0\n",
      "Time 15:45:28. Best of generation 5 has fitness 1.5\n",
      "0\n",
      "Time 15:45:57. Best of generation 6 has fitness 0.85\n",
      "0\n",
      "Time 15:47:33. Best of generation 7 has fitness 1.15\n",
      "0\n",
      "Time 15:48:22. Best of generation 8 has fitness 1.1\n",
      "0\n",
      "Time 15:50:03. Best of generation 9 has fitness 1.1\n",
      "0\n",
      "Time 15:50:38. Best of generation 10 has fitness 1.7\n",
      "0\n",
      "Time 15:51:15. Best of generation 11 has fitness 1.45\n",
      "0\n",
      "Time 15:52:11. Best of generation 12 has fitness 1.4\n",
      "0\n",
      "Time 15:52:48. Best of generation 13 has fitness 1.7\n",
      "0\n",
      "Time 15:53:22. Best of generation 14 has fitness 1.0\n",
      "0\n",
      "Time 15:54:07. Best of generation 15 has fitness 1.8\n",
      "0\n",
      "Time 15:54:53. Best of generation 16 has fitness 0.9\n",
      "0\n",
      "Time 15:55:37. Best of generation 17 has fitness 1.25\n",
      "0\n",
      "Time 15:56:14. Best of generation 18 has fitness 1.35\n",
      "0\n",
      "Time 15:56:50. Best of generation 19 has fitness 0.9\n",
      "0\n",
      "Time 15:57:27. Best of generation 20 has fitness 1.45\n",
      "0\n",
      "Time 15:58:00. Best of generation 21 has fitness 1.7\n",
      "0\n",
      "Time 15:58:39. Best of generation 22 has fitness 1.55\n",
      "0\n",
      "Time 15:59:16. Best of generation 23 has fitness 0.95\n",
      "0\n",
      "Time 16:00:00. Best of generation 24 has fitness 0.85\n",
      "0\n",
      "Time 16:00:35. Best of generation 25 has fitness 0.95\n",
      "0\n",
      "Time 16:01:07. Best of generation 26 has fitness 1.5\n",
      "0\n",
      "Time 16:01:36. Best of generation 27 has fitness 1.15\n",
      "0\n",
      "Time 16:02:11. Best of generation 28 has fitness 1.55\n",
      "0\n",
      "Time 16:02:46. Best of generation 29 has fitness 1.35\n",
      "0\n",
      "Time 16:03:34. Best of generation 30 has fitness 0.45\n",
      "0\n",
      "Time 16:04:05. Best of generation 31 has fitness 1.55\n",
      "0\n",
      "Time 16:04:18. Best of generation 32 has fitness 1.1\n",
      "0\n",
      "Time 16:04:32. Best of generation 33 has fitness 1.0\n",
      "0\n",
      "Time 16:04:59. Best of generation 34 has fitness 1.55\n",
      "0\n",
      "Time 16:05:18. Best of generation 35 has fitness 0.9\n",
      "0\n",
      "Time 16:05:36. Best of generation 36 has fitness 1.5\n",
      "0\n",
      "Time 16:05:54. Best of generation 37 has fitness 1.8\n",
      "0\n",
      "Time 16:06:12. Best of generation 38 has fitness 1.1\n",
      "0\n",
      "Time 16:06:30. Best of generation 39 has fitness 0.8\n",
      "0\n",
      "Time 16:06:50. Best of generation 40 has fitness 1.65\n",
      "0\n",
      "Time 16:07:06. Best of generation 41 has fitness 1.2\n",
      "0\n",
      "Time 16:07:23. Best of generation 42 has fitness 1.55\n",
      "0\n",
      "Time 16:07:40. Best of generation 43 has fitness 0.95\n",
      "0\n",
      "Time 16:07:58. Best of generation 44 has fitness 1.2\n",
      "0\n",
      "Time 16:08:16. Best of generation 45 has fitness 0.85\n",
      "0\n",
      "Time 16:08:33. Best of generation 46 has fitness 1.05\n",
      "0\n",
      "Time 16:08:53. Best of generation 47 has fitness 1.7\n",
      "0\n",
      "Time 16:09:27. Best of generation 48 has fitness 1.2\n",
      "0\n",
      "Time 16:09:52. Best of generation 49 has fitness 1.55\n",
      "0\n",
      "Time 16:10:12. Best of generation 50 has fitness 0.95\n",
      "0\n",
      "Time 16:10:32. Best of generation 51 has fitness 0.85\n",
      "0\n",
      "Time 16:10:52. Best of generation 52 has fitness 1.4\n",
      "0\n",
      "Time 16:11:12. Best of generation 53 has fitness 1.4\n",
      "0\n",
      "Time 16:11:34. Best of generation 54 has fitness 1.2\n",
      "0\n",
      "Time 16:11:56. Best of generation 55 has fitness 1.5\n",
      "0\n",
      "Time 16:12:15. Best of generation 56 has fitness 1.3\n",
      "0\n",
      "Time 16:12:35. Best of generation 57 has fitness 1.35\n",
      "0\n",
      "Time 16:12:56. Best of generation 58 has fitness 1.45\n",
      "0\n",
      "Time 16:13:16. Best of generation 59 has fitness 1.2\n",
      "0\n",
      "Time 16:13:36. Best of generation 60 has fitness 1.6\n",
      "0\n",
      "Time 16:13:55. Best of generation 61 has fitness 1.3\n",
      "0\n",
      "Time 16:14:14. Best of generation 62 has fitness 1.4\n",
      "0\n",
      "Time 16:14:34. Best of generation 63 has fitness 1.4\n",
      "0\n",
      "Time 16:14:53. Best of generation 64 has fitness 1.25\n",
      "0\n",
      "Time 16:15:12. Best of generation 65 has fitness 1.35\n",
      "0\n",
      "Time 16:15:31. Best of generation 66 has fitness 1.15\n",
      "0\n",
      "Time 16:15:51. Best of generation 67 has fitness 1.6\n",
      "0\n",
      "Time 16:16:09. Best of generation 68 has fitness 1.3\n",
      "0\n",
      "Time 16:16:28. Best of generation 69 has fitness 1.45\n",
      "0\n",
      "Time 16:16:46. Best of generation 70 has fitness 1.05\n",
      "0\n",
      "Time 16:17:05. Best of generation 71 has fitness 0.95\n",
      "0\n",
      "Time 16:17:25. Best of generation 72 has fitness 1.1\n",
      "0\n",
      "Time 16:17:44. Best of generation 73 has fitness 1.2\n",
      "0\n",
      "Time 16:18:03. Best of generation 74 has fitness 1.3\n",
      "0\n",
      "Time 16:18:23. Best of generation 75 has fitness 0.75\n",
      "0\n",
      "Time 16:18:42. Best of generation 76 has fitness 0.95\n",
      "0\n",
      "Time 16:19:01. Best of generation 77 has fitness 1.2\n",
      "0\n",
      "Time 16:19:19. Best of generation 78 has fitness 1.5\n",
      "0\n",
      "Time 16:19:38. Best of generation 79 has fitness 0.85\n",
      "0\n",
      "Time 16:19:57. Best of generation 80 has fitness 1.05\n",
      "0\n",
      "Time 16:20:17. Best of generation 81 has fitness 1.1\n",
      "0\n",
      "Time 16:20:37. Best of generation 82 has fitness 1.0\n",
      "0\n",
      "Time 16:20:57. Best of generation 83 has fitness 1.7\n",
      "0\n",
      "Time 16:21:17. Best of generation 84 has fitness 1.55\n",
      "0\n",
      "Time 16:21:37. Best of generation 85 has fitness 1.75\n",
      "0\n",
      "Time 16:21:57. Best of generation 86 has fitness 1.0\n",
      "0\n",
      "Time 16:22:17. Best of generation 87 has fitness 1.45\n",
      "0\n",
      "Time 16:22:36. Best of generation 88 has fitness 1.35\n",
      "0\n",
      "Time 16:22:55. Best of generation 89 has fitness 1.6\n",
      "0\n",
      "Time 16:23:13. Best of generation 90 has fitness 1.05\n",
      "0\n",
      "Time 16:23:32. Best of generation 91 has fitness 1.65\n",
      "0\n",
      "Time 16:23:50. Best of generation 92 has fitness 1.75\n",
      "0\n",
      "Time 16:24:08. Best of generation 93 has fitness 1.3\n",
      "0\n",
      "Time 16:24:28. Best of generation 94 has fitness 1.35\n",
      "0\n",
      "Time 16:24:46. Best of generation 95 has fitness 1.25\n",
      "0\n",
      "Time 16:25:04. Best of generation 96 has fitness 0.9\n",
      "0\n",
      "Time 16:25:23. Best of generation 97 has fitness 1.2\n",
      "0\n",
      "Time 16:25:42. Best of generation 98 has fitness 2.0\n",
      "0\n",
      "Time 16:26:01. Best of generation 99 has fitness 1.75\n",
      "0\n",
      "Time 16:26:20. Best of generation 100 has fitness 1.05\n",
      "0\n",
      "Time 16:26:40. Best of generation 101 has fitness 1.15\n",
      "0\n",
      "Time 16:26:59. Best of generation 102 has fitness 1.0\n",
      "0\n",
      "Time 16:27:18. Best of generation 103 has fitness 1.3\n",
      "0\n",
      "Time 16:27:38. Best of generation 104 has fitness 1.25\n",
      "0\n",
      "Time 16:27:57. Best of generation 105 has fitness 1.65\n",
      "0\n",
      "Time 16:28:16. Best of generation 106 has fitness 1.4\n",
      "0\n",
      "Time 16:28:34. Best of generation 107 has fitness 0.95\n",
      "0\n",
      "Time 16:28:51. Best of generation 108 has fitness 1.0\n",
      "0\n",
      "Time 16:29:10. Best of generation 109 has fitness 1.25\n",
      "0\n",
      "Time 16:29:28. Best of generation 110 has fitness 0.85\n",
      "0\n",
      "Time 16:29:46. Best of generation 111 has fitness 1.2\n",
      "0\n",
      "Time 16:30:05. Best of generation 112 has fitness 1.65\n",
      "0\n",
      "Time 16:30:24. Best of generation 113 has fitness 1.15\n",
      "0\n",
      "Time 16:30:44. Best of generation 114 has fitness 0.8\n",
      "0\n",
      "Time 16:31:03. Best of generation 115 has fitness 1.0\n",
      "0\n",
      "Time 16:31:21. Best of generation 116 has fitness 1.0\n",
      "0\n",
      "Time 16:31:41. Best of generation 117 has fitness 1.45\n",
      "0\n",
      "Time 16:31:59. Best of generation 118 has fitness 0.9\n",
      "0\n",
      "Time 16:32:17. Best of generation 119 has fitness 0.9\n",
      "0\n",
      "Time 16:32:35. Best of generation 120 has fitness 1.1\n",
      "0\n",
      "Time 16:32:54. Best of generation 121 has fitness 1.25\n",
      "0\n",
      "Time 16:33:13. Best of generation 122 has fitness 0.65\n",
      "0\n",
      "Time 16:33:32. Best of generation 123 has fitness 1.0\n",
      "0\n",
      "Time 16:33:49. Best of generation 124 has fitness 1.8\n",
      "0\n",
      "Time 16:34:06. Best of generation 125 has fitness 0.85\n",
      "0\n",
      "Time 16:34:24. Best of generation 126 has fitness 0.9\n",
      "0\n",
      "Time 16:34:40. Best of generation 127 has fitness 1.85\n",
      "0\n",
      "Time 16:34:57. Best of generation 128 has fitness 1.2\n",
      "0\n",
      "Time 16:35:14. Best of generation 129 has fitness 1.25\n",
      "0\n",
      "Time 16:35:30. Best of generation 130 has fitness 1.3\n",
      "0\n",
      "Time 16:35:47. Best of generation 131 has fitness 0.85\n",
      "0\n",
      "Time 16:36:04. Best of generation 132 has fitness 1.25\n",
      "0\n",
      "Time 16:36:21. Best of generation 133 has fitness 0.8\n",
      "0\n",
      "Time 16:36:38. Best of generation 134 has fitness 1.5\n",
      "0\n",
      "Time 16:36:55. Best of generation 135 has fitness 0.9\n",
      "0\n",
      "Time 16:37:11. Best of generation 136 has fitness 1.8\n",
      "0\n",
      "Time 16:37:28. Best of generation 137 has fitness 1.35\n",
      "0\n",
      "Time 16:37:44. Best of generation 138 has fitness 1.05\n",
      "0\n",
      "Time 16:38:01. Best of generation 139 has fitness 1.4\n",
      "0\n",
      "Time 16:38:17. Best of generation 140 has fitness 1.05\n",
      "0\n",
      "Time 16:38:33. Best of generation 141 has fitness 1.45\n",
      "0\n",
      "Time 16:38:51. Best of generation 142 has fitness 1.9\n",
      "0\n",
      "Time 16:39:07. Best of generation 143 has fitness 1.25\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 16:39:23. Best of generation 144 has fitness 1.2\n",
      "0\n",
      "Time 16:39:40. Best of generation 145 has fitness 1.05\n",
      "0\n",
      "Time 16:39:56. Best of generation 146 has fitness 1.4\n",
      "0\n",
      "Time 16:40:13. Best of generation 147 has fitness 1.15\n",
      "0\n",
      "Time 16:40:29. Best of generation 148 has fitness 0.75\n",
      "0\n",
      "Time 16:40:45. Best of generation 149 has fitness 0.75\n",
      "0\n",
      "Time 16:41:02. Best of generation 150 has fitness 1.05\n",
      "0\n",
      "Time 16:41:18. Best of generation 151 has fitness 1.5\n",
      "0\n",
      "Time 16:41:35. Best of generation 152 has fitness 1.3\n",
      "0\n",
      "Time 16:41:52. Best of generation 153 has fitness 1.45\n",
      "0\n",
      "Time 16:42:08. Best of generation 154 has fitness 1.2\n",
      "0\n",
      "Time 16:42:25. Best of generation 155 has fitness 1.0\n",
      "0\n",
      "Time 16:42:41. Best of generation 156 has fitness 1.35\n",
      "0\n",
      "Time 16:42:58. Best of generation 157 has fitness 1.05\n",
      "0\n",
      "Time 16:43:15. Best of generation 158 has fitness 1.0\n",
      "0\n",
      "Time 16:43:31. Best of generation 159 has fitness 1.45\n",
      "0\n",
      "Time 16:43:48. Best of generation 160 has fitness 1.45\n",
      "0\n",
      "Time 16:44:04. Best of generation 161 has fitness 1.2\n",
      "0\n",
      "Time 16:44:31. Best of generation 162 has fitness 1.25\n",
      "0\n",
      "Time 16:44:46. Best of generation 163 has fitness 1.45\n",
      "0\n",
      "Time 16:45:01. Best of generation 164 has fitness 1.35\n",
      "0\n",
      "Time 16:45:16. Best of generation 165 has fitness 1.05\n",
      "0\n",
      "Time 16:45:30. Best of generation 166 has fitness 1.0\n",
      "0\n",
      "Time 16:45:45. Best of generation 167 has fitness 1.25\n",
      "0\n",
      "Time 16:46:00. Best of generation 168 has fitness 1.9\n",
      "0\n",
      "Time 16:46:15. Best of generation 169 has fitness 0.95\n",
      "0\n",
      "Time 16:46:30. Best of generation 170 has fitness 1.6\n",
      "0\n",
      "Time 16:46:44. Best of generation 171 has fitness 1.35\n",
      "0\n",
      "Time 16:46:59. Best of generation 172 has fitness 1.8\n",
      "0\n",
      "Time 16:47:13. Best of generation 173 has fitness 0.95\n",
      "0\n",
      "Time 16:47:28. Best of generation 174 has fitness 1.65\n",
      "0\n",
      "Time 16:47:43. Best of generation 175 has fitness 0.75\n",
      "0\n",
      "Time 16:47:58. Best of generation 176 has fitness 1.4\n",
      "0\n",
      "Time 16:48:12. Best of generation 177 has fitness 1.15\n",
      "0\n",
      "Time 16:48:26. Best of generation 178 has fitness 1.45\n",
      "0\n",
      "Time 16:48:41. Best of generation 179 has fitness 1.6\n",
      "0\n",
      "Time 16:48:55. Best of generation 180 has fitness 1.4\n",
      "0\n",
      "Time 16:49:09. Best of generation 181 has fitness 1.85\n",
      "0\n",
      "Time 16:49:24. Best of generation 182 has fitness 1.1\n",
      "0\n",
      "Time 16:49:39. Best of generation 183 has fitness 1.45\n",
      "0\n",
      "Time 16:49:53. Best of generation 184 has fitness 1.45\n",
      "0\n",
      "Time 16:50:09. Best of generation 185 has fitness 0.9\n",
      "0\n",
      "Time 16:50:23. Best of generation 186 has fitness 0.8\n",
      "0\n",
      "Time 16:50:38. Best of generation 187 has fitness 1.1\n",
      "0\n",
      "Time 16:50:52. Best of generation 188 has fitness 1.0\n",
      "0\n",
      "Time 16:51:07. Best of generation 189 has fitness 1.55\n",
      "0\n",
      "Time 16:51:22. Best of generation 190 has fitness 1.45\n",
      "0\n",
      "Time 16:51:37. Best of generation 191 has fitness 1.2\n",
      "0\n",
      "Time 16:51:52. Best of generation 192 has fitness 0.8\n",
      "0\n",
      "Time 16:52:07. Best of generation 193 has fitness 1.55\n",
      "0\n",
      "Time 16:52:21. Best of generation 194 has fitness 0.9\n",
      "0\n",
      "Time 16:52:36. Best of generation 195 has fitness 1.3\n",
      "0\n",
      "Time 16:52:51. Best of generation 196 has fitness 1.2\n",
      "0\n",
      "Time 16:53:06. Best of generation 197 has fitness 1.65\n",
      "0\n",
      "Time 16:53:20. Best of generation 198 has fitness 1.45\n",
      "0\n",
      "Time 16:53:34. Best of generation 199 has fitness 1.4\n",
      "0\n",
      "Time 16:53:49. Best of generation 200 has fitness 1.15\n",
      "0\n",
      "Time 16:54:04. Best of generation 201 has fitness 1.15\n",
      "0\n",
      "Time 16:54:18. Best of generation 202 has fitness 1.2\n",
      "0\n",
      "Time 16:54:33. Best of generation 203 has fitness 1.3\n",
      "0\n",
      "Time 16:54:47. Best of generation 204 has fitness 1.2\n",
      "0\n",
      "Time 16:55:02. Best of generation 205 has fitness 1.7\n",
      "0\n",
      "Time 16:55:17. Best of generation 206 has fitness 1.45\n",
      "0\n",
      "Time 16:55:34. Best of generation 207 has fitness 1.1\n",
      "0\n",
      "Time 16:55:50. Best of generation 208 has fitness 1.0\n",
      "0\n",
      "Time 16:56:05. Best of generation 209 has fitness 1.25\n",
      "0\n",
      "Time 16:56:20. Best of generation 210 has fitness 1.5\n",
      "0\n",
      "Time 16:56:34. Best of generation 211 has fitness 2.35\n",
      "0\n",
      "Time 16:56:49. Best of generation 212 has fitness 1.15\n",
      "0\n",
      "Time 16:57:05. Best of generation 213 has fitness 1.4\n",
      "0\n",
      "Time 16:57:21. Best of generation 214 has fitness 2.25\n",
      "0\n",
      "Time 16:57:36. Best of generation 215 has fitness 1.55\n",
      "0\n",
      "Time 16:57:51. Best of generation 216 has fitness 0.7\n",
      "0\n",
      "Time 16:58:05. Best of generation 217 has fitness 1.25\n",
      "0\n",
      "Time 16:58:19. Best of generation 218 has fitness 1.3\n",
      "0\n",
      "Time 16:58:34. Best of generation 219 has fitness 0.95\n",
      "0\n",
      "Time 16:58:49. Best of generation 220 has fitness 1.15\n",
      "0\n",
      "Time 16:59:04. Best of generation 221 has fitness 1.35\n",
      "0\n",
      "Time 16:59:19. Best of generation 222 has fitness 1.45\n",
      "0\n",
      "Time 16:59:34. Best of generation 223 has fitness 1.1\n",
      "0\n",
      "Time 16:59:48. Best of generation 224 has fitness 1.85\n",
      "0\n",
      "Time 17:00:03. Best of generation 225 has fitness 1.15\n",
      "0\n",
      "Time 17:00:17. Best of generation 226 has fitness 1.65\n",
      "0\n",
      "Time 17:00:32. Best of generation 227 has fitness 1.65\n",
      "0\n",
      "Time 17:00:47. Best of generation 228 has fitness 0.9\n",
      "0\n",
      "Time 17:01:02. Best of generation 229 has fitness 1.2\n",
      "0\n",
      "Time 17:01:16. Best of generation 230 has fitness 1.55\n",
      "0\n",
      "Time 17:01:31. Best of generation 231 has fitness 1.3\n",
      "0\n",
      "Time 17:01:46. Best of generation 232 has fitness 1.2\n",
      "0\n",
      "Time 17:02:01. Best of generation 233 has fitness 1.25\n",
      "0\n",
      "Time 17:02:16. Best of generation 234 has fitness 1.45\n",
      "0\n",
      "Time 17:02:30. Best of generation 235 has fitness 1.65\n",
      "0\n",
      "Time 17:02:45. Best of generation 236 has fitness 0.85\n",
      "0\n",
      "Time 17:03:00. Best of generation 237 has fitness 1.25\n",
      "0\n",
      "Time 17:03:14. Best of generation 238 has fitness 0.9\n",
      "0\n",
      "Time 17:03:29. Best of generation 239 has fitness 1.15\n",
      "0\n",
      "Time 17:03:44. Best of generation 240 has fitness 1.35\n",
      "0\n",
      "Time 17:03:59. Best of generation 241 has fitness 1.45\n",
      "0\n",
      "Time 17:04:13. Best of generation 242 has fitness 1.3\n",
      "0\n",
      "Time 17:04:27. Best of generation 243 has fitness 1.85\n",
      "0\n",
      "Time 17:04:42. Best of generation 244 has fitness 1.1\n",
      "0\n",
      "Time 17:04:57. Best of generation 245 has fitness 1.3\n",
      "0\n",
      "Time 17:05:11. Best of generation 246 has fitness 1.7\n",
      "0\n",
      "Time 17:05:26. Best of generation 247 has fitness 1.25\n",
      "0\n",
      "Time 17:05:41. Best of generation 248 has fitness 1.65\n",
      "0\n",
      "Time 17:05:55. Best of generation 249 has fitness 1.1\n",
      "0\n",
      "Time 17:06:09. Best of generation 250 has fitness 1.25\n",
      "0\n",
      "Time 17:06:25. Best of generation 251 has fitness 1.25\n",
      "0\n",
      "Time 17:06:43. Best of generation 252 has fitness 1.05\n",
      "0\n",
      "Time 17:07:01. Best of generation 253 has fitness 1.5\n",
      "0\n",
      "Time 17:07:18. Best of generation 254 has fitness 1.6\n",
      "0\n",
      "Time 17:07:36. Best of generation 255 has fitness 0.8\n",
      "0\n",
      "Time 17:07:52. Best of generation 256 has fitness 1.15\n",
      "0\n",
      "Time 17:08:09. Best of generation 257 has fitness 1.2\n",
      "0\n",
      "Time 17:08:27. Best of generation 258 has fitness 1.15\n",
      "0\n",
      "Time 17:08:45. Best of generation 259 has fitness 1.75\n",
      "0\n",
      "Time 17:09:03. Best of generation 260 has fitness 1.0\n",
      "0\n",
      "Time 17:09:21. Best of generation 261 has fitness 1.5\n",
      "0\n",
      "Time 17:09:39. Best of generation 262 has fitness 1.5\n",
      "0\n",
      "Time 17:09:58. Best of generation 263 has fitness 1.55\n",
      "0\n",
      "Time 17:10:17. Best of generation 264 has fitness 1.25\n",
      "0\n",
      "Time 17:10:36. Best of generation 265 has fitness 1.45\n",
      "0\n",
      "Time 17:10:54. Best of generation 266 has fitness 1.6\n",
      "0\n",
      "Time 17:11:11. Best of generation 267 has fitness 0.7\n",
      "0\n",
      "Time 17:11:30. Best of generation 268 has fitness 1.15\n",
      "0\n",
      "Time 17:11:48. Best of generation 269 has fitness 0.85\n",
      "0\n",
      "Time 17:12:07. Best of generation 270 has fitness 1.65\n",
      "0\n",
      "Time 17:12:25. Best of generation 271 has fitness 0.9\n",
      "0\n",
      "Time 17:12:43. Best of generation 272 has fitness 1.1\n",
      "0\n",
      "Time 17:13:01. Best of generation 273 has fitness 0.75\n",
      "0\n",
      "Time 17:13:19. Best of generation 274 has fitness 0.95\n",
      "0\n",
      "Time 17:13:36. Best of generation 275 has fitness 1.0\n",
      "0\n",
      "Time 17:13:55. Best of generation 276 has fitness 1.55\n",
      "0\n",
      "Time 17:14:14. Best of generation 277 has fitness 1.05\n",
      "0\n",
      "Time 17:14:32. Best of generation 278 has fitness 0.85\n",
      "0\n",
      "Time 17:14:50. Best of generation 279 has fitness 1.45\n",
      "0\n",
      "Time 17:15:09. Best of generation 280 has fitness 1.6\n",
      "0\n",
      "Time 17:15:27. Best of generation 281 has fitness 1.2\n",
      "0\n",
      "Time 17:15:45. Best of generation 282 has fitness 1.3\n",
      "0\n",
      "Time 17:16:04. Best of generation 283 has fitness 1.35\n",
      "0\n",
      "Time 17:16:23. Best of generation 284 has fitness 1.0\n",
      "0\n",
      "Time 17:16:41. Best of generation 285 has fitness 1.2\n",
      "0\n",
      "Time 17:16:58. Best of generation 286 has fitness 1.25\n",
      "0\n",
      "Time 17:17:16. Best of generation 287 has fitness 1.3\n",
      "0\n",
      "Time 17:17:34. Best of generation 288 has fitness 0.95\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 17:17:53. Best of generation 289 has fitness 1.35\n",
      "0\n",
      "Time 17:18:12. Best of generation 290 has fitness 0.85\n",
      "0\n",
      "Time 17:18:31. Best of generation 291 has fitness 1.35\n",
      "0\n",
      "Time 17:18:50. Best of generation 292 has fitness 1.55\n",
      "0\n",
      "Time 17:19:09. Best of generation 293 has fitness 1.1\n",
      "0\n",
      "Time 17:19:27. Best of generation 294 has fitness 1.3\n",
      "0\n",
      "Time 17:19:46. Best of generation 295 has fitness 1.05\n",
      "0\n",
      "Time 17:20:05. Best of generation 296 has fitness 1.45\n",
      "0\n",
      "Time 17:20:24. Best of generation 297 has fitness 1.15\n",
      "0\n",
      "Time 17:20:44. Best of generation 298 has fitness 1.25\n",
      "0\n",
      "Time 17:21:03. Best of generation 299 has fitness 1.2\n",
      "0\n",
      "Time 17:21:21. Best of generation 300 has fitness 1.75\n",
      "0\n",
      "Time 17:21:40. Best of generation 301 has fitness 1.05\n",
      "0\n",
      "Time 17:21:59. Best of generation 302 has fitness 0.95\n",
      "0\n",
      "Time 17:22:25. Best of generation 303 has fitness 0.9\n",
      "0\n",
      "Time 17:22:47. Best of generation 304 has fitness 1.15\n",
      "0\n",
      "Time 17:23:13. Best of generation 305 has fitness 2.05\n",
      "0\n",
      "Time 17:23:33. Best of generation 306 has fitness 0.95\n",
      "0\n",
      "Time 17:23:55. Best of generation 307 has fitness 0.95\n",
      "0\n",
      "Time 17:24:18. Best of generation 308 has fitness 1.6\n",
      "0\n",
      "Time 17:24:41. Best of generation 309 has fitness 1.7\n",
      "0\n",
      "Time 17:25:03. Best of generation 310 has fitness 0.85\n",
      "0\n",
      "Time 17:25:27. Best of generation 311 has fitness 1.15\n",
      "0\n",
      "Time 17:25:50. Best of generation 312 has fitness 1.5\n",
      "0\n",
      "Time 17:26:13. Best of generation 313 has fitness 1.2\n",
      "0\n",
      "Time 17:26:36. Best of generation 314 has fitness 1.5\n",
      "0\n",
      "Time 17:26:58. Best of generation 315 has fitness 1.4\n",
      "0\n",
      "Time 17:27:18. Best of generation 316 has fitness 1.5\n",
      "0\n",
      "Time 17:27:39. Best of generation 317 has fitness 1.35\n",
      "0\n",
      "Time 17:28:01. Best of generation 318 has fitness 1.35\n",
      "0\n",
      "Time 17:28:25. Best of generation 319 has fitness 1.05\n",
      "0\n",
      "Time 17:28:48. Best of generation 320 has fitness 1.05\n",
      "0\n",
      "Time 17:29:09. Best of generation 321 has fitness 1.35\n",
      "0\n",
      "Time 17:29:30. Best of generation 322 has fitness 1.4\n",
      "0\n",
      "Time 17:29:51. Best of generation 323 has fitness 0.75\n",
      "0\n",
      "Time 17:30:13. Best of generation 324 has fitness 1.2\n",
      "0\n",
      "Time 17:30:35. Best of generation 325 has fitness 1.35\n",
      "0\n",
      "Time 17:30:56. Best of generation 326 has fitness 1.15\n",
      "0\n",
      "Time 17:31:18. Best of generation 327 has fitness 1.6\n",
      "0\n",
      "Time 17:31:40. Best of generation 328 has fitness 1.25\n",
      "0\n",
      "Time 17:32:02. Best of generation 329 has fitness 1.25\n",
      "0\n",
      "Time 17:32:23. Best of generation 330 has fitness 1.55\n",
      "0\n",
      "Time 17:32:48. Best of generation 331 has fitness 1.1\n",
      "0\n",
      "Time 17:33:10. Best of generation 332 has fitness 0.9\n",
      "0\n",
      "Time 17:33:34. Best of generation 333 has fitness 0.95\n",
      "0\n",
      "Time 17:33:57. Best of generation 334 has fitness 1.25\n",
      "0\n",
      "Time 17:34:19. Best of generation 335 has fitness 1.7\n",
      "0\n",
      "Time 17:34:42. Best of generation 336 has fitness 1.25\n",
      "0\n",
      "Time 17:35:05. Best of generation 337 has fitness 1.3\n",
      "0\n",
      "Time 17:35:29. Best of generation 338 has fitness 1.25\n",
      "0\n",
      "Time 17:35:53. Best of generation 339 has fitness 1.7\n",
      "0\n",
      "Time 17:36:12. Best of generation 340 has fitness 1.25\n",
      "0\n",
      "Time 17:36:35. Best of generation 341 has fitness 1.0\n",
      "0\n",
      "Time 17:36:57. Best of generation 342 has fitness 1.2\n",
      "0\n",
      "Time 17:37:21. Best of generation 343 has fitness 0.85\n",
      "0\n",
      "Time 17:37:42. Best of generation 344 has fitness 1.3\n",
      "0\n",
      "Time 17:38:03. Best of generation 345 has fitness 0.8\n",
      "0\n",
      "Time 17:38:23. Best of generation 346 has fitness 1.15\n",
      "0\n",
      "Time 17:38:47. Best of generation 347 has fitness 1.55\n",
      "0\n",
      "Time 17:39:07. Best of generation 348 has fitness 1.3\n",
      "0\n",
      "Time 17:39:29. Best of generation 349 has fitness 0.75\n",
      "0\n",
      "Time 17:39:51. Best of generation 350 has fitness 1.55\n",
      "0\n",
      "Time 17:40:11. Best of generation 351 has fitness 1.15\n",
      "0\n",
      "Time 17:40:32. Best of generation 352 has fitness 1.5\n",
      "0\n",
      "Time 17:40:54. Best of generation 353 has fitness 1.0\n",
      "0\n",
      "Time 17:41:17. Best of generation 354 has fitness 1.35\n",
      "0\n",
      "Time 17:41:39. Best of generation 355 has fitness 1.25\n",
      "0\n",
      "Time 17:42:01. Best of generation 356 has fitness 1.35\n",
      "0\n",
      "Time 17:42:25. Best of generation 357 has fitness 1.05\n",
      "0\n",
      "Time 17:42:47. Best of generation 358 has fitness 1.65\n",
      "0\n",
      "Time 17:43:10. Best of generation 359 has fitness 1.45\n",
      "0\n",
      "Time 17:43:33. Best of generation 360 has fitness 1.55\n",
      "0\n",
      "Time 17:43:56. Best of generation 361 has fitness 1.2\n",
      "0\n",
      "Time 17:44:18. Best of generation 362 has fitness 0.75\n",
      "0\n",
      "Time 17:44:40. Best of generation 363 has fitness 1.3\n",
      "0\n",
      "Time 17:45:01. Best of generation 364 has fitness 1.25\n",
      "0\n",
      "Time 17:45:22. Best of generation 365 has fitness 1.3\n",
      "0\n",
      "Time 17:45:45. Best of generation 366 has fitness 1.3\n",
      "0\n",
      "Time 17:46:07. Best of generation 367 has fitness 1.3\n",
      "0\n",
      "Time 17:46:27. Best of generation 368 has fitness 1.2\n",
      "0\n",
      "Time 17:46:46. Best of generation 369 has fitness 2.0\n",
      "0\n",
      "Time 17:47:05. Best of generation 370 has fitness 1.4\n",
      "0\n",
      "Time 17:47:24. Best of generation 371 has fitness 1.15\n",
      "0\n",
      "Time 17:47:44. Best of generation 372 has fitness 2.15\n",
      "0\n",
      "Time 17:48:03. Best of generation 373 has fitness 1.0\n",
      "0\n",
      "Time 17:48:23. Best of generation 374 has fitness 1.55\n",
      "0\n",
      "Time 17:48:41. Best of generation 375 has fitness 1.0\n",
      "0\n",
      "Time 17:49:00. Best of generation 376 has fitness 1.0\n",
      "0\n",
      "Time 17:49:19. Best of generation 377 has fitness 1.15\n",
      "0\n",
      "Time 17:49:39. Best of generation 378 has fitness 1.25\n",
      "0\n",
      "Time 17:49:59. Best of generation 379 has fitness 1.4\n",
      "0\n",
      "Time 17:50:20. Best of generation 380 has fitness 1.7\n",
      "0\n",
      "Time 17:50:39. Best of generation 381 has fitness 1.65\n",
      "0\n",
      "Time 17:51:01. Best of generation 382 has fitness 1.55\n",
      "0\n",
      "Time 17:51:23. Best of generation 383 has fitness 1.3\n",
      "0\n",
      "Time 17:51:45. Best of generation 384 has fitness 1.5\n",
      "0\n",
      "Time 17:52:06. Best of generation 385 has fitness 1.65\n",
      "0\n",
      "Time 17:52:28. Best of generation 386 has fitness 1.45\n",
      "0\n",
      "Time 17:52:59. Best of generation 387 has fitness 1.75\n",
      "0\n",
      "Time 17:53:21. Best of generation 388 has fitness 1.3\n",
      "0\n",
      "Time 17:53:37. Best of generation 389 has fitness 1.15\n",
      "0\n",
      "Time 17:53:53. Best of generation 390 has fitness 1.7\n",
      "0\n",
      "Time 17:54:09. Best of generation 391 has fitness 1.25\n",
      "0\n",
      "Time 17:54:25. Best of generation 392 has fitness 1.9\n",
      "0\n",
      "Time 17:54:40. Best of generation 393 has fitness 1.15\n",
      "0\n",
      "Time 17:54:55. Best of generation 394 has fitness 1.1\n",
      "0\n",
      "Time 17:55:11. Best of generation 395 has fitness 1.05\n",
      "0\n",
      "Time 17:55:26. Best of generation 396 has fitness 1.0\n",
      "0\n",
      "Time 17:55:41. Best of generation 397 has fitness 1.0\n",
      "0\n",
      "Time 17:55:56. Best of generation 398 has fitness 0.95\n",
      "0\n",
      "Time 17:56:11. Best of generation 399 has fitness 1.3\n",
      "0\n",
      "Time 17:56:27. Best of generation 400 has fitness 1.05\n",
      "0\n",
      "Time 17:56:42. Best of generation 401 has fitness 1.4\n",
      "0\n",
      "Time 17:56:58. Best of generation 402 has fitness 1.1\n",
      "0\n",
      "Time 17:57:14. Best of generation 403 has fitness 1.25\n",
      "0\n",
      "Time 17:57:28. Best of generation 404 has fitness 1.15\n",
      "0\n",
      "Time 17:57:43. Best of generation 405 has fitness 1.0\n",
      "0\n",
      "Time 17:57:58. Best of generation 406 has fitness 1.05\n",
      "0\n",
      "Time 17:58:13. Best of generation 407 has fitness 1.05\n",
      "0\n",
      "Time 17:58:28. Best of generation 408 has fitness 1.65\n",
      "0\n",
      "Time 17:58:43. Best of generation 409 has fitness 1.0\n",
      "0\n",
      "Time 17:58:58. Best of generation 410 has fitness 2.0\n",
      "0\n",
      "Time 17:59:13. Best of generation 411 has fitness 1.35\n",
      "0\n",
      "Time 17:59:29. Best of generation 412 has fitness 1.0\n",
      "0\n",
      "Time 17:59:44. Best of generation 413 has fitness 1.45\n",
      "0\n",
      "Time 17:59:58. Best of generation 414 has fitness 1.25\n",
      "0\n",
      "Time 18:00:13. Best of generation 415 has fitness 1.5\n",
      "0\n",
      "Time 18:00:28. Best of generation 416 has fitness 1.5\n",
      "0\n",
      "Time 18:00:44. Best of generation 417 has fitness 1.05\n",
      "0\n",
      "Time 18:00:58. Best of generation 418 has fitness 1.05\n",
      "0\n",
      "Time 18:01:13. Best of generation 419 has fitness 1.25\n",
      "0\n",
      "Time 18:01:27. Best of generation 420 has fitness 0.7\n",
      "0\n",
      "Time 18:01:43. Best of generation 421 has fitness 1.4\n",
      "0\n",
      "Time 18:01:58. Best of generation 422 has fitness 1.4\n",
      "0\n",
      "Time 18:02:13. Best of generation 423 has fitness 1.6\n",
      "0\n",
      "Time 18:02:28. Best of generation 424 has fitness 1.6\n",
      "0\n",
      "Time 18:02:43. Best of generation 425 has fitness 1.25\n",
      "0\n",
      "Time 18:02:57. Best of generation 426 has fitness 1.55\n",
      "0\n",
      "Time 18:03:12. Best of generation 427 has fitness 1.45\n",
      "0\n",
      "Time 18:03:27. Best of generation 428 has fitness 1.6\n",
      "0\n",
      "Time 18:03:42. Best of generation 429 has fitness 1.55\n",
      "0\n",
      "Time 18:03:56. Best of generation 430 has fitness 1.25\n",
      "0\n",
      "Time 18:04:09. Best of generation 431 has fitness 0.8\n",
      "0\n",
      "Time 18:04:22. Best of generation 432 has fitness 1.75\n",
      "0\n",
      "Time 18:04:34. Best of generation 433 has fitness 1.65\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 18:04:48. Best of generation 434 has fitness 1.1\n",
      "0\n",
      "Time 18:05:00. Best of generation 435 has fitness 1.25\n",
      "0\n",
      "Time 18:05:13. Best of generation 436 has fitness 1.65\n",
      "0\n",
      "Time 18:05:25. Best of generation 437 has fitness 1.15\n",
      "0\n",
      "Time 18:05:39. Best of generation 438 has fitness 1.75\n",
      "0\n",
      "Time 18:05:51. Best of generation 439 has fitness 1.1\n",
      "0\n",
      "Time 18:06:04. Best of generation 440 has fitness 1.3\n",
      "0\n",
      "Time 18:06:17. Best of generation 441 has fitness 1.0\n",
      "0\n",
      "Time 18:06:30. Best of generation 442 has fitness 1.35\n",
      "0\n",
      "Time 18:06:43. Best of generation 443 has fitness 1.0\n",
      "0\n",
      "Time 18:06:55. Best of generation 444 has fitness 1.2\n",
      "0\n",
      "Time 18:07:08. Best of generation 445 has fitness 1.35\n",
      "0\n",
      "Time 18:07:20. Best of generation 446 has fitness 2.15\n",
      "0\n",
      "Time 18:07:33. Best of generation 447 has fitness 1.0\n",
      "0\n",
      "Time 18:07:46. Best of generation 448 has fitness 1.6\n",
      "0\n",
      "Time 18:07:59. Best of generation 449 has fitness 1.0\n",
      "0\n",
      "Time 18:08:12. Best of generation 450 has fitness 1.3\n",
      "0\n",
      "Time 18:08:24. Best of generation 451 has fitness 1.15\n",
      "0\n",
      "Time 18:08:37. Best of generation 452 has fitness 0.75\n",
      "0\n",
      "Time 18:08:49. Best of generation 453 has fitness 0.8\n",
      "0\n",
      "Time 18:09:02. Best of generation 454 has fitness 0.9\n",
      "0\n",
      "Time 18:09:15. Best of generation 455 has fitness 1.1\n",
      "0\n",
      "Time 18:09:27. Best of generation 456 has fitness 1.05\n",
      "0\n",
      "Time 18:09:40. Best of generation 457 has fitness 0.8\n",
      "0\n",
      "Time 18:09:52. Best of generation 458 has fitness 1.65\n",
      "0\n",
      "Time 18:10:05. Best of generation 459 has fitness 1.85\n",
      "0\n",
      "Time 18:10:17. Best of generation 460 has fitness 0.8\n",
      "0\n",
      "Time 18:10:30. Best of generation 461 has fitness 1.3\n",
      "0\n",
      "Time 18:10:43. Best of generation 462 has fitness 1.05\n",
      "0\n",
      "Time 18:10:56. Best of generation 463 has fitness 1.8\n",
      "0\n",
      "Time 18:11:08. Best of generation 464 has fitness 1.3\n",
      "0\n",
      "Time 18:11:21. Best of generation 465 has fitness 1.1\n",
      "0\n",
      "Time 18:11:34. Best of generation 466 has fitness 1.2\n",
      "0\n",
      "Time 18:11:47. Best of generation 467 has fitness 0.95\n",
      "0\n",
      "Time 18:12:00. Best of generation 468 has fitness 1.5\n",
      "0\n",
      "Time 18:12:12. Best of generation 469 has fitness 1.25\n",
      "0\n",
      "Time 18:12:25. Best of generation 470 has fitness 1.4\n",
      "0\n",
      "Time 18:12:53. Best of generation 471 has fitness 1.35\n",
      "0\n",
      "Time 18:13:05. Best of generation 472 has fitness 1.45\n",
      "0\n",
      "Time 18:13:17. Best of generation 473 has fitness 1.3\n",
      "0\n",
      "Time 18:13:30. Best of generation 474 has fitness 1.1\n",
      "0\n",
      "Time 18:13:42. Best of generation 475 has fitness 1.7\n",
      "0\n",
      "Time 18:13:55. Best of generation 476 has fitness 0.65\n",
      "0\n",
      "Time 18:14:07. Best of generation 477 has fitness 1.2\n",
      "0\n",
      "Time 18:14:20. Best of generation 478 has fitness 1.1\n",
      "0\n",
      "Time 18:14:33. Best of generation 479 has fitness 1.5\n",
      "0\n",
      "Time 18:14:45. Best of generation 480 has fitness 1.35\n",
      "0\n",
      "Time 18:14:58. Best of generation 481 has fitness 1.15\n",
      "0\n",
      "Time 18:15:11. Best of generation 482 has fitness 1.35\n",
      "0\n",
      "Time 18:15:23. Best of generation 483 has fitness 0.85\n",
      "0\n",
      "Time 18:15:35. Best of generation 484 has fitness 1.35\n",
      "0\n",
      "Time 18:15:48. Best of generation 485 has fitness 1.5\n",
      "0\n",
      "Time 18:16:01. Best of generation 486 has fitness 0.8\n",
      "0\n",
      "Time 18:16:13. Best of generation 487 has fitness 1.15\n",
      "0\n",
      "Time 18:16:26. Best of generation 488 has fitness 1.6\n",
      "0\n",
      "Time 18:16:38. Best of generation 489 has fitness 1.5\n",
      "0\n",
      "Time 18:16:54. Best of generation 490 has fitness 1.7\n",
      "0\n",
      "Time 18:17:11. Best of generation 491 has fitness 1.2\n",
      "0\n",
      "Time 18:17:27. Best of generation 492 has fitness 1.0\n",
      "0\n",
      "Time 18:17:42. Best of generation 493 has fitness 1.4\n",
      "0\n",
      "Time 18:17:57. Best of generation 494 has fitness 1.15\n",
      "0\n",
      "Time 18:18:12. Best of generation 495 has fitness 0.7\n",
      "0\n",
      "Time 18:18:26. Best of generation 496 has fitness 1.3\n",
      "0\n",
      "Time 18:18:49. Best of generation 497 has fitness 1.3\n",
      "0\n",
      "Time 18:19:29. Best of generation 498 has fitness 1.15\n",
      "0\n",
      "Time 18:19:50. Best of generation 499 has fitness 1.0\n",
      "0\n",
      "Time 18:20:10. Best of generation 500 has fitness 1.3\n",
      "0\n",
      "Time 18:20:33. Best of generation 501 has fitness 1.05\n",
      "0\n",
      "Time 18:20:54. Best of generation 502 has fitness 1.4\n",
      "0\n",
      "Time 18:21:15. Best of generation 503 has fitness 1.05\n",
      "0\n",
      "Time 18:21:38. Best of generation 504 has fitness 1.45\n",
      "0\n",
      "Time 18:22:01. Best of generation 505 has fitness 1.6\n",
      "0\n",
      "Time 18:22:20. Best of generation 506 has fitness 0.95\n",
      "0\n",
      "Time 18:22:39. Best of generation 507 has fitness 1.05\n",
      "0\n",
      "Time 18:22:59. Best of generation 508 has fitness 1.5\n",
      "0\n",
      "Time 18:23:17. Best of generation 509 has fitness 1.45\n",
      "0\n",
      "Time 18:23:35. Best of generation 510 has fitness 1.9\n",
      "0\n",
      "Time 18:23:54. Best of generation 511 has fitness 1.35\n",
      "0\n",
      "Time 18:24:12. Best of generation 512 has fitness 1.1\n",
      "0\n",
      "Time 18:24:32. Best of generation 513 has fitness 1.4\n",
      "0\n",
      "Time 18:24:51. Best of generation 514 has fitness 1.85\n",
      "0\n",
      "Time 18:25:10. Best of generation 515 has fitness 0.85\n",
      "0\n",
      "Time 18:25:28. Best of generation 516 has fitness 1.15\n",
      "0\n",
      "Time 18:25:46. Best of generation 517 has fitness 1.6\n",
      "0\n",
      "Time 18:26:04. Best of generation 518 has fitness 1.95\n",
      "0\n",
      "Time 18:26:24. Best of generation 519 has fitness 1.15\n",
      "0\n",
      "Time 18:26:41. Best of generation 520 has fitness 1.45\n",
      "0\n",
      "Time 18:27:01. Best of generation 521 has fitness 1.15\n",
      "0\n",
      "Time 18:27:19. Best of generation 522 has fitness 0.75\n",
      "0\n",
      "Time 18:27:38. Best of generation 523 has fitness 1.3\n",
      "0\n",
      "Time 18:27:56. Best of generation 524 has fitness 1.3\n",
      "0\n",
      "Time 18:28:14. Best of generation 525 has fitness 0.95\n",
      "0\n",
      "Time 18:28:33. Best of generation 526 has fitness 0.9\n",
      "0\n",
      "Time 18:28:52. Best of generation 527 has fitness 1.35\n",
      "0\n",
      "Time 18:29:11. Best of generation 528 has fitness 1.65\n",
      "0\n",
      "Time 18:29:28. Best of generation 529 has fitness 0.95\n",
      "0\n",
      "Time 18:29:46. Best of generation 530 has fitness 1.25\n",
      "0\n",
      "Time 18:30:04. Best of generation 531 has fitness 1.8\n",
      "0\n",
      "Time 18:30:22. Best of generation 532 has fitness 1.1\n",
      "0\n",
      "Time 18:30:38. Best of generation 533 has fitness 1.05\n",
      "0\n",
      "Time 18:30:56. Best of generation 534 has fitness 1.1\n",
      "0\n",
      "Time 18:31:13. Best of generation 535 has fitness 1.4\n",
      "0\n",
      "Time 18:31:32. Best of generation 536 has fitness 1.35\n",
      "0\n",
      "Time 18:31:50. Best of generation 537 has fitness 1.2\n",
      "0\n",
      "Time 18:32:08. Best of generation 538 has fitness 1.05\n",
      "0\n",
      "Time 18:32:27. Best of generation 539 has fitness 1.4\n",
      "0\n",
      "Time 18:32:46. Best of generation 540 has fitness 0.9\n",
      "0\n",
      "Time 18:33:04. Best of generation 541 has fitness 1.4\n",
      "0\n",
      "Time 18:33:22. Best of generation 542 has fitness 1.7\n",
      "0\n",
      "Time 18:33:39. Best of generation 543 has fitness 0.75\n",
      "0\n",
      "Time 18:33:56. Best of generation 544 has fitness 1.5\n",
      "0\n",
      "Time 18:34:13. Best of generation 545 has fitness 1.25\n",
      "0\n",
      "Time 18:34:29. Best of generation 546 has fitness 1.6\n",
      "0\n",
      "Time 18:34:46. Best of generation 547 has fitness 1.35\n",
      "0\n",
      "Time 18:35:03. Best of generation 548 has fitness 1.15\n",
      "0\n",
      "Time 18:35:19. Best of generation 549 has fitness 1.15\n",
      "0\n",
      "Time 18:35:35. Best of generation 550 has fitness 1.0\n",
      "0\n",
      "Time 18:35:52. Best of generation 551 has fitness 1.35\n",
      "0\n",
      "Time 18:36:09. Best of generation 552 has fitness 0.9\n",
      "0\n",
      "Time 18:36:26. Best of generation 553 has fitness 1.0\n",
      "0\n",
      "Time 18:36:43. Best of generation 554 has fitness 1.1\n",
      "0\n",
      "Time 18:37:01. Best of generation 555 has fitness 1.55\n",
      "0\n",
      "Time 18:37:18. Best of generation 556 has fitness 1.35\n",
      "0\n",
      "Time 18:37:36. Best of generation 557 has fitness 1.0\n",
      "0\n",
      "Time 18:38:02. Best of generation 558 has fitness 1.5\n",
      "0\n",
      "Time 18:38:28. Best of generation 559 has fitness 1.05\n",
      "0\n",
      "Time 18:38:48. Best of generation 560 has fitness 1.15\n",
      "0\n",
      "Time 18:39:06. Best of generation 561 has fitness 1.4\n",
      "0\n",
      "Time 18:39:23. Best of generation 562 has fitness 1.45\n",
      "0\n",
      "Time 18:39:40. Best of generation 563 has fitness 1.2\n",
      "0\n",
      "Time 18:39:59. Best of generation 564 has fitness 1.4\n",
      "0\n",
      "Time 18:40:24. Best of generation 565 has fitness 0.9\n",
      "0\n",
      "Time 18:40:59. Best of generation 566 has fitness 1.05\n",
      "0\n",
      "Time 18:41:20. Best of generation 567 has fitness 1.3\n",
      "0\n",
      "Time 18:41:38. Best of generation 568 has fitness 0.8\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "def play_game(game_parameters,agent):\n",
    "    game = pyhanabi.HanabiGame(game_parameters)\n",
    "    obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "    state = game.new_initial_state()\n",
    "    score=0\n",
    "    \n",
    "    while not state.is_terminal():\n",
    "        if state.score() >=score:\n",
    "            score = state.score()\n",
    "        if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:\n",
    "            state.deal_random_card()\n",
    "            continue\n",
    "\n",
    "\n",
    "        current_life_token = state.life_tokens()\n",
    "        current_fireworks = state.fireworks()\n",
    "        move  = agent.act(state)\n",
    "\n",
    "        state.apply_move(move)\n",
    "    return score\n",
    "\n",
    "game_parameters = {\"players\": 2, \"random_start_player\": True}\n",
    "game = pyhanabi.HanabiGame(game_parameters)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "\n",
    "# pyagent = PytorchAgent(game)\n",
    "\n",
    "#TODO: Try different values for these hyperparameters\n",
    "population_size = 100\n",
    "num_games = 20\n",
    "num_generations = 1000\n",
    "# one run of game\n",
    "\n",
    "#TODO: Try to load the initial parameters of a few of the individuals from our Rainbow AIIIDE experiments.\n",
    "population = [PytorchAgent(game) for p in range(population_size)]\n",
    "print(population[0])\n",
    "\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    # Evaluate each agent\n",
    "    for agent in population:\n",
    "        total_score = 0.0\n",
    "        for g in range(num_games):\n",
    "            score = play_game(game_parameters,agent)\n",
    "            total_score+=score\n",
    "#             print(\"Gen {} game {} had score {}\".format((gen,g,score)))\n",
    "        agent.fitness = float(total_score)/float(num_games)\n",
    "    \n",
    "    # Sort by fitness\n",
    "    population.sort(key = lambda x: x.fitness, reverse=True)\n",
    "    \n",
    "    new_population=[]\n",
    "    \n",
    "    # Create new population by discarding the bottom half, duplicating the top half, then mutating one of the copies\n",
    "    for i, a in enumerate(population): #TODO: Try other strategies such as make parent selection more likely for high fitness parents, elitism for the top k agents, etc\n",
    "        if i >= population_size/2:\n",
    "            parent_index = int(i - population_size/2) #Here it could be something like random parent (weighted by fitness)\n",
    "            parent = population[parent_index]\n",
    "            child = PytorchAgent(game,parent.net)\n",
    "            child.mutate()\n",
    "            new_population.append(child)\n",
    "        else:\n",
    "            agent.mutate()\n",
    "            new_population.append(agent)\n",
    "    population = new_population\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "#     print (\"Population Size is \".format(get_size([x.seeds for x in population])))\n",
    "#     print(get_size([x.seeds for x in population]))\n",
    "#     print(get_size([x.net for x in population]))\n",
    "#     for p in population:\n",
    "#         n = p.net\n",
    "#         print(get_size(n.parameters()))\n",
    "#         for param in n.parameters():\n",
    "#             print(\" \" + str(get_size(param)))\n",
    "#             print(\" \" + str(len(param)))\n",
    "#             print(\" \" +str(param.shape))\n",
    "#             print(param)\n",
    "    print('Time {}. Best of generation {} has fitness {}'.format(current_time,gen, population[0].fitness))\n",
    "    cmd = 'ps -o pid,user,%mem,command -p ' + str(os.getpid())\n",
    "    print(os.system(cmd))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'is_terminal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b74cbe644526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrl_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hanabi-Full'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_players\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpyhanabi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHANCE_PLAYER_ID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal_random_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'is_terminal'"
     ]
    }
   ],
   "source": [
    "environment = rl_env.make('Hanabi-Full', num_players=2)\n",
    "state = environment.reset()\n",
    "while not state.is_terminal():\n",
    "    if state.cur_player() == pyhanabi.CHANCE_PLAYER_ID:  \n",
    "        state.deal_random_card()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(get_encoded_observations(obs_encoder, state, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_observations = torch.FloatTensor(get_encoded_observations(obs_encoder, state, 0))\n",
    "net(tensor_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net(tensor_observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_value = net(tensor_observations).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_value.index(max(move_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_observations(encoder, state, player_num):\n",
    "    codes = encoder.encode(state.observation(player_num))\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.cur_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_observations = get_encoded_observations(obs_encoder, state, state.cur_player())\n",
    "mytensor = list_to_tensor(encoded_observations)\n",
    "legal_moves = state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.new_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.life_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.fireworks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = rl_env.make('Hanabi-Full', num_players=2)\n",
    "state = environment.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = environment.reset()\n",
    "type(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = pyhanabi.HanabiGame()\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)\n",
    "print(game.parameter_string(), end=\"\")\n",
    "obs_encoder = pyhanabi.ObservationEncoder(game, enc_type=pyhanabi.ObservationEncoderType.CANONICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hle_test)",
   "language": "python",
   "name": "hle_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
